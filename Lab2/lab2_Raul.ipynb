{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# NLP 2026\n",
    "# Lab 2: Word Vectors and Information Retrieval\n",
    "## *alt*-title: ğŸš€ Project CleanSearch AI, a DOGE initiative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ğŸ›ï¸ğŸ• PRESS RELEASE â€” For Immediate (and Maximum Efficiency) Distribution  \n",
    "\n",
    "### The Department of Outdated Government Encyclopedias (DOGE) Launches Revolutionary NLP Project to Rescue Public Knowledge  \n",
    "\n",
    "**Washington, D.C.** â€” In a bold step toward modernizing the nationâ€™s most chaotic digital archives, the   **Department of Outdated Government Encyclopedias (DOGE)** today announced the launch of its new initiative:  ğŸš€ **Project CleanSearch AI**.\n",
    "\n",
    "For decades, citizens have struggled to find simple answers hidden inside massive, noisy, and poorly structured government knowledge repositories.\n",
    "\n",
    "Questions such as:\n",
    "\n",
    "- â€œWho won the Nobel Prize in 1930?â€  \n",
    "- â€œWhen did Angola become independent?â€  \n",
    "\n",
    "have resulted in thousands of irrelevant web pages, confusing biographies and excessive scrolling ğŸ“‰\n",
    "\n",
    "> *â€œFrankly, our archives are a mess,â€* said a DOGE spokesperson.  \n",
    "> *â€œTheyâ€™re long, noisy and about as searchable as a pile of printed Wikipedia pages thrown into a hurricane.â€*\n",
    "\n",
    "### ğŸ§  The Solution  \n",
    "\n",
    "DOGE has assembled an elite team of AI specialists, hired from UM DACS 2nd year bachelor program with the following goals:\n",
    "\n",
    "âœ… Clean decades of messy digital text  \n",
    "âœ… Extract meaningful knowledge  \n",
    "âœ… Replace outdated keyword search with modern **retrieval systems**  \n",
    "âœ… Deliver instant, accurate answers to citizens  \n",
    "\n",
    "Using real-world noisy data similar to the governmentâ€™s archives, the team will experiment with multiple retrieval models to determine the most efficient approach, methods which have been taught in the fabulous classes of some person quoted as J.S. \n",
    "\n",
    "Whispers across the digital corridors suggest that DOGE may soon supercede the legendary Project 2-2, though DACS management insist these rumours are â€œunder control.â€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deliverable:\n",
    "\n",
    "- You are asked to deliver **two files only**:\n",
    "  - your executed notebook file (`.ipynb`), and\n",
    "  - your poster (`.pdf`).  \n",
    "  No other files will be taken into consideration.\n",
    "  \n",
    "âš ï¸ âš ï¸ âš ï¸ Each part of the poster will contribute to your grade proportionally to what we present below. If we can't find the relevant part in your notebook (e.g. the figure or the code to support your findings) we will reduce (or even zero-out) your grade for that part.\n",
    "\n",
    "### Instructions for the poster: \n",
    "\n",
    "The final deliverable for this lab is a **scientific poster** presenting your work on building and evaluating a sentence retrieval system using the TriviaQA dataset.\n",
    "- ğŸ“ **Size:** A0 or A1  \n",
    "- ğŸ§­ **Orientation:** Portrait or landscape (your choice)  \n",
    "- ğŸ“‘ **Layout:** Clear section structure (e.g., columns or blocks)  \n",
    "\n",
    "#### Your poster should include the following sections:\n",
    "---\n",
    "#### 1ï¸âƒ£ Problem & Motivation ğŸ¯\n",
    "- Describe the retrieval task (query â†’ correct answer document) and the challenges\n",
    "- Briefly introduce the dataset and its challenges  \n",
    "#### 2ï¸âƒ£ Data Preparation ğŸ§¹\n",
    "Explain:\n",
    "- Train / validation / test splitting  \n",
    "- Your cleaning pipeline (at least 6 preprocessing steps)  \n",
    "Include at least one **before vs after cleaning** example.\n",
    "#### 3ï¸âƒ£ Retrieval Models ğŸ¤–\n",
    "Present and explain the modes you used:\n",
    "- Bag-of-Words + cosine similarity  \n",
    "- TF-IDF + cosine similarity  \n",
    "- Sentence embeddings (averaged word embeddings)  \n",
    "- [any other model?] \n",
    "Discuss strengths and limitations of each.\n",
    "#### 4ï¸âƒ£ Qualitative Analysis ğŸ”\n",
    "Provide:\n",
    "- At least **3 successful retrieval examples**  \n",
    "- At least **3 failure cases**  \n",
    "Explain why each worked or failed.\n",
    "#### 5ï¸âƒ£ Quantitative Evaluation ğŸ“Š (Main focus)\n",
    "Report **Recall@K** (and possibly other metrics) on the **test set** for all methods:\n",
    "- BOW  \n",
    "- TF-IDF  \n",
    "- Pre-trained embeddings  \n",
    "- [Additional models]  \n",
    "Include relevant table(s) and/or plot(s) and briefly discuss trends.\n",
    "#### 6ï¸âƒ£ Discussion & Recommendations ğŸ’¡\n",
    "Conclude with:\n",
    "- Which method you would recommend and why  \n",
    "- Key tradeoffs  \n",
    "- Possible improvements  \n",
    "### ğŸ¨ Optional Creative Element (Bonus)\n",
    "\n",
    "You may (optionally) present your poster within the fictional storyline of ğŸ›ï¸ **DOGE â€” Department of Outdated Government Encyclopedias**, where your retrieval system modernizes chaotic national archives and replaces legacy keyword search. Creativity is welcome, but scientific clarity is the priority. We will vote for the \"most creative poster\".\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Evaluation Focus\n",
    "\n",
    "Posters will be assessed on:\n",
    "- Correctness of the pipeline incl. the code (25%)\n",
    "- Clarity of explanations and interpretations of results (25%)\n",
    "- Quality of analysis (20%)\n",
    "- Proper use of evaluation metrics (e.g. Recall@K) (10%)\n",
    "- Visual organization (10%)\n",
    "- Discussion and recommendations (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "As in the last lab, we will be using huggingface datasets library ([https://huggingface.co/datasets](https://huggingface.co/datasets)). We will work with TriviaQA dataset ([https://huggingface.co/datasets/sentence-transformers/trivia-qa](https://huggingface.co/datasets/sentence-transformers/trivia-qa)), which contains pairs of queries and articles that contain the answer.\n",
    "\n",
    "In this section we will prepare the dataset, aka clean the sentences and tokenize. We will additionally extract the answers, as some articles correspond to multiple queries. We will create a separate dataset from the unique answers. We will do that for each split separately, so that we can test our retrieval fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start with importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from datasets import DatasetDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading\n",
    "Now, we can begin loading the dataset and inspecting the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcb904ec1ee4edfb84abb164b36513e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8796d885b950427788a81f50907a5843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pair/train-00000-of-00001.parquet:   0%|          | 0.00/150M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2ca39840ed49c5878d51a30b8abaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/73346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'answer'],\n",
      "        num_rows: 73346\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('sentence-transformers/trivia-qa')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 0\n",
      "query Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "answer The Nobel Prize in Literature 1930 The Nobel Prize in Literature 1930 Sinclair Lewis The Nobel Prize in Literature 1930 Sinclair Lewis Prize share: 1/1 The Nobel Prize in Literature 1930 was awarded to Sinclair Lewis \"for his vigorous and graphic art of description and his ability to create, with wit and humour, new types of characters\". Photos: Copyright Â© The Nobel Foundation Share this: To cite this page MLA style: \"The Nobel Prize in Literature 1930\". Nobelprize.org. Nobel Media AB 2014. Web. 18 Jan 2017. <http://www.nobelprize.org/nobel_prizes/literature/laureates/1930/>\n",
      "\n",
      "example 1\n",
      "query Where in England was Dame Judi Dench born?\n",
      "answer Judi Dench - IMDb IMDb Actress | Music Department | Soundtrack Judi Dench was born in York, England, to Eleanora Olive (Jones), who was from Dublin, Ireland, and Reginald Arthur Dench, a doctor from Dorset, England. She attended Mount School in York, and studied at the Central School of Speech and Drama. She has performed with Royal Shakespeare Company, the National Theatre, and at Old Vic Theatre. She is a ... See full bio Â» Born: a list of 35 people created 02Â JulÂ 2011 a list of 35 people created 19Â AprÂ 2012 a list of 35 people created 28Â MayÂ 2014 a list of 25 people created 05Â AugÂ 2014 a list of 26 people created 18Â MayÂ 2015 Do you have a demo reel? Add it to your IMDbPage How much of Judi Dench's work have you seen? User Polls Won     1     Oscar. Another    59 wins & 163 nominations. See more awards Â Â» Known For Â 2016 The Hollow Crown (TV Series) Cecily, Duchess of York Â 2015 The Vote (TV Movie) Christine Metcalfe - Total War (1996) ... Narrator (voice) - Stalemate (1996) ... Narrator (voice) Â 1992 The Torch (TV Mini-Series) Aba Â 1990 Screen One (TV Series) Anne Â 1989 Behaving Badly (TV Mini-Series) Bridget Â 1981 BBC2 Playhouse (TV Series) Sister Scarli Â 1976 Arena (TV Series documentary) Sweetie Simpkins Â 1973 Ooh La La! (TV Series) AmÃ©lie Â 1966 Court Martial (TV Series) Marthe Â 1963 Z Cars (TV Series) Elena Collins Â 1963 Love Story (TV Series) Pat McKendrick Â 1960 The Terrible Choice (TV Series) Good Angel Music department (1 credit) Â  A Fine Romance (TV Series) (theme sung by - 14 episodes, 1981 - 1983) (theme song sung by - 12 episodes, 1983 - 1984) - A Romantic Meal (1984) ... (theme song sung by) - Problems (1984) ... (theme song sung by) Â 2013 Fifty Years on Stage (TV Movie) (performer: \"Send in the Clowns\") Â 2009 Nine (performer: \"Folies BergÃ¨re\") - What's Wrong with Mrs Bale? (1997) ... (performer: \"Raindrops Keep Fallin' On My Head\" - uncredited) - Misunderstandings (1993) ... (performer: \"Walkin' My Baby Back Home\" - uncredited) Â 1982-1984 A Fine Romance (TV Series) (performer - 2 episodes) - The Telephone Call (1984) ... (performer: \"Boogie Woogie Bugle Boy\" - uncredited) - Furniture (1982) ... (performer: \"Rule, Britannia!\" - uncredited) HideÂ  Â 2009 Waiting in Rhyme (Video short) (special thanks) Â 2007 Expresso (Short) (special thanks) Â 1999 Shakespeare in Love and on Film (TV Movie documentary) (thanks - as Dame Judi Dench) HideÂ  Â 2016 Rio Olympics (TV Mini-Series) Herself Â 2015 In Conversation (TV Series documentary) Herself Â 2015 Entertainment Tonight (TV Series) Herself Â 2015 CBS This Morning (TV Series) Herself - Guest Â 2015 The Insider (TV Series) Herself Â 1999-2014 Cinema 3 (TV Series) Herself Â 2013 Good Day L.A. (TV Series) Herself - Guest Â 2013 Arena (TV Series documentary) Herself Â 2013 At the Movies (TV Series) Herself Â 2013 Shooting Bond (Video documentary) Herself Â 2013 Bond's Greatest Moments (TV Movie documentary) Herself Â 2012 Made in Hollywood (TV Series) Herself Â 1999-2012 Charlie Rose (TV Series) Herself - Guest Â 2008-2012 This Morning (TV Series) Herself - Guest Â 2012 The Secrets of Skyfall (TV Short documentary) Herself Â 2012 Anderson Live (TV Series) Herself Â 2012 J. Edgar: A Complicated Man (Video documentary short) Herself Â 2011 The Many Faces of... (TV Series documentary) Herself / Various Characters Â 2011 Na plovÃ¡rne (TV Series) Herself Â 2010 BBC Proms (TV Series) Herself Â 2010 The South Bank Show Revisited (TV Series documentary) Herself - Episode #6.68 (2009) ... Herself - Guest (as Dame Judi Dench) Â 2007-2009 Breakfast (TV Series) Â 2009 Larry King Live (TV Series) Herself - Guest Â 2009 The One Show (TV Series) Herself Â 2009 Cranford in Detail (Video documentary short) Herself / Miss Matty Jenkins (as Dame Judi Dench) Â 2005-2008 The South Bank Show (TV Series documentary) Herself Â 2008 Tavis Smiley (TV Series) Herself - Guest Â 2007 ITV News (TV Series) Herself - BAFTA Nominee Â 2007 The Making of Cranford (Video documentary short) Herself / Miss Matty Jenkyns (as Dame Judi Dench) Â 2006 Becoming Bond (TV Movie documentary) Herself Â 2006 CorazÃ³n de... (TV Series) Hers\n",
      "\n",
      "example 2\n",
      "query In which decade did Billboard magazine first publish and American hit chart?\n",
      "answer The US Billboard song chart The US Billboard song chart Search this site with Google Song chart US Billboard The Billboard magazine has published various music charts starting (with sheet music) in 1894, the first \"Music Hit Parade\" was published in 1936 , the first \"Music Popularity Chart\" was calculated in 1940 . These charts became less irregular until the weekly \"Hot 100\" was started in 1958 . The current chart combines sales, airplay and downloads. A music collector that calls himself Bullfrog has been consolidating the complete chart from 1894 to the present day.  he has published this information in a comprehenive spreadsheet (which can be obtained at bullfrogspond.com/ ). The Bullfrog data assigns each song a unique identifier, something like \"1968_076\" (which just happens to be the Bee Gees song \"I've Gotta Get A Message To You\"). This \"Whitburn Number\" is provided to match with the books of Joel Whitburn and consists of the year and a ranking within the year. A song that first entered the charts in December and has a long run is listed the following year. This numbering scheme means that songs which are still in the charts cannot be assigned a final id, because their ranking might change. So the definitive listing for a year cannot be final until about April. In our listing we only use songs with finalised IDs, this means that every year we have to wait until last year's entries are finalised before using them. (Source bullfrogspond.com/ , the original version used here was 20090808 with extra data from: the 2009 data from 20091219 the 2010 data from 20110305 the 2011 data from 20120929 the 2012 data from 20130330 the 2013 data from 20150328 The 20150328 data was the last one produced before the Billboard company forced the data to be withdrawn. As far as we know there are no more recent data sets available. This pattern of obtaining the data for a particular year in the middle of the following one comes from the way that the Bullfrog project generates the identifier for a song (what they call the \"Prefix\" in the spreadsheet). Recent entries are identified with keys like \"2015-008\" while older ones have keys like \"2013_177\". In the second case the underscore is significant, it indicates that this was the 177th biggest song released in 2013. Now, of course, during the year no one knows where a particular song will rank, so the underscore names can't be assigned until every song from a particular year has dropped out of the charts, so recent records are temporarily assigned a name with a dash. In about May of the following year the rankings are calculated and the final identifiers are assigned. That is why we at the Turret can only grab this data retrospectively. Attributes The original spreadsheet has a number of attributes, we have limited our attention to just a few of them: 134 9 The songs with the most entries on the chart were White Christmas (with 33 versions and a total of 110 weeks) and Stardust (with 19 and a total of 106 weeks). position The peak position that songs reached in the charts should show an smooth curve from number one down to the lowest position. This chart has more songs in the lower peak positions than one would expect. Before 1991 the profile of peak positions was exactly as you would expect, that year Billboard introduced the concept of \"Recurrent\" tracks, that is they removed any track from the chart which had spent more than twenty weeks in the chart and had fallen to the lower positions. weeks The effect of the \"Recurrent\" process, by which tracks are removed if they have spent at least twenty weeks in the chart and have fallen to the lower reaches, can clearly be seen in the strange spike in this attribute. This \"adjustment\" was intended to promote newer songs and ensure the chart does not become \"stale\". In fact since it was introduced in 1991 the length of long chart runs has increased, this might reflect the more conscious efforts of record companies to \"game\" the charts by controlling release times and promotions, or it coul\n",
      "\n",
      "example 3\n",
      "query From which country did Angola achieve independence in 1975?\n",
      "answer Angola from past to present | Conciliation Resources Angola from past to present Angola from past to present From military peace to social justice? The Angolan peace process Publication date:Â  David Birmingham When Angola achieved independence in 1975, a war was raging between competing national liberation movements and their foreign backers. Guus Meijer and David Birmingham revisit Angolaâ€™s colonial period and the independence struggle that followed and ask how the resulting social and economic divisions shaped and were manipulated by the warring parties. The article describes the introduction of authoritarian one-party rule under the MPLA and the impact of natural resource development and international and regional powers on the conflict. Tracing the conflict up to the signing of the Luena Memorandum, the authors conclude that Angolaâ€™s peace remains incomplete and that the country faces many challenges in achieving social and democratic reconstruction. Read full article Angola from past to present On 11 November 1975, the Popular Movement for the Liberation of Angola (MPLA) declared Angola's independence and installed Agostinho Neto as its first President in the former Portuguese colony's capital at Luanda. This outcome had long seemed uncertain and indeed even unlikely; the MPLA had not only had to deal with its own serious internal troubles and disaffections, but had also had to take on the Portuguese colonial army and the two rival armed movements, each backed by powerful allies. Holden Roberto's National Front for the Liberation of Angola (FNLA) had initially been the most powerful of the three competing national liberation movements and in the autumn of 1975 it came close to capturing Luanda from the north, backed by a heavily armed force supplied by President Mobuto Sese Seko of Zaire (now the Democratic Republic of Congo). In the south, two armoured columns of a South African invasion force, acting in military coordination with the Union for the Total Independence of Angola (UNITA), led by Jonas Savimbi, almost reached Luanda before they were stopped by Cuban troops which had been rushed to the assistance of the MPLA. The independent Angolan state was thus born out of turmoil and violence and amid serious national, regional and global rivalries. This heritage with its deep historical roots was to influence the unfolding of events for a long time. Angola, like most African countries, grew out of a conglomerate of peoples and groups each with its own distinct history and traditions. Gradually small local nations and states came into contact with each other and historical developments drove them to share a common destiny under increasing Portuguese influence. Long before the arrival of the Portuguese, Bantu-speaking communities had established a farming economy over most of the territory. They had absorbed many of the scattered Khoisan-speaking populations and developed a successful pastoral dimension to their agriculture as well as building up trading economies. One of the most successfully diverse market centres became the town of M'banza Kongo around which the Kongo kingdom evolved. Further east the concept of state formation related to the political ideology of the Lunda peoples while in the south later kingdoms took shape in the highlands of the Ovimbundu people. Angola under Portuguese rule Although the first Portuguese traders, explorers and soldiers set foot on this part of the African coast from 1483, modern colonisation of the whole territory was only formalised four centuries later after the Berlin Conference of 1884-85. Wide stretches of Angola experienced colonial rule for less than a century, and even after 1900 armed revolts broke out and resistance movements sprang up as among the Ovimbundu and the Bakongo from 1913, until the last northern resistance was put down in 1917. During its century of overrule the colonial regime left crucial marks on Angolan society. Its discriminatory legislation, particularly the Statute of the Portuguese Natives of the Provinces of Angola, Mozambique, and Guinea, separ\n",
      "\n",
      "example 4\n",
      "query Which city does David Soul come from?\n",
      "answer David Soul - IMDb IMDb Actor | Soundtrack | Director David Soul achieved pop icon status as handsome, blond-haired, blue-eyed Detective Kenneth Hutchinson on the cult \"buddy cop\" TV series Starsky and Hutch (1975), Soul also had a very successful singing career recording several albums, with worldwide number one hit singles including \"Silver Lady\" & \"Don't Give Up on Us Baby\". Born in Chicago, ... See full bio Â» Born: Share this page: Related News a list of 43 people created 14Â JanÂ 2011 a list of 37 people created 13Â MarÂ 2011 a list of 48 people created 26Â MarÂ 2012 a list of 973 people created 26Â FebÂ 2013 a list of 127 people created 05Â JulÂ 2014 Do you have a demo reel? Add it to your IMDbPage How much of David Soul's work have you seen? User Polls 1 win & 3 nominations. See more awards Â Â» Known For Starsky and Hutch Det. Ken 'Hutch' Hutchinson (1975-1979) Â 2004 The Dark Lantern (TV Movie) Storyteller Â 2004 Dalziel and Pascoe (TV Series) Detective Gus D'Amato Â 1995 Vents contraires (TV Movie) Quill Â 1994 High Tide (TV Series) Brian Landis Â 1991-1993 Murder, She Wrote (TV Series) Jordan Barnett / Wes McSorley Â 1990 The Young Riders (TV Series) Jeremy Styles Â 1989 Prime Target (TV Movie) Peter Armetage Â 1989 Deadly Nightmares (TV Series) Cooper Halliday Â 1989 Alfred Hitchcock Presents (TV Series) Michael Dennison Â 1987 Crime Story (TV Series) Dr. Newhouse Â 1987 Harry's Hong Kong (TV Movie) Harry Petros Â 1986 The Fifth Missile (TV Movie) Capt. Kevin Harris Â 1984 Partners in Crime (TV Series) Harry Â 1983 Through Naked Eyes (TV Movie) William Parrish Â 1982 World War III (TV Movie) Col. Jake Caffey Â 1980 Homeward Bound (TV Movie) Jake Seaton Â 1980 Swan Song (TV Movie) Jesse Swan Â 1974 Medical Center (TV Series) Walter Â 1974 McMillan & Wife (TV Series) Jerry Â 1974 The Rookies (TV Series) Johnny Dane Â 1973 Circle of Fear (TV Series) James Barlow Â 1972 The F.B.I. (TV Series) Clifford Wade Â 1972 Movin' On (TV Movie) Jeff Â 1971 Dan August (TV Series) Lawrence Merrill III Â 1967 Star Trek (TV Series) Makora Â 2016 The Conjuring 2 (performer: \"Don't Give Up On Us\") Â 2013/I Filth (performer: \"Silver Lady\") Â 2011 Johnny English Reborn (courtesy: \"Don't Give Up On Us\") / (performer: \"Don't Give Up On Us\") Â 2010 Rabbit Hole (performer: \"Don't Give Up On Us\") Â 2007 The Hitcher (performer: \"Don't Give Up on Us\") Â 1977-1978 Top of the Pops (TV Series) (performer - 17 episodes) - Episode dated 22 June 1978 (1978) ... (performer: \"It Sure Brings Out the Love in Your Eyes\") - Episode dated 8 June 1978 (1978) ... (performer: \"It Sure Brings Out the Love in Your Eyes\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('example', i)\n",
    "    print('query', dataset['train'][i]['query'])\n",
    "    print('answer', dataset['train'][i]['answer'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Splitting\n",
    "\n",
    "You might have noticed that the dataset is not split into subsets (it contains only the `train` subset). To maintain the good practice of working with ML, we should have three datasets: `train`, `validation`, and `test`. The code below splits our dataset into those three subsets. We set the size of both the `validation` and `test` sets as 10,000 and keep the rest in the `train` subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 53346\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=10_000)\n",
    "valid_dataset = dataset['test']\n",
    "dataset = dataset['train'].train_test_split(test_size=10_000)\n",
    "dataset['validation'] = valid_dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleaning\n",
    "\n",
    "Let's write the function to clean the text. It can be similar to the one from the previous lab (Lab1) but make sure that it makes sense for this dataset and task.\n",
    "\n",
    "More specifically, think about lower-casing, punctuation, stop-words and lemmatization/stemming and the impact it might have on the dataset. Also reflect on the fact that with word embeddings we want to uncover semantic relationships between words, whereas with bag-of-words we were trying to capture different morphological variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e1'></a>\n",
    "#### Exercise 1: Clean function\n",
    "Fill in the following function to clean the dataset. Implement at least 6 different steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the clean function:\n",
      "Original: Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Cleaned: american-born sinclair won nobel prize literature 1930\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Cleans the text\n",
    "    Args:\n",
    "        text: a string that will be cleaned\n",
    "\n",
    "    Returns: the cleaned text\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Empty text\n",
    "    if text == '':\n",
    "        return text\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    stop_words = set(['a', 'an', 'the', 'and', 'or', 'but', 'in', 'on', 'for', 'of', 'to', 'with', 'at', 'by', 'from', 'what', 'which', 'why', 'when', 'how'])\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "\n",
    "    # collapses and adds one white space before and one after for each punctutaion/parenthesis character\n",
    "    text = re.sub(r'\\s*([()\\[\\]{}.,;:!?])\\s*', r' \\1 ', text)\n",
    "    # remove trailing punctuation tokens like \"?\" and other hyphens not inside words\n",
    "    text = re.sub(r'(?<!\\w)-|-(?!\\w)', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "\n",
    "    # replaces multiple whitespaces with a single one\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # removing comma between numbers\n",
    "    text = re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "\n",
    "    # removing multiple characters\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    text = text.strip()\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "sentence = 'Which American-born Sinclair won the Nobel Prize for Literature in 1930?'\n",
    "print('Testing the clean function:')\n",
    "print('Original:', sentence)\n",
    "print('Cleaned:', clean(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will apply the function you just wrote to the whole dataset. More specifically, it takes the `query` and `answer` fields, applies the `clean` function and saves the processed sentences back to the `query` and `answer` fields. This will override the original fields. If you want to have access to them, you can make a copy in separate fields before cleaning. As in the last lab, we will use the `map()` method of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d528baecf246487a95d8b86f656fe95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning queries and answers:   0%|          | 0/53346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5318bac1cead42b99707ec8215e30e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning queries and answers:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc30fe9eada4057bf9d036364136f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning queries and answers:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 53346\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def clean_example(example):\n",
    "    \"\"\"\n",
    "    Applies the clean() function to the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: update example with cleaned 'query' and 'answer' columns\n",
    "\n",
    "    \"\"\"\n",
    "    example['original_query'] = example['query']\n",
    "    example['original_answer'] = example['answer']\n",
    "\n",
    "    example['query'] = clean(example['query'])\n",
    "    example['answer'] = clean(example['answer'])\n",
    "    return example\n",
    "\n",
    "\n",
    "dataset = dataset.map(clean_example, desc=\"Cleaning queries and answers\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine some examples from the dataset and make sure that we got the results we wanted. At this step, it might be necessary to revisit some pre-processing steps if you are not happy with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 0\n",
      "query river is high force waterfall\n",
      "answer high force discover force nature call us 01833 622209 email us highforcerabycastle com content slider welcome high force discover force nature high force one most spectacular waterfalls england located forest-in-teesdale heart durham dales co durham experience its rise as trickle high heather covered fells top north pennines top whin sill rock forest-in-teesdale river tees steadily grows gathers pace then it suddenly spectacularly drops 21 metres into plunge pool below gentle pretty woodland walk leads you view this spectacular sight base falls high force is surrounded stunning countryside upper teesdale is situated north pennines area outstanding natural beauty variety animal plant life can be seen high force throughout seasons vast array wildflowers ferns towering trees roe deer rabbits high force is sight behold along well-maintained picturesque car park picnic area walkers can set off along many way marked routes lavatories gift shop it makes ideal place stop picnic base exploring teesdale north pennines car bike foot\n",
      "\n",
      "example 1\n",
      "query leffe beer company was founded is headquartered\n",
      "answer leffe blond phil lowry phil lowry leffe blond leffe blond uk leffe is beer brand owned inbev belgium european operating arm global anheuserbusch inbev brewery giant there are several beers range they are marketed as abbey beers they are brewed large quantities are widely distributed history image via wikipedia abbey notre dame de leffe was founded 1152 meuse river province namur southern belgium like many monasteries across europe premonstratensian norbertine canons abbey brewed ale using knowledge passed generation generation ingredients found wild near abbey canons developed unique ale brewed only abbey abbey itself has known hard times has been damaged both natural human circumstances over years 1460 abbey was destroyed flood fire swept through settlement 1466 1735 billeted troops damaged brewery 1794 outbreak french revolution resulted abbey being deserted brewery destroyed canons returned 1902 1952 production beer was continued after partnership flemish based lootvoet brewery overijse this brewery was later bought international beer company interbrew now inbev leffe was then brewed mont-saint-guibert until interbrew closed that brewery now all leffe brands are brewed stella artois brewery leuven 1952 agreement between leffe abbey commercial brewery is said have been first its kind royalties continue be paid abbey today belgiums beer category called abbey is thriving several beers brewed under similar licenses leffe as well as abbey beers named after abbey ruins abbeys that no longer exist affligem grimbergen beers are part heinekens international portfolio other notable abbey brands include corsendonk leffe museum town dinant is open visitors image via wikipedia abinbev leffe makes extraordinary just perfect bringing people together share savor special moments leffe family beers are rich full bodied made only highest quality ingredients they provide recipe rich moments life that deserve be savored leffes unique brewing heritage is n ow shared enjoyed consumers more than 60 countries worldwide while sharing leffe consumers savor true moments indulgence designed real beer lovers leffe is be savored there is time relax enjoy deep complex flavors wrought centuries-old brewing tradition brand is available four varieties blonde brown triple radieusevieille cuvÃ©e each these unique brews is made craftsmen who rely hundreds years brewing competence tradition make drink that offers perfect moment indulgence each one has its own character treats enjoy different occasions leffe blond dry fruity lightly spiced beer full creamy perfect balance strength subtlety brand has delicate light malty aroma subtle sweet finish leffe blonde is perfect accompaniment light everyday meals leffe blond is available belgian beer importers cavedirect buy leffe blond online leffe brown leffe brown is substantially more robust than leffe blonde this rich variety combines rich aroma roasted caramel slightly sweet finish it is excellent accompaniment hearty sweet savory types cuisine buy leffe brun online leffe triple leffe triple is stronger beer full aftertaste spicy coriander orange leffe triple is excellent replacement any robust full-flavored white wine image via wikipedia leffe radieusevieille cuvÃ©e leffe radieusevieille cuvÃ©e combines very complex taste pallet fruity flavors banana citrus fruit coriander cloves mild sharpness it is beer drink instead complex wines\n",
      "\n",
      "example 2\n",
      "query american-born engineer invented first portable fully automatic machine gun\n",
      "answer machine gun machine gun inventors edubilla com weapons about invention machine gun is fully automatic mounted portable firearm usually designed fire bullets quick succession ammunition belt magazine typically rate three eighteen hundred rounds per minute fully automatic weapons are generally categorized as submachine guns machine guns autocannons submachine guns are hand-held automatic weapons personal defense short-range combat firing pistol-caliber rounds machine gun is often portable certain degree is generally used attached mount fired ground bipod tripod generally fires rifle cartridge is capable sustained fire light machine guns are small enough be fired hand-held are more effective fired prone position difference between machine guns autocannons is based caliber autocannons using calibers larger than 16 mm whether gun fires conventional bullets explosive rounds guns firing large-caliber explosive rounds are generally considered either autocannons automatic grenade launchers grenade machine guns contrast submachine guns autocannons machine guns like rifles tend have very high ratio barrel length caliber long barrel small caliber indeed true machine gun is essentially fully automatic rifle often primary criterion machine gun as opposed automatic rifle is presence quick-change barrel other cooling system automatic rifles more commonly assault rifles may be capable fully automatic fire are not designed sustained fire united states gun law machine gun is technical term any fully automatic firearm also any component part that will modify existing firearm such that it functions as fully automatic firearm history it would not be until mid-19th century that successful machine-gun designs came into existence key characteristic modern machine guns their relatively high rate fire more importantly machine automatic loading came model 1862 gatling gun was adopted united states navy these weapons were still powered hand however this changed hiram maxims idea harnessing recoil energy power reloading his maxim machine gun dr gatling also experimented electric-motor-powered models this externally powered machine reloading has seen use modern weapons as well vandenburg miltrailleuse volley organ gun concepts have been revived partially early 21st century form electronically controlled multibarreled volley guns it is important note that exactly constitutes machine gun whether volley guns are type machine gun extent some earlier types devices are considered be like machine guns is matter debate many cases can vary depending language exact definition is used early rapid-firing weapons first known ancestors multi-shot weapons were early revolvers made europe late 1500s one is shoulder-gun-length weapon made nuremberg germany circa 1580 another is revolving arquebus produced hans stopler nuremberg 1597 another large early repeating was created james puckle london lawyer who patented he called puckle gun may 15 1718 it was design 1 25 4 mm caliber flintlock revolver cannon able fire 9 rounds before reloading intended use ships according puckle it was able fire round bullets christians square bullets turks while ahead its time foreshadowing designs revolvers it was not adopted produced 1777 philadelphia gunsmith joseph belton offered continental congress new improved gun was capable firing up twenty shots five seconds automatically was capable being loaded cartridge congress requested that belton modify 100 flintlock muske\n",
      "\n",
      "example 3\n",
      "query american president used slogan its morning again america his presidential campaign\n",
      "answer presidential-project ronald reagan presidential-project president ronald reagan was member republican party path president reagan became governor california 1967 he also was re-elected governor 1970 reagans ran republican partys nomination president 1976 lost incumbent president gerald ford then 1980 reagan made successful bid republican nomination was subsequently re-elected president second term he was president 1981-1989 campaign sloganplatform ronald reagan had two different campaign slogans his first one he used during his campaign 1980 was are you better off than you were four years ago his second campaign slogan its morning again america was used his 1984 campaign reagans campaign platform was stimulate economy lowering taxes have government interfere less peoples lives states rights strong national defense election results ronald reagan was elected president 1981 then second time 1985 results after his election were considered landslide election 1981 were as follows he received 50 8 popular vote jimmy carter having 41 his number electoral college votes was 489 out 538 carter took other 69 votes reagans results after his 1985 election were he had 58 8 popular vote walter mondale having 40 5 his number electoral college votes was 525 out 538 this election was another even larger landslide reagan 1981 electoral votes country issues reagan faced many international issues during his presidency here are two president ronald reagan citing threat posed american nationals caribbean nation grenada that nations marxist regime orders marines invade secure their safety there were nearly 1 000 americans grenada time many them students islands medical school little more than week grenadas government was overthrown situation grenada had been concern american officials since 1979 leftist maurice bishop seized power began develop close relations cuba 1983 another marxist bernard coard had bishop assassinated took control government protesters clashed new government violence escalated citing danger u s citizens grenada reagan ordered nearly 2 000 u s troops into island where they soon found themselves facing opposition grenadan armed forces groups cuban military engineers grenada repair expand islands airport matters were not helped fact that u s forces had rely minimal intelligence about situation maps used many them were fact old tourist maps island reagan ordered more troops time fighting was done nearly 6 000 u s troops were grenada nearly 20 these troops were killed over hundred wounded over 60 grenadan cuban troops were killed coards government collapsed was replaced one acceptable united states afterwards reagan withdrew american forces 1986 u s launched several airstrikes number targets libya attacks were supposed stop muammar gaddafi leader libya aiding terrorists intel found showed qdoba as providing bomb that terrorists used milan injuring 63 u s citizens after attacks were carried out reagan addressed nation oval office he said our citizens are attacked abused anywhere world direct orders hostile regimes we will respond so long as im this office domestic issues reagan also faced numerous domestic issues during his presidency here are two august 1981 u s air traffic controllers went strike going strike they violated federal regulation prohibiting government unions striking as well as became threat americas economy bringing air travel halt reagan gave air traffic contro\n",
      "\n",
      "example 4\n",
      "query was hosted seattle 1962 new york city 1964 montreal 1967\n",
      "answer century 21 1962 seattle worlds fair part 1 historylink org century 21 1962 seattle worlds fair part 1 alan j stein tweet 1962 seattle worlds fair otherwise known as century 21 gave visitors glimpse future left seattle lasting legacy exposition gave seattle world-wide recognition effectively putting it map years planning went into fair through hard work visionaries go-getters civic boosters dreamers many concepts icons century 21 remain ingrained seattle culture even as real 21st century begins seattles first worlds fair 1962 seattle worlds fair had its beginnings earlier fair that was held university washington campus 1909 alaska-yukon-pacific exposition a-y-p commemorated first shipment klondike gold through seattle 1897 a-y-p its exhibits rides food fun attracted more than 3 5 million visitors around world giving seattle much-needed prominence attention as leader pacific trade one attendees fair was 14-year-old al rochester whose family lived near volunteer park capitol hill young rochester operated bread-slicer tearoom run his sunday school teacher concession stand went broke within week this left al employees pass that got him into expo free every day fair he showed up gates flashed his pass had free rein roam fairgrounds wonders exposition left lasting memory his mind al remembers 1955 al rochester 1895-1989 had come age was now seattle city councilman remembering successes joys a-y-p he began bandying about idea second worlds fair commemorate first was met mixed response one day informal luncheon washington athletic club don follett executive vice-president chamber commerce took interest als idea also luncheon were denny givens chambers director public affairs ross cunningham editor seattle times they too expressed interest buoyed this support rochester began follow through earnest within short time memorial was drafted that asked state legislature consider supporting new worlds fair that would celebrate 50th anniversary a-y-p before al knew it bill was drafted olympia calling 5 000 form worlds fair commission there things steamrolled enter eddie carlson original worlds fair commission empanelled 1955 state senators willam goodloe andrew winberg state representatives ray olsen donald mcdermott community leaders eddie carlson paul sceva alfred williams commission was expanded 15 members 1961 included lt governor john cherberg former u s senator clarence c dill 1884-1978 state senators howard bargreen herbert h freise michael j gallagher reuben knoblauch state representatives audley f mahaffey ray olsen leonard sawyer jeanette testu seattle city councilman future mayor dorm braman 1901-1980 business community leaders paul s friedlander h dewayne kraeger victor rosellini 1915-2003 al rochester served as executive director western hotels vice president eddie carlson 1911-1990 served as chairman carlson well known 7 m businessmans working breakfasts could best be described as go-getter doer mover shaker he would bring these traits more table duncan pp 21 40 1959 50th anniversary a-y-p too near commission pushed fair date out few years 1909 a-y-p itself had been delayed two years 10th anniversary klondike gold rush was actually 1907 giving commission bit historical precedent besides few more years would allow them plan event better begin they needed choose site fairgrounds early\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('example', i)\n",
    "    print('query', dataset['train'][i]['query'])\n",
    "    print('answer', dataset['train'][i]['answer'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extracting answers\n",
    "\n",
    "Because the answers in our dataset are not unique, we will extract them and create a separate dataset containing only the unique answers. We will do this for each split separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_answers(subset):\n",
    "    \"\"\"\n",
    "    Extracts unique answers from the subset of the dataset and builds a dictionary with answers as keys and ids as values.\n",
    "    Args:\n",
    "        subset: a subset of the dataset\n",
    "\n",
    "    Returns: a dictionary mapping answers to their ids\n",
    "    \"\"\"\n",
    "    answer_to_id = {}\n",
    "    answers = list(set(subset['answer']))\n",
    "    for i, answer in enumerate(answers):\n",
    "        answer_to_id[answer] = i\n",
    "    return answer_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We apply this function separately to each subset and create the answers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'answer'],\n",
      "        num_rows: 47982\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'answer'],\n",
      "        num_rows: 9702\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'answer'],\n",
      "        num_rows: 9732\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_answer_to_id = get_answers(dataset['train'])\n",
    "valid_answer_to_id = get_answers(dataset['validation'])\n",
    "test_answer_to_id = get_answers(dataset['test'])\n",
    "\n",
    "answers_dataset = DatasetDict({\n",
    "    'train': datasets.Dataset.from_dict({'id': range(len(train_answer_to_id)), 'answer': train_answer_to_id.keys()}),\n",
    "    'validation': datasets.Dataset.from_dict(\n",
    "        {'id': range(len(valid_answer_to_id)), 'answer': valid_answer_to_id.keys()}),\n",
    "    'test': datasets.Dataset.from_dict({'id': range(len(test_answer_to_id)), 'answer': test_answer_to_id.keys()})\n",
    "})\n",
    "print(answers_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last thing we will have to do is to connect the answers in the original dataset to the ids of answers (in the answers dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e2'></a>\n",
    "#### Exercise 2: Setting answer ids\n",
    "Fill in the following function to find and set the `answer_id` field with the id of the answer. The function accepts one of the `answer_to_id` dictionaries that you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_answer_id(example, answer_to_id):\n",
    "    \"\"\"\n",
    "    Sets the answer_id field in the example based on the answer_to_id dictionary\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "        answer_to_id: a dictionary mapping answers to their ids\n",
    "\n",
    "    Returns: the updated example with the 'answer_id' field\n",
    "    \"\"\"\n",
    "    answer = example['answer']\n",
    "    ### YOUR CODE HERE\n",
    "    example['answer_id'] = answer_to_id[answer]\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we apply the function to each split separately making sure to pass the correct `answer_to_id` dictionary. We also remove the `answer` columns from the original dataset, as now we can reference the correct answer through the `answer_id` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b22dfdd505544699314db6cb7f3df79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting ids for answers (train):   0%|          | 0/53346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2ad55a4da14cada2182ed1e223bb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting ids for answers (validation):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbf96198b83428fae7b5fc4b81a819d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting ids for answers (test:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].map(set_answer_id,\n",
    "                                        fn_kwargs={'answer_to_id': train_answer_to_id},\n",
    "                                        desc=\"Setting ids for answers (train)\")\n",
    "dataset['validation'] = dataset['validation'].map(set_answer_id,\n",
    "                                                  fn_kwargs={'answer_to_id': valid_answer_to_id},\n",
    "                                                  desc=\"Setting ids for answers (validation)\")\n",
    "dataset['test'] = dataset['test'].map(set_answer_id,\n",
    "                                      fn_kwargs={'answer_to_id': test_answer_to_id},\n",
    "                                      desc=\"Setting ids for answers (test\")\n",
    "\n",
    "dataset = dataset.remove_columns('answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenizing\n",
    "\n",
    "<a name='e3'></a>\n",
    "#### Exercise 3: Tokenizing\n",
    "As always, we will need to tokenize the dataset in order to create bat-of-words and TF-IDF representations in the next sections. You can use the function from the previous lab or use a library such as [Natural Language Toolkit (NLTK) library]([https://www.nltk.org/]) (https://www.nltk.org/). Complete the following function to split the text into tokens.\n",
    "\n",
    "Contrary to the previous lab, we will not include the special tokens (unknown, beginning, and end of the sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the text that is assumed to be cleaned first with the clean() function. The tokenized sequence should start with the `bos_token` token and end with the 'eos_token'.\n",
    "    Args:\n",
    "        text: a cleaned text\n",
    "\n",
    "    Returns: tokenized text as a list of tokens\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = None  # list of tokens, your code should fill this variable\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    tokens = text.split()\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We apply your function to both the `query` field in the original dataset and `answer` field in the answers dataset. We save the tokenized queries in `query_tokens` field and answers in `answer_tokens` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d474652c19054ba2a9b125d8f2d8be04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing queries:   0%|          | 0/53346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a693a0b268704b99a0315d7a42262543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing queries:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030cd1d6bd7c44a2bc00a8e3f4e829f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing queries:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'original_query', 'original_answer', 'answer_id', 'query_tokens'],\n",
      "        num_rows: 53346\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'original_query', 'original_answer', 'answer_id', 'query_tokens'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['query', 'original_query', 'original_answer', 'answer_id', 'query_tokens'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfe2030f6bf4ae9a9914e5dd6cbd955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing answers:   0%|          | 0/47982 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0994e50f910a44fd90884cabf48be73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing answers:   0%|          | 0/9702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a7da159e7c447cbf0fb35eac6363ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing answers:   0%|          | 0/9732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers_dataset\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'answer', 'answer_tokens'],\n",
      "        num_rows: 47982\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'answer', 'answer_tokens'],\n",
      "        num_rows: 9702\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'answer', 'answer_tokens'],\n",
      "        num_rows: 9732\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_example(example, src_column, tgt_column):\n",
    "    \"\"\"\n",
    "    Applies the tokenize() function to the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: update example containing 'query_tokens' column\n",
    "\n",
    "    \"\"\"\n",
    "    query = example[src_column]\n",
    "    example[tgt_column] = tokenize(query)\n",
    "    return example\n",
    "\n",
    "\n",
    "dataset = dataset.map(tokenize_example,\n",
    "                      fn_kwargs={'src_column': 'query', 'tgt_column': 'query_tokens'},\n",
    "                      desc=\"Tokenizing queries\")\n",
    "print('dataset')\n",
    "print(dataset)\n",
    "\n",
    "answers_dataset = answers_dataset.map(tokenize_example,\n",
    "                                      fn_kwargs={'src_column': 'answer', 'tgt_column': 'answer_tokens'},\n",
    "                                      desc=\"Tokenizing answers\")\n",
    "print('answers_dataset')\n",
    "print(answers_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine some examples of tokenized queries and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: 0\n",
      "query: river is high force waterfall\n",
      "query_tokens: ['river', 'is', 'high', 'force', 'waterfall']\n",
      "answer_id: 3691\n",
      "answer: high force discover force nature call us 01833 622209 email us highforcerabycastle com content slider welcome high force discover force nature high force one most spectacular waterfalls england located forest-in-teesdale heart durham dales co durham experience its rise as trickle high heather covered fells top north pennines top whin sill rock forest-in-teesdale river tees steadily grows gathers pace then it suddenly spectacularly drops 21 metres into plunge pool below gentle pretty woodland walk leads you view this spectacular sight base falls high force is surrounded stunning countryside upper teesdale is situated north pennines area outstanding natural beauty variety animal plant life can be seen high force throughout seasons vast array wildflowers ferns towering trees roe deer rabbits high force is sight behold along well-maintained picturesque car park picnic area walkers can set off along many way marked routes lavatories gift shop it makes ideal place stop picnic base exploring teesdale north pennines car bike foot\n",
      "answer_tokens: ['high', 'force', 'discover', 'force', 'nature', 'call', 'us', '01833', '622209', 'email', 'us', 'highforcerabycastle', 'com', 'content', 'slider', 'welcome', 'high', 'force', 'discover', 'force', 'nature', 'high', 'force', 'one', 'most', 'spectacular', 'waterfalls', 'england', 'located', 'forest-in-teesdale', 'heart', 'durham', 'dales', 'co', 'durham', 'experience', 'its', 'rise', 'as', 'trickle', 'high', 'heather', 'covered', 'fells', 'top', 'north', 'pennines', 'top', 'whin', 'sill', 'rock', 'forest-in-teesdale', 'river', 'tees', 'steadily', 'grows', 'gathers', 'pace', 'then', 'it', 'suddenly', 'spectacularly', 'drops', '21', 'metres', 'into', 'plunge', 'pool', 'below', 'gentle', 'pretty', 'woodland', 'walk', 'leads', 'you', 'view', 'this', 'spectacular', 'sight', 'base', 'falls', 'high', 'force', 'is', 'surrounded', 'stunning', 'countryside', 'upper', 'teesdale', 'is', 'situated', 'north', 'pennines', 'area', 'outstanding', 'natural', 'beauty', 'variety', 'animal', 'plant', 'life', 'can', 'be', 'seen', 'high', 'force', 'throughout', 'seasons', 'vast', 'array', 'wildflowers', 'ferns', 'towering', 'trees', 'roe', 'deer', 'rabbits', 'high', 'force', 'is', 'sight', 'behold', 'along', 'well-maintained', 'picturesque', 'car', 'park', 'picnic', 'area', 'walkers', 'can', 'set', 'off', 'along', 'many', 'way', 'marked', 'routes', 'lavatories', 'gift', 'shop', 'it', 'makes', 'ideal', 'place', 'stop', 'picnic', 'base', 'exploring', 'teesdale', 'north', 'pennines', 'car', 'bike', 'foot']\n",
      "\n",
      "example: 1\n",
      "query: leffe beer company was founded is headquartered\n",
      "query_tokens: ['leffe', 'beer', 'company', 'was', 'founded', 'is', 'headquartered']\n",
      "answer_id: 23067\n",
      "answer: leffe blond phil lowry phil lowry leffe blond leffe blond uk leffe is beer brand owned inbev belgium european operating arm global anheuserbusch inbev brewery giant there are several beers range they are marketed as abbey beers they are brewed large quantities are widely distributed history image via wikipedia abbey notre dame de leffe was founded 1152 meuse river province namur southern belgium like many monasteries across europe premonstratensian norbertine canons abbey brewed ale using knowledge passed generation generation ingredients found wild near abbey canons developed unique ale brewed only abbey abbey itself has known hard times has been damaged both natural human circumstances over years 1460 abbey was destroyed flood fire swept through settlement 1466 1735 billeted troops damaged brewery 1794 outbreak french revolution resulted abbey being deserted brewery destroyed canons returned 1902 1952 production beer was continued after partnership flemish based lootvoet brewery overijse this brewery was later bought international beer company interbrew now inbev leffe was then brewed mont-saint-guibert until interbrew closed that brewery now all leffe brands are brewed stella artois brewery leuven 1952 agreement between leffe abbey commercial brewery is said have been first its kind royalties continue be paid abbey today belgiums beer category called abbey is thriving several beers brewed under similar licenses leffe as well as abbey beers named after abbey ruins abbeys that no longer exist affligem grimbergen beers are part heinekens international portfolio other notable abbey brands include corsendonk leffe museum town dinant is open visitors image via wikipedia abinbev leffe makes extraordinary just perfect bringing people together share savor special moments leffe family beers are rich full bodied made only highest quality ingredients they provide recipe rich moments life that deserve be savored leffes unique brewing heritage is n ow shared enjoyed consumers more than 60 countries worldwide while sharing leffe consumers savor true moments indulgence designed real beer lovers leffe is be savored there is time relax enjoy deep complex flavors wrought centuries-old brewing tradition brand is available four varieties blonde brown triple radieusevieille cuvÃ©e each these unique brews is made craftsmen who rely hundreds years brewing competence tradition make drink that offers perfect moment indulgence each one has its own character treats enjoy different occasions leffe blond dry fruity lightly spiced beer full creamy perfect balance strength subtlety brand has delicate light malty aroma subtle sweet finish leffe blonde is perfect accompaniment light everyday meals leffe blond is available belgian beer importers cavedirect buy leffe blond online leffe brown leffe brown is substantially more robust than leffe blonde this rich variety combines rich aroma roasted caramel slightly sweet finish it is excellent accompaniment hearty sweet savory types cuisine buy leffe brun online leffe triple leffe triple is stronger beer full aftertaste spicy coriander orange leffe triple is excellent replacement any robust full-flavored white wine image via wikipedia leffe radieusevieille cuvÃ©e leffe radieusevieille cuvÃ©e combines very complex taste pallet fruity flavors banana citrus fruit coriander cloves mild sharpness it is beer drink instead complex wines\n",
      "answer_tokens: ['leffe', 'blond', 'phil', 'lowry', 'phil', 'lowry', 'leffe', 'blond', 'leffe', 'blond', 'uk', 'leffe', 'is', 'beer', 'brand', 'owned', 'inbev', 'belgium', 'european', 'operating', 'arm', 'global', 'anheuserbusch', 'inbev', 'brewery', 'giant', 'there', 'are', 'several', 'beers', 'range', 'they', 'are', 'marketed', 'as', 'abbey', 'beers', 'they', 'are', 'brewed', 'large', 'quantities', 'are', 'widely', 'distributed', 'history', 'image', 'via', 'wikipedia', 'abbey', 'notre', 'dame', 'de', 'leffe', 'was', 'founded', '1152', 'meuse', 'river', 'province', 'namur', 'southern', 'belgium', 'like', 'many', 'monasteries', 'across', 'europe', 'premonstratensian', 'norbertine', 'canons', 'abbey', 'brewed', 'ale', 'using', 'knowledge', 'passed', 'generation', 'generation', 'ingredients', 'found', 'wild', 'near', 'abbey', 'canons', 'developed', 'unique', 'ale', 'brewed', 'only', 'abbey', 'abbey', 'itself', 'has', 'known', 'hard', 'times', 'has', 'been', 'damaged', 'both', 'natural', 'human', 'circumstances', 'over', 'years', '1460', 'abbey', 'was', 'destroyed', 'flood', 'fire', 'swept', 'through', 'settlement', '1466', '1735', 'billeted', 'troops', 'damaged', 'brewery', '1794', 'outbreak', 'french', 'revolution', 'resulted', 'abbey', 'being', 'deserted', 'brewery', 'destroyed', 'canons', 'returned', '1902', '1952', 'production', 'beer', 'was', 'continued', 'after', 'partnership', 'flemish', 'based', 'lootvoet', 'brewery', 'overijse', 'this', 'brewery', 'was', 'later', 'bought', 'international', 'beer', 'company', 'interbrew', 'now', 'inbev', 'leffe', 'was', 'then', 'brewed', 'mont-saint-guibert', 'until', 'interbrew', 'closed', 'that', 'brewery', 'now', 'all', 'leffe', 'brands', 'are', 'brewed', 'stella', 'artois', 'brewery', 'leuven', '1952', 'agreement', 'between', 'leffe', 'abbey', 'commercial', 'brewery', 'is', 'said', 'have', 'been', 'first', 'its', 'kind', 'royalties', 'continue', 'be', 'paid', 'abbey', 'today', 'belgiums', 'beer', 'category', 'called', 'abbey', 'is', 'thriving', 'several', 'beers', 'brewed', 'under', 'similar', 'licenses', 'leffe', 'as', 'well', 'as', 'abbey', 'beers', 'named', 'after', 'abbey', 'ruins', 'abbeys', 'that', 'no', 'longer', 'exist', 'affligem', 'grimbergen', 'beers', 'are', 'part', 'heinekens', 'international', 'portfolio', 'other', 'notable', 'abbey', 'brands', 'include', 'corsendonk', 'leffe', 'museum', 'town', 'dinant', 'is', 'open', 'visitors', 'image', 'via', 'wikipedia', 'abinbev', 'leffe', 'makes', 'extraordinary', 'just', 'perfect', 'bringing', 'people', 'together', 'share', 'savor', 'special', 'moments', 'leffe', 'family', 'beers', 'are', 'rich', 'full', 'bodied', 'made', 'only', 'highest', 'quality', 'ingredients', 'they', 'provide', 'recipe', 'rich', 'moments', 'life', 'that', 'deserve', 'be', 'savored', 'leffes', 'unique', 'brewing', 'heritage', 'is', 'n', 'ow', 'shared', 'enjoyed', 'consumers', 'more', 'than', '60', 'countries', 'worldwide', 'while', 'sharing', 'leffe', 'consumers', 'savor', 'true', 'moments', 'indulgence', 'designed', 'real', 'beer', 'lovers', 'leffe', 'is', 'be', 'savored', 'there', 'is', 'time', 'relax', 'enjoy', 'deep', 'complex', 'flavors', 'wrought', 'centuries-old', 'brewing', 'tradition', 'brand', 'is', 'available', 'four', 'varieties', 'blonde', 'brown', 'triple', 'radieusevieille', 'cuvÃ©e', 'each', 'these', 'unique', 'brews', 'is', 'made', 'craftsmen', 'who', 'rely', 'hundreds', 'years', 'brewing', 'competence', 'tradition', 'make', 'drink', 'that', 'offers', 'perfect', 'moment', 'indulgence', 'each', 'one', 'has', 'its', 'own', 'character', 'treats', 'enjoy', 'different', 'occasions', 'leffe', 'blond', 'dry', 'fruity', 'lightly', 'spiced', 'beer', 'full', 'creamy', 'perfect', 'balance', 'strength', 'subtlety', 'brand', 'has', 'delicate', 'light', 'malty', 'aroma', 'subtle', 'sweet', 'finish', 'leffe', 'blonde', 'is', 'perfect', 'accompaniment', 'light', 'everyday', 'meals', 'leffe', 'blond', 'is', 'available', 'belgian', 'beer', 'importers', 'cavedirect', 'buy', 'leffe', 'blond', 'online', 'leffe', 'brown', 'leffe', 'brown', 'is', 'substantially', 'more', 'robust', 'than', 'leffe', 'blonde', 'this', 'rich', 'variety', 'combines', 'rich', 'aroma', 'roasted', 'caramel', 'slightly', 'sweet', 'finish', 'it', 'is', 'excellent', 'accompaniment', 'hearty', 'sweet', 'savory', 'types', 'cuisine', 'buy', 'leffe', 'brun', 'online', 'leffe', 'triple', 'leffe', 'triple', 'is', 'stronger', 'beer', 'full', 'aftertaste', 'spicy', 'coriander', 'orange', 'leffe', 'triple', 'is', 'excellent', 'replacement', 'any', 'robust', 'full-flavored', 'white', 'wine', 'image', 'via', 'wikipedia', 'leffe', 'radieusevieille', 'cuvÃ©e', 'leffe', 'radieusevieille', 'cuvÃ©e', 'combines', 'very', 'complex', 'taste', 'pallet', 'fruity', 'flavors', 'banana', 'citrus', 'fruit', 'coriander', 'cloves', 'mild', 'sharpness', 'it', 'is', 'beer', 'drink', 'instead', 'complex', 'wines']\n",
      "\n",
      "example: 2\n",
      "query: american-born engineer invented first portable fully automatic machine gun\n",
      "query_tokens: ['american-born', 'engineer', 'invented', 'first', 'portable', 'fully', 'automatic', 'machine', 'gun']\n",
      "answer_id: 22960\n",
      "answer: machine gun machine gun inventors edubilla com weapons about invention machine gun is fully automatic mounted portable firearm usually designed fire bullets quick succession ammunition belt magazine typically rate three eighteen hundred rounds per minute fully automatic weapons are generally categorized as submachine guns machine guns autocannons submachine guns are hand-held automatic weapons personal defense short-range combat firing pistol-caliber rounds machine gun is often portable certain degree is generally used attached mount fired ground bipod tripod generally fires rifle cartridge is capable sustained fire light machine guns are small enough be fired hand-held are more effective fired prone position difference between machine guns autocannons is based caliber autocannons using calibers larger than 16 mm whether gun fires conventional bullets explosive rounds guns firing large-caliber explosive rounds are generally considered either autocannons automatic grenade launchers grenade machine guns contrast submachine guns autocannons machine guns like rifles tend have very high ratio barrel length caliber long barrel small caliber indeed true machine gun is essentially fully automatic rifle often primary criterion machine gun as opposed automatic rifle is presence quick-change barrel other cooling system automatic rifles more commonly assault rifles may be capable fully automatic fire are not designed sustained fire united states gun law machine gun is technical term any fully automatic firearm also any component part that will modify existing firearm such that it functions as fully automatic firearm history it would not be until mid-19th century that successful machine-gun designs came into existence key characteristic modern machine guns their relatively high rate fire more importantly machine automatic loading came model 1862 gatling gun was adopted united states navy these weapons were still powered hand however this changed hiram maxims idea harnessing recoil energy power reloading his maxim machine gun dr gatling also experimented electric-motor-powered models this externally powered machine reloading has seen use modern weapons as well vandenburg miltrailleuse volley organ gun concepts have been revived partially early 21st century form electronically controlled multibarreled volley guns it is important note that exactly constitutes machine gun whether volley guns are type machine gun extent some earlier types devices are considered be like machine guns is matter debate many cases can vary depending language exact definition is used early rapid-firing weapons first known ancestors multi-shot weapons were early revolvers made europe late 1500s one is shoulder-gun-length weapon made nuremberg germany circa 1580 another is revolving arquebus produced hans stopler nuremberg 1597 another large early repeating was created james puckle london lawyer who patented he called puckle gun may 15 1718 it was design 1 25 4 mm caliber flintlock revolver cannon able fire 9 rounds before reloading intended use ships according puckle it was able fire round bullets christians square bullets turks while ahead its time foreshadowing designs revolvers it was not adopted produced 1777 philadelphia gunsmith joseph belton offered continental congress new improved gun was capable firing up twenty shots five seconds automatically was capable being loaded cartridge congress requested that belton modify 100 flintlock muske\n",
      "answer_tokens: ['machine', 'gun', 'machine', 'gun', 'inventors', 'edubilla', 'com', 'weapons', 'about', 'invention', 'machine', 'gun', 'is', 'fully', 'automatic', 'mounted', 'portable', 'firearm', 'usually', 'designed', 'fire', 'bullets', 'quick', 'succession', 'ammunition', 'belt', 'magazine', 'typically', 'rate', 'three', 'eighteen', 'hundred', 'rounds', 'per', 'minute', 'fully', 'automatic', 'weapons', 'are', 'generally', 'categorized', 'as', 'submachine', 'guns', 'machine', 'guns', 'autocannons', 'submachine', 'guns', 'are', 'hand-held', 'automatic', 'weapons', 'personal', 'defense', 'short-range', 'combat', 'firing', 'pistol-caliber', 'rounds', 'machine', 'gun', 'is', 'often', 'portable', 'certain', 'degree', 'is', 'generally', 'used', 'attached', 'mount', 'fired', 'ground', 'bipod', 'tripod', 'generally', 'fires', 'rifle', 'cartridge', 'is', 'capable', 'sustained', 'fire', 'light', 'machine', 'guns', 'are', 'small', 'enough', 'be', 'fired', 'hand-held', 'are', 'more', 'effective', 'fired', 'prone', 'position', 'difference', 'between', 'machine', 'guns', 'autocannons', 'is', 'based', 'caliber', 'autocannons', 'using', 'calibers', 'larger', 'than', '16', 'mm', 'whether', 'gun', 'fires', 'conventional', 'bullets', 'explosive', 'rounds', 'guns', 'firing', 'large-caliber', 'explosive', 'rounds', 'are', 'generally', 'considered', 'either', 'autocannons', 'automatic', 'grenade', 'launchers', 'grenade', 'machine', 'guns', 'contrast', 'submachine', 'guns', 'autocannons', 'machine', 'guns', 'like', 'rifles', 'tend', 'have', 'very', 'high', 'ratio', 'barrel', 'length', 'caliber', 'long', 'barrel', 'small', 'caliber', 'indeed', 'true', 'machine', 'gun', 'is', 'essentially', 'fully', 'automatic', 'rifle', 'often', 'primary', 'criterion', 'machine', 'gun', 'as', 'opposed', 'automatic', 'rifle', 'is', 'presence', 'quick-change', 'barrel', 'other', 'cooling', 'system', 'automatic', 'rifles', 'more', 'commonly', 'assault', 'rifles', 'may', 'be', 'capable', 'fully', 'automatic', 'fire', 'are', 'not', 'designed', 'sustained', 'fire', 'united', 'states', 'gun', 'law', 'machine', 'gun', 'is', 'technical', 'term', 'any', 'fully', 'automatic', 'firearm', 'also', 'any', 'component', 'part', 'that', 'will', 'modify', 'existing', 'firearm', 'such', 'that', 'it', 'functions', 'as', 'fully', 'automatic', 'firearm', 'history', 'it', 'would', 'not', 'be', 'until', 'mid-19th', 'century', 'that', 'successful', 'machine-gun', 'designs', 'came', 'into', 'existence', 'key', 'characteristic', 'modern', 'machine', 'guns', 'their', 'relatively', 'high', 'rate', 'fire', 'more', 'importantly', 'machine', 'automatic', 'loading', 'came', 'model', '1862', 'gatling', 'gun', 'was', 'adopted', 'united', 'states', 'navy', 'these', 'weapons', 'were', 'still', 'powered', 'hand', 'however', 'this', 'changed', 'hiram', 'maxims', 'idea', 'harnessing', 'recoil', 'energy', 'power', 'reloading', 'his', 'maxim', 'machine', 'gun', 'dr', 'gatling', 'also', 'experimented', 'electric-motor-powered', 'models', 'this', 'externally', 'powered', 'machine', 'reloading', 'has', 'seen', 'use', 'modern', 'weapons', 'as', 'well', 'vandenburg', 'miltrailleuse', 'volley', 'organ', 'gun', 'concepts', 'have', 'been', 'revived', 'partially', 'early', '21st', 'century', 'form', 'electronically', 'controlled', 'multibarreled', 'volley', 'guns', 'it', 'is', 'important', 'note', 'that', 'exactly', 'constitutes', 'machine', 'gun', 'whether', 'volley', 'guns', 'are', 'type', 'machine', 'gun', 'extent', 'some', 'earlier', 'types', 'devices', 'are', 'considered', 'be', 'like', 'machine', 'guns', 'is', 'matter', 'debate', 'many', 'cases', 'can', 'vary', 'depending', 'language', 'exact', 'definition', 'is', 'used', 'early', 'rapid-firing', 'weapons', 'first', 'known', 'ancestors', 'multi-shot', 'weapons', 'were', 'early', 'revolvers', 'made', 'europe', 'late', '1500s', 'one', 'is', 'shoulder-gun-length', 'weapon', 'made', 'nuremberg', 'germany', 'circa', '1580', 'another', 'is', 'revolving', 'arquebus', 'produced', 'hans', 'stopler', 'nuremberg', '1597', 'another', 'large', 'early', 'repeating', 'was', 'created', 'james', 'puckle', 'london', 'lawyer', 'who', 'patented', 'he', 'called', 'puckle', 'gun', 'may', '15', '1718', 'it', 'was', 'design', '1', '25', '4', 'mm', 'caliber', 'flintlock', 'revolver', 'cannon', 'able', 'fire', '9', 'rounds', 'before', 'reloading', 'intended', 'use', 'ships', 'according', 'puckle', 'it', 'was', 'able', 'fire', 'round', 'bullets', 'christians', 'square', 'bullets', 'turks', 'while', 'ahead', 'its', 'time', 'foreshadowing', 'designs', 'revolvers', 'it', 'was', 'not', 'adopted', 'produced', '1777', 'philadelphia', 'gunsmith', 'joseph', 'belton', 'offered', 'continental', 'congress', 'new', 'improved', 'gun', 'was', 'capable', 'firing', 'up', 'twenty', 'shots', 'five', 'seconds', 'automatically', 'was', 'capable', 'being', 'loaded', 'cartridge', 'congress', 'requested', 'that', 'belton', 'modify', '100', 'flintlock', 'muske']\n",
      "\n",
      "example: 3\n",
      "query: american president used slogan its morning again america his presidential campaign\n",
      "query_tokens: ['american', 'president', 'used', 'slogan', 'its', 'morning', 'again', 'america', 'his', 'presidential', 'campaign']\n",
      "answer_id: 15517\n",
      "answer: presidential-project ronald reagan presidential-project president ronald reagan was member republican party path president reagan became governor california 1967 he also was re-elected governor 1970 reagans ran republican partys nomination president 1976 lost incumbent president gerald ford then 1980 reagan made successful bid republican nomination was subsequently re-elected president second term he was president 1981-1989 campaign sloganplatform ronald reagan had two different campaign slogans his first one he used during his campaign 1980 was are you better off than you were four years ago his second campaign slogan its morning again america was used his 1984 campaign reagans campaign platform was stimulate economy lowering taxes have government interfere less peoples lives states rights strong national defense election results ronald reagan was elected president 1981 then second time 1985 results after his election were considered landslide election 1981 were as follows he received 50 8 popular vote jimmy carter having 41 his number electoral college votes was 489 out 538 carter took other 69 votes reagans results after his 1985 election were he had 58 8 popular vote walter mondale having 40 5 his number electoral college votes was 525 out 538 this election was another even larger landslide reagan 1981 electoral votes country issues reagan faced many international issues during his presidency here are two president ronald reagan citing threat posed american nationals caribbean nation grenada that nations marxist regime orders marines invade secure their safety there were nearly 1 000 americans grenada time many them students islands medical school little more than week grenadas government was overthrown situation grenada had been concern american officials since 1979 leftist maurice bishop seized power began develop close relations cuba 1983 another marxist bernard coard had bishop assassinated took control government protesters clashed new government violence escalated citing danger u s citizens grenada reagan ordered nearly 2 000 u s troops into island where they soon found themselves facing opposition grenadan armed forces groups cuban military engineers grenada repair expand islands airport matters were not helped fact that u s forces had rely minimal intelligence about situation maps used many them were fact old tourist maps island reagan ordered more troops time fighting was done nearly 6 000 u s troops were grenada nearly 20 these troops were killed over hundred wounded over 60 grenadan cuban troops were killed coards government collapsed was replaced one acceptable united states afterwards reagan withdrew american forces 1986 u s launched several airstrikes number targets libya attacks were supposed stop muammar gaddafi leader libya aiding terrorists intel found showed qdoba as providing bomb that terrorists used milan injuring 63 u s citizens after attacks were carried out reagan addressed nation oval office he said our citizens are attacked abused anywhere world direct orders hostile regimes we will respond so long as im this office domestic issues reagan also faced numerous domestic issues during his presidency here are two august 1981 u s air traffic controllers went strike going strike they violated federal regulation prohibiting government unions striking as well as became threat americas economy bringing air travel halt reagan gave air traffic contro\n",
      "answer_tokens: ['presidential-project', 'ronald', 'reagan', 'presidential-project', 'president', 'ronald', 'reagan', 'was', 'member', 'republican', 'party', 'path', 'president', 'reagan', 'became', 'governor', 'california', '1967', 'he', 'also', 'was', 're-elected', 'governor', '1970', 'reagans', 'ran', 'republican', 'partys', 'nomination', 'president', '1976', 'lost', 'incumbent', 'president', 'gerald', 'ford', 'then', '1980', 'reagan', 'made', 'successful', 'bid', 'republican', 'nomination', 'was', 'subsequently', 're-elected', 'president', 'second', 'term', 'he', 'was', 'president', '1981-1989', 'campaign', 'sloganplatform', 'ronald', 'reagan', 'had', 'two', 'different', 'campaign', 'slogans', 'his', 'first', 'one', 'he', 'used', 'during', 'his', 'campaign', '1980', 'was', 'are', 'you', 'better', 'off', 'than', 'you', 'were', 'four', 'years', 'ago', 'his', 'second', 'campaign', 'slogan', 'its', 'morning', 'again', 'america', 'was', 'used', 'his', '1984', 'campaign', 'reagans', 'campaign', 'platform', 'was', 'stimulate', 'economy', 'lowering', 'taxes', 'have', 'government', 'interfere', 'less', 'peoples', 'lives', 'states', 'rights', 'strong', 'national', 'defense', 'election', 'results', 'ronald', 'reagan', 'was', 'elected', 'president', '1981', 'then', 'second', 'time', '1985', 'results', 'after', 'his', 'election', 'were', 'considered', 'landslide', 'election', '1981', 'were', 'as', 'follows', 'he', 'received', '50', '8', 'popular', 'vote', 'jimmy', 'carter', 'having', '41', 'his', 'number', 'electoral', 'college', 'votes', 'was', '489', 'out', '538', 'carter', 'took', 'other', '69', 'votes', 'reagans', 'results', 'after', 'his', '1985', 'election', 'were', 'he', 'had', '58', '8', 'popular', 'vote', 'walter', 'mondale', 'having', '40', '5', 'his', 'number', 'electoral', 'college', 'votes', 'was', '525', 'out', '538', 'this', 'election', 'was', 'another', 'even', 'larger', 'landslide', 'reagan', '1981', 'electoral', 'votes', 'country', 'issues', 'reagan', 'faced', 'many', 'international', 'issues', 'during', 'his', 'presidency', 'here', 'are', 'two', 'president', 'ronald', 'reagan', 'citing', 'threat', 'posed', 'american', 'nationals', 'caribbean', 'nation', 'grenada', 'that', 'nations', 'marxist', 'regime', 'orders', 'marines', 'invade', 'secure', 'their', 'safety', 'there', 'were', 'nearly', '1', '000', 'americans', 'grenada', 'time', 'many', 'them', 'students', 'islands', 'medical', 'school', 'little', 'more', 'than', 'week', 'grenadas', 'government', 'was', 'overthrown', 'situation', 'grenada', 'had', 'been', 'concern', 'american', 'officials', 'since', '1979', 'leftist', 'maurice', 'bishop', 'seized', 'power', 'began', 'develop', 'close', 'relations', 'cuba', '1983', 'another', 'marxist', 'bernard', 'coard', 'had', 'bishop', 'assassinated', 'took', 'control', 'government', 'protesters', 'clashed', 'new', 'government', 'violence', 'escalated', 'citing', 'danger', 'u', 's', 'citizens', 'grenada', 'reagan', 'ordered', 'nearly', '2', '000', 'u', 's', 'troops', 'into', 'island', 'where', 'they', 'soon', 'found', 'themselves', 'facing', 'opposition', 'grenadan', 'armed', 'forces', 'groups', 'cuban', 'military', 'engineers', 'grenada', 'repair', 'expand', 'islands', 'airport', 'matters', 'were', 'not', 'helped', 'fact', 'that', 'u', 's', 'forces', 'had', 'rely', 'minimal', 'intelligence', 'about', 'situation', 'maps', 'used', 'many', 'them', 'were', 'fact', 'old', 'tourist', 'maps', 'island', 'reagan', 'ordered', 'more', 'troops', 'time', 'fighting', 'was', 'done', 'nearly', '6', '000', 'u', 's', 'troops', 'were', 'grenada', 'nearly', '20', 'these', 'troops', 'were', 'killed', 'over', 'hundred', 'wounded', 'over', '60', 'grenadan', 'cuban', 'troops', 'were', 'killed', 'coards', 'government', 'collapsed', 'was', 'replaced', 'one', 'acceptable', 'united', 'states', 'afterwards', 'reagan', 'withdrew', 'american', 'forces', '1986', 'u', 's', 'launched', 'several', 'airstrikes', 'number', 'targets', 'libya', 'attacks', 'were', 'supposed', 'stop', 'muammar', 'gaddafi', 'leader', 'libya', 'aiding', 'terrorists', 'intel', 'found', 'showed', 'qdoba', 'as', 'providing', 'bomb', 'that', 'terrorists', 'used', 'milan', 'injuring', '63', 'u', 's', 'citizens', 'after', 'attacks', 'were', 'carried', 'out', 'reagan', 'addressed', 'nation', 'oval', 'office', 'he', 'said', 'our', 'citizens', 'are', 'attacked', 'abused', 'anywhere', 'world', 'direct', 'orders', 'hostile', 'regimes', 'we', 'will', 'respond', 'so', 'long', 'as', 'im', 'this', 'office', 'domestic', 'issues', 'reagan', 'also', 'faced', 'numerous', 'domestic', 'issues', 'during', 'his', 'presidency', 'here', 'are', 'two', 'august', '1981', 'u', 's', 'air', 'traffic', 'controllers', 'went', 'strike', 'going', 'strike', 'they', 'violated', 'federal', 'regulation', 'prohibiting', 'government', 'unions', 'striking', 'as', 'well', 'as', 'became', 'threat', 'americas', 'economy', 'bringing', 'air', 'travel', 'halt', 'reagan', 'gave', 'air', 'traffic', 'contro']\n",
      "\n",
      "example: 4\n",
      "query: was hosted seattle 1962 new york city 1964 montreal 1967\n",
      "query_tokens: ['was', 'hosted', 'seattle', '1962', 'new', 'york', 'city', '1964', 'montreal', '1967']\n",
      "answer_id: 40516\n",
      "answer: century 21 1962 seattle worlds fair part 1 historylink org century 21 1962 seattle worlds fair part 1 alan j stein tweet 1962 seattle worlds fair otherwise known as century 21 gave visitors glimpse future left seattle lasting legacy exposition gave seattle world-wide recognition effectively putting it map years planning went into fair through hard work visionaries go-getters civic boosters dreamers many concepts icons century 21 remain ingrained seattle culture even as real 21st century begins seattles first worlds fair 1962 seattle worlds fair had its beginnings earlier fair that was held university washington campus 1909 alaska-yukon-pacific exposition a-y-p commemorated first shipment klondike gold through seattle 1897 a-y-p its exhibits rides food fun attracted more than 3 5 million visitors around world giving seattle much-needed prominence attention as leader pacific trade one attendees fair was 14-year-old al rochester whose family lived near volunteer park capitol hill young rochester operated bread-slicer tearoom run his sunday school teacher concession stand went broke within week this left al employees pass that got him into expo free every day fair he showed up gates flashed his pass had free rein roam fairgrounds wonders exposition left lasting memory his mind al remembers 1955 al rochester 1895-1989 had come age was now seattle city councilman remembering successes joys a-y-p he began bandying about idea second worlds fair commemorate first was met mixed response one day informal luncheon washington athletic club don follett executive vice-president chamber commerce took interest als idea also luncheon were denny givens chambers director public affairs ross cunningham editor seattle times they too expressed interest buoyed this support rochester began follow through earnest within short time memorial was drafted that asked state legislature consider supporting new worlds fair that would celebrate 50th anniversary a-y-p before al knew it bill was drafted olympia calling 5 000 form worlds fair commission there things steamrolled enter eddie carlson original worlds fair commission empanelled 1955 state senators willam goodloe andrew winberg state representatives ray olsen donald mcdermott community leaders eddie carlson paul sceva alfred williams commission was expanded 15 members 1961 included lt governor john cherberg former u s senator clarence c dill 1884-1978 state senators howard bargreen herbert h freise michael j gallagher reuben knoblauch state representatives audley f mahaffey ray olsen leonard sawyer jeanette testu seattle city councilman future mayor dorm braman 1901-1980 business community leaders paul s friedlander h dewayne kraeger victor rosellini 1915-2003 al rochester served as executive director western hotels vice president eddie carlson 1911-1990 served as chairman carlson well known 7 m businessmans working breakfasts could best be described as go-getter doer mover shaker he would bring these traits more table duncan pp 21 40 1959 50th anniversary a-y-p too near commission pushed fair date out few years 1909 a-y-p itself had been delayed two years 10th anniversary klondike gold rush was actually 1907 giving commission bit historical precedent besides few more years would allow them plan event better begin they needed choose site fairgrounds early\n",
      "answer_tokens: ['century', '21', '1962', 'seattle', 'worlds', 'fair', 'part', '1', 'historylink', 'org', 'century', '21', '1962', 'seattle', 'worlds', 'fair', 'part', '1', 'alan', 'j', 'stein', 'tweet', '1962', 'seattle', 'worlds', 'fair', 'otherwise', 'known', 'as', 'century', '21', 'gave', 'visitors', 'glimpse', 'future', 'left', 'seattle', 'lasting', 'legacy', 'exposition', 'gave', 'seattle', 'world-wide', 'recognition', 'effectively', 'putting', 'it', 'map', 'years', 'planning', 'went', 'into', 'fair', 'through', 'hard', 'work', 'visionaries', 'go-getters', 'civic', 'boosters', 'dreamers', 'many', 'concepts', 'icons', 'century', '21', 'remain', 'ingrained', 'seattle', 'culture', 'even', 'as', 'real', '21st', 'century', 'begins', 'seattles', 'first', 'worlds', 'fair', '1962', 'seattle', 'worlds', 'fair', 'had', 'its', 'beginnings', 'earlier', 'fair', 'that', 'was', 'held', 'university', 'washington', 'campus', '1909', 'alaska-yukon-pacific', 'exposition', 'a-y-p', 'commemorated', 'first', 'shipment', 'klondike', 'gold', 'through', 'seattle', '1897', 'a-y-p', 'its', 'exhibits', 'rides', 'food', 'fun', 'attracted', 'more', 'than', '3', '5', 'million', 'visitors', 'around', 'world', 'giving', 'seattle', 'much-needed', 'prominence', 'attention', 'as', 'leader', 'pacific', 'trade', 'one', 'attendees', 'fair', 'was', '14-year-old', 'al', 'rochester', 'whose', 'family', 'lived', 'near', 'volunteer', 'park', 'capitol', 'hill', 'young', 'rochester', 'operated', 'bread-slicer', 'tearoom', 'run', 'his', 'sunday', 'school', 'teacher', 'concession', 'stand', 'went', 'broke', 'within', 'week', 'this', 'left', 'al', 'employees', 'pass', 'that', 'got', 'him', 'into', 'expo', 'free', 'every', 'day', 'fair', 'he', 'showed', 'up', 'gates', 'flashed', 'his', 'pass', 'had', 'free', 'rein', 'roam', 'fairgrounds', 'wonders', 'exposition', 'left', 'lasting', 'memory', 'his', 'mind', 'al', 'remembers', '1955', 'al', 'rochester', '1895-1989', 'had', 'come', 'age', 'was', 'now', 'seattle', 'city', 'councilman', 'remembering', 'successes', 'joys', 'a-y-p', 'he', 'began', 'bandying', 'about', 'idea', 'second', 'worlds', 'fair', 'commemorate', 'first', 'was', 'met', 'mixed', 'response', 'one', 'day', 'informal', 'luncheon', 'washington', 'athletic', 'club', 'don', 'follett', 'executive', 'vice-president', 'chamber', 'commerce', 'took', 'interest', 'als', 'idea', 'also', 'luncheon', 'were', 'denny', 'givens', 'chambers', 'director', 'public', 'affairs', 'ross', 'cunningham', 'editor', 'seattle', 'times', 'they', 'too', 'expressed', 'interest', 'buoyed', 'this', 'support', 'rochester', 'began', 'follow', 'through', 'earnest', 'within', 'short', 'time', 'memorial', 'was', 'drafted', 'that', 'asked', 'state', 'legislature', 'consider', 'supporting', 'new', 'worlds', 'fair', 'that', 'would', 'celebrate', '50th', 'anniversary', 'a-y-p', 'before', 'al', 'knew', 'it', 'bill', 'was', 'drafted', 'olympia', 'calling', '5', '000', 'form', 'worlds', 'fair', 'commission', 'there', 'things', 'steamrolled', 'enter', 'eddie', 'carlson', 'original', 'worlds', 'fair', 'commission', 'empanelled', '1955', 'state', 'senators', 'willam', 'goodloe', 'andrew', 'winberg', 'state', 'representatives', 'ray', 'olsen', 'donald', 'mcdermott', 'community', 'leaders', 'eddie', 'carlson', 'paul', 'sceva', 'alfred', 'williams', 'commission', 'was', 'expanded', '15', 'members', '1961', 'included', 'lt', 'governor', 'john', 'cherberg', 'former', 'u', 's', 'senator', 'clarence', 'c', 'dill', '1884-1978', 'state', 'senators', 'howard', 'bargreen', 'herbert', 'h', 'freise', 'michael', 'j', 'gallagher', 'reuben', 'knoblauch', 'state', 'representatives', 'audley', 'f', 'mahaffey', 'ray', 'olsen', 'leonard', 'sawyer', 'jeanette', 'testu', 'seattle', 'city', 'councilman', 'future', 'mayor', 'dorm', 'braman', '1901-1980', 'business', 'community', 'leaders', 'paul', 's', 'friedlander', 'h', 'dewayne', 'kraeger', 'victor', 'rosellini', '1915-2003', 'al', 'rochester', 'served', 'as', 'executive', 'director', 'western', 'hotels', 'vice', 'president', 'eddie', 'carlson', '1911-1990', 'served', 'as', 'chairman', 'carlson', 'well', 'known', '7', 'm', 'businessmans', 'working', 'breakfasts', 'could', 'best', 'be', 'described', 'as', 'go-getter', 'doer', 'mover', 'shaker', 'he', 'would', 'bring', 'these', 'traits', 'more', 'table', 'duncan', 'pp', '21', '40', '1959', '50th', 'anniversary', 'a-y-p', 'too', 'near', 'commission', 'pushed', 'fair', 'date', 'out', 'few', 'years', '1909', 'a-y-p', 'itself', 'had', 'been', 'delayed', 'two', 'years', '10th', 'anniversary', 'klondike', 'gold', 'rush', 'was', 'actually', '1907', 'giving', 'commission', 'bit', 'historical', 'precedent', 'besides', 'few', 'more', 'years', 'would', 'allow', 'them', 'plan', 'event', 'better', 'begin', 'they', 'needed', 'choose', 'site', 'fairgrounds', 'early']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('example:', i)\n",
    "    print('query:', dataset['train'][i]['query'])\n",
    "    print('query_tokens:', dataset['train'][i]['query_tokens'])\n",
    "    answer_id = dataset['train'][i]['answer_id']\n",
    "    print('answer_id:', answer_id)\n",
    "    print('answer:', answers_dataset['train'][answer_id]['answer'])\n",
    "    print('answer_tokens:', answers_dataset['train'][answer_id]['answer_tokens'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice the difference in the types of the different structures we use. Run the following cell to check the types. Do they make sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "--\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "--\n",
      "river is high force waterfall\n",
      "<class 'str'>\n",
      "--\n",
      "['river', 'is', 'high', 'force', 'waterfall']\n",
      "<class 'list'>\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#type of original dataset\n",
    "print(type(dataset))\n",
    "print(\"--\")\n",
    "#type of the split of the dataset\n",
    "print(type(dataset['test']))\n",
    "print(\"--\")\n",
    "#type of original query\n",
    "print(dataset['train'][0]['query'])\n",
    "print(type(dataset['train'][0]['query']))\n",
    "print(\"--\")\n",
    "#type of tokenized query\n",
    "print(dataset['train'][0]['query_tokens'])\n",
    "print(type(dataset['train'][0]['query_tokens']))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bag of Words\n",
    "\n",
    "In this section you will built a bag-of-words representation of the dataset. We will use numpy arrays to store the results. The bag-of-words representation is a simple and effective way to represent text data. It involves creating a vocabulary of unique words from the dataset and representing each sentence as a vector of word counts. We first need the vocabulary, which we will build from both the full sentences and the compressed sentences. Similar to the first lab, the vocabulary will be a list of unique words from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extracting Vocabulary\n",
    "\n",
    "<a name='e4'></a>\n",
    "#### Exercise 4: Extracting vocabulary counts\n",
    "\n",
    "In the following cell, you will implement a function that takes two datasets (`dataset`, and `answers_dataset`) and returns a dictionary with the counts of each word in the vocabulary. The dictionary should be of the form {word: count}. As in previous lab, you will use the `Counter` class from the `collections` module to do this. Iterate over the two datasets and count the tokens in `query_tokens` and `answer_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_vocabulary_counts(dataset, answers_dataset):\n",
    "    \"\"\"\n",
    "    Extracts the vocabulary from the tokenized sentences\n",
    "    Args:\n",
    "        dataset: a Dataset from which 'query_tokens' are used to build vocabulary\n",
    "        answers_dataset: a Dataset from which 'answer_tokens' are used to build vocabulary\n",
    "\n",
    "    Returns: a Counter object with the counts of each word in the vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    vocab = Counter()\n",
    "    ### YOUR CODE HERE\n",
    "    for atoken in answers_dataset['answer_tokens']:\n",
    "        vocab.update(atoken)\n",
    "    for qtoken in dataset['query_tokens']:\n",
    "        vocab.update(qtoken)\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we use the function you implemented. Notice that we build our vocabulary based on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448167\n",
      "[('is', 289258), ('was', 228735), ('as', 183038), ('that', 175434), ('it', 149611), ('his', 140939), ('he', 129504), ('this', 107580), ('are', 107501), ('be', 88097)]\n"
     ]
    }
   ],
   "source": [
    "vocab_counter = extract_vocabulary_counts(dataset['train'], answers_dataset['train'])\n",
    "print(len(vocab_counter))\n",
    "print(vocab_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will truncate the vocabulary. We also create the handy `token_to_id` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 20_000\n",
    "vocab = vocab_counter.most_common(max_vocab_size)\n",
    "# cast to list of words\n",
    "vocab = [word for word, _ in vocab]\n",
    "token_to_id = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "\n",
    "<a name='e5'></a>\n",
    "#### Exercise 5: Bag of Words\n",
    "Here we will create the bag-of-words representation of the sentences. The function will take a single sentence (list of tokens) and return an array of size `vocab_size` with the counts of each word in the vocabulary. The\n",
    "`vocab_size` is calculated as the length of the passed `token_to_id` dictionary. The resulting array should have zeros everywhere but the indices corresponding to the words in the vocabulary where it should have the counts of the words in the sentence. For example, if the sentence is `['fox', 'and', 'deer']` and the vocabulary is `{'fox': 0, 'and': 1, 'deer': 2}`, the resulting array should be `[1, 1, 1]`. If the sentence is `['fox', 'and', 'fox', 'deer']`, the resulting array should be `[2, 1, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bag_of_words(sentence_tokens, token_to_id):\n",
    "    \"\"\"\n",
    "    Creates a bag-of-words representation of the sentence\n",
    "    Args:\n",
    "        sentence_tokens: a list of tokens\n",
    "        token_to_id: a dictionary mapping each word to an index in the vocabulary\n",
    "\n",
    "    Returns:: a numpy array of size vocab_size with the counts of each word in the vocabulary\n",
    "    \"\"\"\n",
    "    vocab_size = len(token_to_id)\n",
    "    bow = np.zeros(vocab_size, dtype=int)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    for token in sentence_tokens:\n",
    "        vocab_idx = token_to_id.get(token)\n",
    "        if vocab_idx is not None:\n",
    "            bow[vocab_idx] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's test the function. The output should be a numpy array of size `vocab_size` with the counts of each word in the vocabulary. Notice that most of the elements of the BOW representation are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence:\n",
      "['was', 'name', 'gangs', 'van', 'scooby-doo', 'tv', 'series']\n",
      "Bag of words:\n",
      "[0 1 0 ... 0 0 0]\n",
      "Type of bag of words:\n",
      "<class 'numpy.ndarray'>\n",
      "Shape of bag of words:\n",
      "(20000,)\n",
      "Non-zero elements in bag of words:\n",
      "[    1    58   100   166  1240 10409]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized sentence:')\n",
    "print(dataset['test'][0]['query_tokens'])\n",
    "query_bow = bag_of_words(dataset['test'][0]['query_tokens'], token_to_id)\n",
    "query_non_zero_bow = np.nonzero(query_bow)[0]\n",
    "\n",
    "print('Bag of words:')\n",
    "print(query_bow)\n",
    "print('Type of bag of words:')\n",
    "print(type(query_bow))\n",
    "print('Shape of bag of words:')\n",
    "print(query_bow.shape)\n",
    "print('Non-zero elements in bag of words:')\n",
    "print(query_non_zero_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine further the non-zero elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements in bag of words:\n",
      "[    1    58   100   166  1240 10409]\n",
      "was : 1\n",
      "name : 1\n",
      "series : 1\n",
      "tv : 1\n",
      "van : 1\n",
      "gangs : 1\n"
     ]
    }
   ],
   "source": [
    "print('Non-zero elements in bag of words:')\n",
    "print(query_non_zero_bow)\n",
    "for i in query_non_zero_bow:\n",
    "    print(vocab[i], ':', query_bow[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Function for Embedding Text\n",
    "\n",
    "The following function will apply all the steps we implemented to a single sentence. It returns a bag of words representation that we will use to calculate the similarity between different sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "[   0    7  459 3360]\n"
     ]
    }
   ],
   "source": [
    "def embed_text(text, clean_fn, tokenize_fn, embed_fn):\n",
    "    \"\"\"\n",
    "    Embeds the text using the provided functions. The pipeline applies cleaning (clean_fn), tokenization (tokenize_fn), and embedding (embed_fn).\n",
    "    Args:\n",
    "        text: the text to be embedded\n",
    "        clean_fn: function/Callable clean_fn(text:str):str\n",
    "        tokenize_fn: function/Callable tokenize_fn(text:str): List[str]\n",
    "        embed_fn: function/Callable embed_fn(tokens:List[str]): np.ndarray\n",
    "\n",
    "    Returns: the embedding of the text as a numpy array\n",
    "    \"\"\"\n",
    "    cleaned = clean_fn(text)\n",
    "    tokens = tokenize_fn(cleaned)\n",
    "    embedding = embed_fn(tokens)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "embedding = embed_text(\"This is an example of a sentence\", clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "print(embedding.shape)\n",
    "print(np.nonzero(embedding)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "<a name='e6'></a>\n",
    "#### Exercise 6: Cosine Similarity between two vectors\n",
    "\n",
    "Complete the following function that given any two vectors will compute the cosine similarity. If you don't remember the formula for the cosine similarity, revisit the course material. Notice that the function receives numpy arrays and recall that you can express cosine similarity as a dot product. Use numpy functions to write an efficient implementation. Two more exercises builds upon this one, so make sure to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors\n",
    "    Args:\n",
    "        vector1: numpy array of the first vector\n",
    "        vector2: numpy array of the second vector\n",
    "\n",
    "    Returns: cosine similarity\n",
    "\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    cosine = 0.0\n",
    "    dot_prod = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    if norm1 != 0 and norm2 != 0: \n",
    "        cosine = dot_prod / (norm1 * norm2) \n",
    "    return cosine\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999999999999998)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(np.array([0, 1, 2]), np.array([0, 2, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see how similar are the BOW representations of some sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: fox and deer\n",
      "Cosine Similarity: 0.2673 - Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Cosine Similarity: 0.0000 - Sentence: Some interesting document containing sentences.\n",
      "Cosine Similarity: 0.2236 - Sentence: The quick brown fox jumps over the lazy cat and some other stuff.\n",
      "Cosine Similarity: 0.6325 - Sentence: Fox and deer are not friends.\n",
      "Cosine Similarity: 0.3015 - Sentence: Fox and deer are not friends. But this document is a lot longer than the previous one. We can add sentence by sentence and see how the embeddings change.\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog.',\n",
    "    'Some interesting document containing sentences.',\n",
    "    'The quick brown fox jumps over the lazy cat and some other stuff.',\n",
    "    'Fox and deer are not friends.',\n",
    "    'Fox and deer are not friends. But this document is a lot longer than the previous one. We can add sentence by sentence and see how the embeddings change.',\n",
    "]\n",
    "embedded_sentences = [\n",
    "    embed_text(sentence, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "query = 'fox and deer'\n",
    "embedded_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "\n",
    "cosine_similarities = [\n",
    "    cosine_similarity(embedded_query, embedded_sentence)\n",
    "    for embedded_sentence in embedded_sentences\n",
    "]\n",
    "print(f'Query: {query}')\n",
    "for sent, cos_sim in zip(sentences, cosine_similarities):\n",
    "    print(f'Cosine Similarity: {cos_sim:.4f} - Sentence: {sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Retrieval\n",
    "\n",
    "In this section, we will use the BOW representations to finally search for the answers to our questions. We start by calculating the BOWs of queries and answers of the whole `validation` subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 20625.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9702/9702 [00:02<00:00, 3858.43it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_queries_bows = []\n",
    "for example in tqdm.tqdm(dataset['validation']):\n",
    "    valid_queries_bows.append(bag_of_words(example['query_tokens'], token_to_id))\n",
    "\n",
    "valid_answers_bows = []\n",
    "for example in tqdm.tqdm(answers_dataset['validation']):\n",
    "    valid_answers_bows.append(bag_of_words(example['answer_tokens'], token_to_id))\n",
    "\n",
    "valid_queries_bows = np.array(valid_queries_bows)\n",
    "valid_answers_bows = np.array(valid_answers_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e7'></a>\n",
    "#### Exercise 7: Cosine Similarity between a vector and an array of vectors\n",
    "\n",
    "The next step in our retrieval system, would be to calculate the proximity of a query to our retrieval corpus (in our case that is all the sentences).\n",
    "\n",
    "Complete the following function to calculate the cosine similarity between a vector (first parameter `vector`, that will usually be the query vector) and all other vectors (second parameter `other_vectors`, that will be the sentence embeddings in our case). Note that the `other_vectors` parameter is a single numpy array of size `N x D`, where $N$ is the number of vectors and $D$ is the dimension of each vector.\n",
    "\n",
    "For maximum efficiency (we will need it) do not use loops. Try to write the implementation with numpy functions. Hint: matrix multiplication can be seen as calculating the dot product between rows and columns of the multiplied matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_1_to_n(vector, other_vectors):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between a single vector and other vectors.\n",
    "    Args:\n",
    "        vector: a numpy array representing a vector of D dimensions\n",
    "        other_vectors: a 2D numpy array representing other vectors (of the size NxD, where N is the number of vectors and D is their dimension)\n",
    "\n",
    "    Returns: a 1D numpy array of size N containing the cosine similarity between the vector and all the other vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    dot_prods = other_vectors @ vector\n",
    "    \n",
    "    v_norm = np.linalg.norm(vector)\n",
    "    ov_norms = np.linalg.norm(other_vectors, axis=1)\n",
    "\n",
    "    denom = v_norm * ov_norms\n",
    "    cos_similarities = np.zeros_like(dot_prods, dtype=float)\n",
    "    nonzero = denom != 0\n",
    "    cos_similarities[nonzero] = dot_prods[nonzero] / denom[nonzero]\n",
    "\n",
    "    return cos_similarities\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now can try out our retrieval system by calculating the cosine similarities between the query and all answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9702,)\n",
      "[0.04101782 0.05382864 0.00680982 0.04174829 0.05540613 0.09814658\n",
      " 0.04005612 0.04476895 0.05132002 0.02599376]\n"
     ]
    }
   ],
   "source": [
    "query = 'Which vegetable is Blackadderâ€™s servant obsessed with in the UK television series â€˜Blackadder IIâ€™?'\n",
    "embedded_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "\n",
    "query_similarity = cosine_similarity_1_to_n(embedded_query, valid_answers_bows)\n",
    "print(query_similarity.shape)\n",
    "print(query_similarity[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9394\n",
      "0.3009774122576535\n",
      "[1 4 4 ... 0 0 0]\n",
      "blackadder watch tv series streaming online synopsis blackadder is name that encompassed four series bbc 1 period british sitcom along several one-off instalments all television episodes starred rowan atkinson as anti-hero edmund blackadder tony robinson as blackadders dogsbody baldrick each series was set different historical period two protagonists accompanied different characters though several reappear one series another example melchett lord flashheart first series titled black adder was written richard curtis rowan atkinson while subsequent episodes were written curtis ben elton shows were produced john lloyd 2000 fourth series blackadder goes forth ranked 16 100 greatest british television programmes list created british film institute also 2004 tv poll find britains best sitcom blackadder was voted second-best british sitcom all time topped only fools horses it was also ranked as 20th-best tv show all time empire magazine blackadder watch online stream buy rent currently you are able watch blackadder streaming netflix buy it as download apple itunes google play movies wuaki microsoft store\n"
     ]
    }
   ],
   "source": [
    "most_similar = int(np.argmax(query_similarity))\n",
    "print(most_similar)\n",
    "print(query_similarity[most_similar])\n",
    "print(valid_answers_bows[most_similar])\n",
    "print(answers_dataset['validation'][most_similar]['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function returns the indices of the top-k elements in the array. If the `sorted` parameter is `True` (it is by default) the returned array will be sorted in the descending order (of the corresponding values in array). For example, if the `array` is `[3, 2, 4, 1]` and `k=2` the returned numpy array will be `[2, 0]` if `sorted` is True (the top values are `3` and `4` with indices `0` and `2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def top_k_indices(array, k, sorted=True):\n",
    "    \"\"\"\n",
    "    Returns top-k indices from the 1D array. If `sorted` is `True` the returned indices are sorted in the descending order\n",
    "    Args:\n",
    "        array: a 1D numpy array\n",
    "        k: a number of top indices to return\n",
    "        sorted: if True, the returned indices are sorted in descending order\n",
    "\n",
    "    Returns: a 1D numpy array containing top-k indices\n",
    "\n",
    "    \"\"\"\n",
    "    top_k = np.argpartition(array, -k)[-k:]\n",
    "    if sorted:\n",
    "        selected = array[top_k]\n",
    "        sorted_selected = (-selected).argsort()\n",
    "        top_k = top_k[sorted_selected]\n",
    "    return top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackadder watch tv series streaming online synopsis blackadder is name that encompassed four series bbc 1 period british sitcom along several one-off instalments all television episodes starred rowan atkinson as anti-hero edmund blackadder tony robinson as blackadders dogsbody baldrick each series was set different historical period two protagonists accompanied different characters though several reappear one series another example melchett lord flashheart first series titled black adder was written richard curtis rowan atkinson while subsequent episodes were written curtis ben elton shows were produced john lloyd 2000 fourth series blackadder goes forth ranked 16 100 greatest british television programmes list created british film institute also 2004 tv poll find britains best sitcom blackadder was voted second-best british sitcom all time topped only fools horses it was also ranked as 20th-best tv show all time empire magazine blackadder watch online stream buy rent currently you are able watch blackadder streaming netflix buy it as download apple itunes google play movies wuaki microsoft store\n",
      "similarity: 0.3009774122576535\n",
      "\n",
      "x-files season 1-9 download torrent tpb get this torrent problems magnets links are fixed upgrading your torrent client x-files is american science fiction drama television series is part x-files franchise created chris carter program originally aired september 10 1993 may 19 2002 spanning nine seasons 202 episodes show was hit fox network its characters slogans such as truth is out there trust no one i want believe became popular culture touchstones 1990s seen as defining series its era x-files tapped into public mistrust governments large institutions embraced conspiracy theories spirituality as it centered efforts uncover existence extraterrestrial life series spawned spin-off show lone gunmen series fbi special agents fox mulder david duchovny dana scully gillian anderson are investigators x-files marginalized unsolved cases involving paranormal phenomena mulder is believer existence aliens paranormal while scully skeptic is assigned make scientific analyses mulders discoveries could ultimately be used debunk mulders work thus return him fbi mainstream 1 early series both agents become pawns larger conflict come trust only each other they develop close relationship begins as platonic friendship develops into romantic relationship end series run addition series-spanning story arc monster week episodes made up roughly two-thirds series such stand-alone episodes mulder scully investigated strange crimes often had no long-term effect storyline though episodes contributed shows background 1998 feature film x-files has been released this was followed 2008 post-series film x-files i want believe last two seasons gillian anderson became star as david duchovny appeared intermittently new central characters were introduced fbi agents john doggett robert patrick monica reyes annabeth gish mulder scullys boss assistant director walter skinner mitch pileggi also became central character time series ended x-files had become longest-running science fiction series u s television history though it was subsequently surpassed stargate sg-1 2007 smallville 2011 series won golden globe award best television series drama three times 1994 1996 1997 duchovny anderson received multiple award nominations their performances\n",
      "similarity: 0.2782706909370396\n",
      "\n",
      "poll best long running british tv comedy imdb imdb poll best long running british tv comedy poll cartman_1337 these uk tv comedy shows that lasted least 4 series is funniest scripted mainly comedy shows no talk shows game shows shows where comedy part was secondaryincidental only entirely uk productions limited 31 most popular shows based imdb ratings 2 000 votes more plus 4 longest running shows fewer votes check out this poll shows that lasted less than 4 series 5 series significantly longer series than common uk see moresee less bit fry laurie 1987 4 series are you being served 1972 10 series benny hill show 1969 19 series not live your life 2007 4 series last summer wine 1973 31 series british men behaving badly 1992 7 series monty pythons flying circus 1969 4 series one foot grave 1990 6 series only fools horses 1981 9 series that mitchell webb look 2006 4 series thick it 2005 4 series vicar dibley 1994 5 series two pints lager packet crisps 2001 9 series\n",
      "similarity: 0.2766992952647332\n",
      "\n",
      "sharpe series sharpe series last update 04 september 2003 you need browser capable viewing tables see this page properly richard sharpe is dashing maverick british rifleman fighting against napoleon 19th century europe this british television series based best-selling novels bernard cornwell series also stars assumpta serna as teresa daragh omalley as harper abigail cruttenden as jane cecile paoli as lucille trivia name horse sean rode series was fantastice video diaries rifleman harris click here insiders look behind scenes sharpe series complete listing all sharpe episodes dates shown are original uk airdates click episode title cast crew details additional pictures series 1 sharpes eagle may 12 1993 series 2\n",
      "similarity: 0.2667107547328796\n",
      "\n",
      "black-adder ii potato tv episode 1986 imdb united kingdom see all my reviews potato is another great series 2 episode tom baker appears this his role as captain redbeard rum is absolutely hilarious humour is once again strong baldrick is once again stupid form he is much funnier this way there are more endlessly quotable lines be found this start end potato is absolutely cracking episode yes budget is still remarkably cheap this episode there should have least been some fancy visuals blackadders boat however tom bakers legs were hidden quite well during this episode he is meant be legless captain after all effects arent be snorted blackadder 1 may have had higher budget than this this is blackadder its very best clever cheap cheerful potato is last 1010 episode this series others are good they just cant recapture its heights whole potato is great blackadder episode not be skipped 1010 4 6 people found this review helpful was this review helpful you yes\n",
      "similarity: 0.2616623547057791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_indices = top_k_indices(query_similarity, k=5).tolist()\n",
    "for idx in top_indices:\n",
    "    print(answers_dataset['validation'][idx]['answer'])\n",
    "    print(f'similarity: {query_similarity[idx]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e8'></a>\n",
    "#### Exercise 8: Analyzing and improving BOW search results\n",
    "\n",
    "Experiment with different queries (taking into account the nature of the dataset and your insights from the analysis so far).\n",
    "Answer the following questions:\n",
    "- Does the search perform well? When does it fail? Discuss several examples that are we get an expected but also unexpected results (find at least 3 from each category). Provide reasons for the good/bad result in each case (e.g. is there some error in the data, is there some linguistic phenomenon that we don't capture, is something wrong with our modeling, ...)\n",
    "- If you see problems with search, how could you improve your implementation? Change the functions above, if you think there is room for improvement. Describe your changes and how they made the search better or (in case you made no changes) explain what made the search robust enough to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>original_query</th>\n",
       "      <th>original_answer</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>query_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was name representative body pre-revolutionary...</td>\n",
       "      <td>was name representative body pre-revolutionary...</td>\n",
       "      <td>1905 russian revolution introduction up end 19...</td>\n",
       "      <td>5046</td>\n",
       "      <td>[was, name, representative, body, pre-revoluti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country was called albion romans</td>\n",
       "      <td>country was called albion romans</td>\n",
       "      <td>alban albion white island alban albion white i...</td>\n",
       "      <td>5688</td>\n",
       "      <td>[country, was, called, albion, romans]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flying mare is term used sport</td>\n",
       "      <td>flying mare is term used sport</td>\n",
       "      <td>flying mare definition flying mare free dictio...</td>\n",
       "      <td>6651</td>\n",
       "      <td>[flying, mare, is, term, used, sport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>playing card is known as devils bedpost</td>\n",
       "      <td>playing card is known as devils bedpost</td>\n",
       "      <td>playing card superstitions snopes com legend v...</td>\n",
       "      <td>5598</td>\n",
       "      <td>[playing, card, is, known, as, devils, bedpost]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is name farm 1995 film orphan flora poste play...</td>\n",
       "      <td>is name farm 1995 film orphan flora poste play...</td>\n",
       "      <td>kate beckinsale picture pages shooting fish ba...</td>\n",
       "      <td>8325</td>\n",
       "      <td>[is, name, farm, 1995, film, orphan, flora, po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  was name representative body pre-revolutionary...   \n",
       "1                   country was called albion romans   \n",
       "2                     flying mare is term used sport   \n",
       "3            playing card is known as devils bedpost   \n",
       "4  is name farm 1995 film orphan flora poste play...   \n",
       "\n",
       "                                      original_query  \\\n",
       "0  was name representative body pre-revolutionary...   \n",
       "1                   country was called albion romans   \n",
       "2                     flying mare is term used sport   \n",
       "3            playing card is known as devils bedpost   \n",
       "4  is name farm 1995 film orphan flora poste play...   \n",
       "\n",
       "                                     original_answer  answer_id  \\\n",
       "0  1905 russian revolution introduction up end 19...       5046   \n",
       "1  alban albion white island alban albion white i...       5688   \n",
       "2  flying mare definition flying mare free dictio...       6651   \n",
       "3  playing card superstitions snopes com legend v...       5598   \n",
       "4  kate beckinsale picture pages shooting fish ba...       8325   \n",
       "\n",
       "                                        query_tokens  \n",
       "0  [was, name, representative, body, pre-revoluti...  \n",
       "1             [country, was, called, albion, romans]  \n",
       "2              [flying, mare, is, term, used, sport]  \n",
       "3    [playing, card, is, known, as, devils, bedpost]  \n",
       "4  [is, name, farm, 1995, film, orphan, flora, po...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "answers_df = pd.DataFrame(dataset['validation'])\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>original_query</th>\n",
       "      <th>original_answer</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>query_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>ordinance survey map is indicated red triangle</td>\n",
       "      <td>ordinance survey map is indicated red triangle</td>\n",
       "      <td>symbols symbols find information photos videos...</td>\n",
       "      <td>1542</td>\n",
       "      <td>[ordinance, survey, map, is, indicated, red, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>who wrote raindrops are fallin my head theme f...</td>\n",
       "      <td>who wrote raindrops are fallin my head theme f...</td>\n",
       "      <td>butch cassidy sundance kid rain drops keep fal...</td>\n",
       "      <td>3043</td>\n",
       "      <td>[who, wrote, raindrops, are, fallin, my, head,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>fictional character has been played largest nu...</td>\n",
       "      <td>fictional character has been played largest nu...</td>\n",
       "      <td>sherlock holmes awarded title most portrayed l...</td>\n",
       "      <td>7865</td>\n",
       "      <td>[fictional, character, has, been, played, larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>town is st magnus cathedral most northerly bri...</td>\n",
       "      <td>town is st magnus cathedral most northerly bri...</td>\n",
       "      <td>st magnus cathedral kirkwall orkney music st m...</td>\n",
       "      <td>4113</td>\n",
       "      <td>[town, is, st, magnus, cathedral, most, northe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>colour would magnesium flare burn</td>\n",
       "      <td>colour would magnesium flare burn</td>\n",
       "      <td>magnesium com data bank safe handling magnesiu...</td>\n",
       "      <td>835</td>\n",
       "      <td>[colour, would, magnesium, flare, burn]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "4295     ordinance survey map is indicated red triangle   \n",
       "1544  who wrote raindrops are fallin my head theme f...   \n",
       "6842  fictional character has been played largest nu...   \n",
       "9897  town is st magnus cathedral most northerly bri...   \n",
       "1599                  colour would magnesium flare burn   \n",
       "\n",
       "                                         original_query  \\\n",
       "4295     ordinance survey map is indicated red triangle   \n",
       "1544  who wrote raindrops are fallin my head theme f...   \n",
       "6842  fictional character has been played largest nu...   \n",
       "9897  town is st magnus cathedral most northerly bri...   \n",
       "1599                  colour would magnesium flare burn   \n",
       "\n",
       "                                        original_answer  answer_id  \\\n",
       "4295  symbols symbols find information photos videos...       1542   \n",
       "1544  butch cassidy sundance kid rain drops keep fal...       3043   \n",
       "6842  sherlock holmes awarded title most portrayed l...       7865   \n",
       "9897  st magnus cathedral kirkwall orkney music st m...       4113   \n",
       "1599  magnesium com data bank safe handling magnesiu...        835   \n",
       "\n",
       "                                           query_tokens  \n",
       "4295  [ordinance, survey, map, is, indicated, red, t...  \n",
       "1544  [who, wrote, raindrops, are, fallin, my, head,...  \n",
       "6842  [fictional, character, has, been, played, larg...  \n",
       "9897  [town, is, st, magnus, cathedral, most, northe...  \n",
       "1599            [colour, would, magnesium, flare, burn]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR CODE HERE\n",
    "sampled_queries = queries_df.sample(n=10)\n",
    "\n",
    "sampled_queries.head()\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 : ordinance survey map is indicated red triangle\n",
      "Answer: trigonometryangles triangle sum 180 degrees wikibooks open books open world trigonometryangles triangle sum 180 degrees wikibooks open books open world any triangle angles always sum sum angles edit any triangle angles always sum 180 this is perhaps surprising fact because displaystyle 90 circ is right angle it means that sum angles any triangle is same as two right angles if we tore corners off placed them together same point we could arrange them so that they exactly formed straight line there doesnt need be anything special about triangle it works any triangle angles sum 180o some examples that we had before triangles are shown below 50-60-70 triangle 20-40-120 triangle first example shows equilateral triangle all sides are equal all angles are equal each angle is 60 degrees sum angles is 60 displaystyle 60 circ 60 circ 60 circ is displaystyle 180 circ second triangle shows right angle triangle one angles is right angle this right angle triangle has two sides same length it is symmetric it fulfils our criteria being isosceles triangle this is particularly special isosceles triangle because it is isosceles it is right triangle there is one angle 90 each two remaining angles is 45 sum angles is 45 displaystyle 45 circ 45 circ 90 circ is displaystyle 180 circ third triangle is sometimes called 30 60 90 triangle because its angles it is actually half equilateral triangle sum angles is 30 displaystyle 30 circ 60 circ 90 circ is pattern is pretty clear next we have more arbitrary triangle all sides are different angles are 50 60 70 sum angles is 50 displaystyle 50 circ 60 circ 70 circ is displaystyle 180 circ finally we have triangle obtuse angle that is one angles is larger than 90 angles happen be 20 40 120 sum angles is 20 displaystyle 20 circ 40 circ 120 circ is examples suggest it is true they dont prove it edit we could keep doing this other triangles keep finding same answer unless we make mistake this might convince us that our statement that angles sum 180 is true all triangles it does not prove that it is so prove it we need some kind general argument that could convince mathematician that it is true do we know it is always true could it go wrong well if we hadnt tried triangle obtuse angle it might be case that formula only works triangles dont have obtuse angles even having tried triangle obtuse angle we could have not been trying hard enough find example that doesnt work all we know formula only works if angles are multiples 5 proof will show it works all triangles edit formula does fact work all triangles we can example make triangle angles 33 66 third angle will have be 81 making more more examples unfortunately doesnt get us anywhere closer proving it is true all triangles we need different approach well show proof later point having proof is show that it is true all triangles not just ones weve chosen look exercises edit given any triangle angles 123 60 evaluate third angle is it possible it is not possible because sum all angles triangle cannot exceed 180 triangle has angles 15 65 is third angle triangle has angles 100 79 5 is third angle do you think all sides this triangle will be about same length is measure each angle equilateral triangle roadsign exercise\n",
      "Cosine similarity: 0.35236199221335424\n",
      "\n",
      "Answer: lycopene human health lycopene human health friday january 20th 2017 is lycopene lycopene is carotenoid pigment found tomatoes other red fruits like watermelon papaya pink grapefruit pink guava its name is derived tomatos species classification solanum lycopersicum lycopene similar other carotenoids is natural fat-soluble pigment red case lycopene is synthesized some plants micro-organisms not animals where it serves as accessory light-gathering pigment protect these organisms against toxic effects oxygen light carotenoids are principal pigments responsible colors vegetables fruits these include ÃŸ-carotene lutein zeaxanthin lycopene is responsible red color red tomatoes other fruits it is found its colour is due its many conjugated carbon double bonds each double bond reduces energy required electrons transition higher energy states allowing molecule absorb visible lengths progressively longer wavelengths lycopene absorbs most visible spectrum so it appears red lycopene is acyclic isomer ÃŸ carotene it is 40 carbon atom open chain polyisoprenoid 11 conjugated double bonds its molecular formula is c40h56 structural formula lycopene is represented diagram above all-e lycopene is predominant geometric isomer found plants z isomers lycopene are also found nature including 5z 9z 13z 15z isomers lycopene found human plasma is mixture approximately 50 z lycopene 50 all-e lycopene lycopene processed foods is mainly form all-e lycopene lycopene is most common carotenoid human body is one most potent carotenoid antioxidants lycopene is easily absorbed organism is naturally present human plasma tissues higher concentrations than other carotenoids its level is affected several biological lifestyle factors because its lipophilic nature lycopene concentrates low-density very-low-density lipoprotein fractions serum lycopene is also found concentrate adrenal liver testes prostate however unlike other carotenoids lycopene levels serum tissues do not correlate well overall intake fruits vegetables\n",
      "Cosine similarity: 0.33987654065040135\n",
      "\n",
      "Answer: flags every country follow us flags every country tweet this map shows flags every country world flag description produced actual flags best information available time entry was written flags independent states are used their dependencies unless there is officially recognized local flag some disputed other areas do not have flags note flag description cia factbook flag image wikipedia last updated abkhazia afghanistan three equal vertical bands black hoist side red green national emblem white centered red band slightly overlapping other two bands center emblem features mosque pulpit flags either side below mosque are numerals solar year 1298 1919 gregorian calendar year afghan independence uk this central image is circled border consisting sheaves wheat left right upper-center is arabic inscription shahada muslim creed below are rays rising sun over takbir arabic expression meaning god is great bottom center is scroll bearing name afghanistan black signifies past red is blood shed independence green can represent either hope future agricultural prosperity islam note afghanistan had more changes its national flag 20th century than any other country colors black red green appeared most them akrotiri flag uk is used albania red black two-headed eagle center design is claimed be that 15th-century hero george castriota skanderberg who led successful uprising against turks that resulted short-lived independence some albanian regions 1443-1478 unsubstantiated explanation eagle symbol is tradition that albanians see themselves as descendants eagle they refer themselves as shkypetars translates as sons eagle algeria two equal vertical bands green hoist side white red five-pointed star within red crescent centered over two-color boundary colors represent islam green purity peace white liberty red crescent star are also islamic symbols crescent is more closed than those other muslim countries because algerians believe long crescent horns bring happiness american samoa blue white triangle edged red that is based fly side extends hoist side brown white american bald eagle flying toward hoist side is carrying two traditional samoan symbols authority war club known as faalaufai upper left talon coconut fiber fly whisk known as fue lower right talon combination symbols broadly mimics that seen us great seal reflects relationship between united states american samoa andorra three vertical bands blue hoist side yellow red national coat arms centered yellow band latter band is slightly wider than other two so that ratio band widths is 8 9 8 coat arms features quartered shield emblems starting upper left proceeding clockwise urgell foix bearn catalonia motto reads virtus unita fortior strength united is stronger flag combines blue red french colors red yellow spain show franco-spanish protection note similar flags chad romania do not have national coat arms center flag moldova does bear national emblem angola two equal horizontal bands red top black centered yellow emblem consisting five-pointed star within half cogwheel crossed machete style hammer sickle red represents liberty black african continent symbols characterize workers peasants anguilla blue flag uk upper hoist-side quadrant\n",
      "Cosine similarity: 0.3011270268809713\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 2 : who wrote raindrops are fallin my head theme film butch cassidy sundance kid\n",
      "Answer: butch cassidy sundance kid cast list actors actresses butch cassidy sundance kid full cast butch cassidy sundance kid actorsactresses 4 9k views 12 items tags f t p butch cassidy sundance kid cast list listed alphabetically photos available this list butch cassidy sundance kid actors includes any butch cassidy sundance kid actresses all other actors film you can view additional information about each butch cassidy sundance kid actor this list such as where they were born find out more about particular actor actress click their name youll be taken page even more details about their acting career cast members butch cassidy sundance kid have been many other movies so use this list as starting point find actors actresses that you may not be familiar list contains actors like paul newman robert redford if you want answer questions who starred movie butch cassidy sundance kid is full cast list butch cassidy sundance kid then this page has got you covered this cast list who was butch cassidy sundance kid includes both lead minor roles 12 items\n",
      "Cosine similarity: 0.5045021411410923\n",
      "\n",
      "Answer: butch cassidy sundance kid 1969 quotes imdb butch cassidy sundance kid 1969 sundance kid no i said butch cassidy whats matter you sundance kid i cant swim butch cassidy are you crazy fall will probably kill you butch cassidy kid theres something i ought tell you i never shot anybody before sundance kid one hell time tell me butch cassidy well that ought do it after blowing train car smithereens sundance kid think ya used enough dynamite there butch butch cassidy i dont want shoot you harvey harvey logan draws big knife anything you say butch butch walks over sundance butch cassidy low voice maybe theres way make profit this bet logan sundance kid i would whod bet you harvey logan sundance were done hes dead youre welcome stay butch cassidy low voice sundance listen i dont mean be sore loser its done if im dead kill him sundance kid low voice butch love waves harvey smiles butch cassidy no no not yet not until me harvey get rules straightened out harvey logan rules knife fight no rules butch immediately kicks harvey groin butch cassidy well if there aint going be any rules lets get fight started someone count 1 2 3 go sundance kid quickly 1 2 3 go butch knocks harvey out flat nose curry i was really rooting you butch butch cassidy well thank you flatnose thats sustained me my time trouble sundance kid its your great ideas that got us into this mess i never want hear another one your great ideas ever butch cassidy australia i thought that secretly you wanted know so i told you sundance kid thats your great idea butch cassidy latest long line we get out here alive we go australia goodbye bolivia hello australia sundance kid australia is no better than here sundance kid name me one thing butch cassidy they speak english australia sundance kid they do butch cassidy thats right smart guy so we wouldnt be foreigners wed blend more easily they got horses australia thousands miles countryside that we can hide out good climate nice beaches you can learn swim sundance kid no swimming isnt important about banks butch cassidy very easy easy ripe luscious sundance kid banks women butch cassidy well once you get one you get other sundance kid australia is quite long way here butch cassidy oh please everything you has got be perfect sundance kid i just dont want get there realize that it stinks thats all butch cassidy least think about it sundance kid all right ill think about it sundance kid im saying is if you want go i wont stop you minute you start whine make nuisance i dont care where we are im dumping you flat butch cassidy dont sugarcoat it like that kid tell her straight etta place im 26 im single school teacher thats bottom pit only excitement ive known is here me now ill go you i wont whine ill sew your socks ill stitch you youre wounded ill do anything you ask me except one thing i wont watch you die ill miss that scene if you dont mind butch cassidy those guys will split up eventually they cant stay together that long etta place yes they can because mr e h harriman sundance kid e h harriman etta place yes apparently mr e h harriman is not happy that you boys are picking him so he has put together special armored train hired new employees get you butch cassidy that must cost him more than i ever took him if he wants pay that much get me stop robbing him then he can give it me ill stop robbing him\n",
      "Cosine similarity: 0.4482800264018707\n",
      "\n",
      "Answer: butch cassidy sundance kid rain drops keep falling my head youtube butch cassidy sundance kid rain drops keep falling my head want watch this again later sign add this video playlist need report video sign report inappropriate content rating is available video has been rented this feature is not available right now please try again later published apr 7 2009 this song was uploaded k m wahiduzzaman apollo movie butch cassidy sundance kid performers paul newman katharine ross singer b j thomas lyrics hal david music burt bacharach this scene paul newman did his own bicycle stunts after his stunt man was unable stay bike category\n",
      "Cosine similarity: 0.3537261506283055\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 3 : fictional character has been played largest number different actors\n",
      "Answer: prime numbers 2 3 5 7 11 13 prime numbers is 2 prime number is prime number prime number is positive natural number that has only two positive natural number divisors one itself opposite prime numbers are composite numbers composite number is positive nutural number that has least one positive divisor other than one itself number 1 is not prime number definition it has only one divisor number 0 is not prime number it is not positive number has infinite number divisors number 15 has divisors 1 3 5 15 because 15115 so 15 is not prime number number 13 has only two divisors 1 13 13113 so 13 is prime number prime numbers list list prime numbers up 100 2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 is 0 prime number number 0 is not prime number zero is not positive number has infinite number divisors is 1 prime number number 1 is not prime number definition one is has one divisor itself is 2 prime number number 2 is prime number two has 2 natural number divisors 1 2 2 1 2\n",
      "Cosine similarity: 0.28444675574787964\n",
      "\n",
      "Answer: numbers define numbers dictionary com numbers noun used singular verb 1 fourth book old testament containing census israelites after exodus egypt abbreviation num numeral group numerals 2 sum total count aggregate collection units like number people were hurt accident number homeless children city has risen alarmingly 3 word symbol combination words symbols used counting noting total 4 particular numeral assigned object so as designate its place series house number license number one series things distinguished marked numerals 6 certain collection company quantity not precisely reckoned usually considerable large ive gone there number times 7 full count collection company 8 their number was more than 20 000 10 considerable amount quantity many numbers flocked city see parade metrical feet verse informal figures representing actual cost expense profit etc we wont make decision until we see numbers quantity as composed units increase number eligible voters 12 numerical strength superiority complement garrison is not up its full number 13 tune arrangement singing dancing 14 single distinct performance within show as song dance comic routine followed dance number 15 single part program made up group similar parts her third number she played nocturne 16 any collection poems songs 17 distinct part extended musical work one sequence compositions 18 conformity music verse regular beat measure rhythm 19 single part book published series parts 20 single issue periodical several numbers popular magazine 21 code numerals letters combination these assigned particular telephone did you call right number 22 grammar category noun verb adjective inflection found many languages as english latin arabic used indicate whether word has one more than one referent there may be two-way distinction number as between singular plural three-way as between singular dual plural more 23 attractive number standing bar 24 informal article merchandise especially wearing apparel offered sale put those leather numbers display window 25 mathematics regarded as science basic concept mode thought number is basis science verb used object mark distinguish numbers number each definitions 27 amount comprise number total manuscript already numbers 425 pages 28 consider include number i number myself among his friends 29 mention individually one one enumerate they numbered highlights their trip length 31 set fix number limit number make few number sick old mans days are numbered 32 live have lived number years 33 ascertain number count 34 players were numbered into two teams verb used without object make total reach amount casualties numbered thousands 36 be numbered included usually followed among several eminent scientists number among his friends 37 do number slang undermine defeat humiliate criticize thoroughly committee really did number mayors proposal discuss discourse about especially entertaining way she could do number anything dentistry bomb 40 give performance perform its time you get stage do your number slang behave predictable customary manner whenever i call he does his number about being too busy talk 41 get have someones number informal become informed about someo\n",
      "Cosine similarity: 0.26250067794684123\n",
      "\n",
      "Answer: sherlock holmes awarded title most portrayed literary human character film tv guinness world records sherlock holmes awarded title most portrayed literary human character film tv guinness world records news published google having been depicted screen 254 times gwr today announces that sherlock holmes sir arthur conan doyles fictional detective has been awarded world record most portrayed literary human character film tv since his creation 1887 sherlock holmes has been played over 75 actors including sir christopher lee charlton heston peter otoole christopher plummer peter cook roger moore john cleese benedict cumberbatch robert downey jr above guinness world records adjudicator claire burgess commented sherlock holmes is literary institution this guinness world records title reflects his enduring appeal demonstrates that his detective talents are as compelling today as they were 125 years ago through combination films television series dramas documentaries sherlocks appearances beat character shakespeares hamlet 48 portrayals claim record however sherlock is not overall most portrayed literary character film that title belongs non-human character dracula who has been portrayed 272 films record was recognised as part world record london calendar record-breaking events taking place run-up london 2012 olympic paralympic games so far project has overseen successful record attempts longest curtsey relay longest marathon hug future events set include queens diamond jubilee river pageant sunday 3 june hopes break record largest parade boats find out whats coming up as part world record london visit www visitlondon comworldrecordlondon share\n",
      "Cosine similarity: 0.2502172968684897\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 4 : town is st magnus cathedral most northerly britain\n",
      "Answer: st magnus cathedral kirkwall orkney music st magnus st magnus cathedral britains most northerly cathedral st magnus cathedral known as light north was founded 1137 viking earl rognvald honour his uncle st magnus cathedral belongs people orkney its doors are open all cathedral set heart kirkwall capital city orkney islands is place stillness inspiration warmth is steeped presence god we invite you explore this website contains information about many aspects cathedrals life congregation st magnus cathedral is very conscious its place long continuum worship this ancient holy building worship is draws people cathedral our worship is open anyone who might wish participate society friends st magnus cathedral is dedicated group people who contribute life cathedral through fund raising support maintenance development building society also seeks promote increased awareness knowledge cathedral general public joining friends you are supporting cathedral helping secure this magnificent building future generations st magnus centre is not just church hall it is meeting place visitor centre arts venue place quiet contemplation building facilities offered 19th century st magnus hall st magnus centre has meeting rooms projector room where film saga st magnus is shown large hall can serve as great venue events such as receptions dances socials etc visit this site see st magnus centre can offer you your organisation kirkwall st magnus cathedral church scotland registered charity sc005322\n",
      "Cosine similarity: 0.6042103056535397\n",
      "\n",
      "Answer: cathedrals uk interactive map photo gallery cathedrals britain world-famous st pauls london charming 12th century st davids cathedral wales simply scroll down see our interactive map christian cathedrals britain although we have attempted be as thorough as possible please do not hesitate contact us if you have cathedral that we have not included map is cathedral cathedral is not just large church word cathedral comes latin word cathedra meaning seat chair refers presence bishops archbishops chair throne it is most important church diocese is minster is it same as cathedral sometimes not always minsters were established during anglo-saxon times were churches attached monastery monasterium nowadays term minster has come refer more generally any large important often parish church famous minsters include york minster southwell minster westminster london cathedrals england aldershot cathedral roman catholic church cathedral church st michael st george serves as roman catholic cathedral bishopric forces provides chaplains british armed forces church was designed 1892 two military engineers originally intended as principal church anglican chaplaincies british army it eventually became seat roman catholic bishop forces instead arundel cathedral roman catholic church cathedral church our lady st philip howard was dedicated 1873 as catholic parish church arundel designated cathedral 1965 cathedrals location construction design owe much howard family who as dukes norfolk earls arundel are most prominent catholic family england architectural style cathedral is french gothic suitable counterpart their nearby home arundel castle birmingham cathedral church england designed english baroque architect thomas archer st philips was originally built as parish church 1715 it became cathedral newly formed diocese birmingham 1905 birmingham cathedral roman catholic church metropolitan cathedral church basilica saint chad was first catholic cathedral be built england after english reformation initiated 1534 king henry viii designed augustus pugin it was completed 1841 raised cathedral status 1852 blackburn cathedral church england one englands newest cathedrals creation diocese blackburn 1926 parish church st mary virgin was elevated cathedral status church was built 1826 now forms cathedrals nave bradford cathedral church england site christian worship since anglo-saxon times later norman church stood 300 years before being destroyed raiding scots during fourteenth century church was rebuilt oldest parts present building were completed 1458 brentwood cathedral roman catholic church roman catholic cathedral church st mary st helen dates 1861 originally parish church built gothic style this relatively small building was elevated cathedral status 1917 enlarged between 1989-1991 new cathedral was dedicated 31 may 1991 bristol cathedral church england founded as st augustines abbey 1140 cathedral church holy undivided trinity became seat bishop cathedral new diocese bristol 1542 st edmundsbury cathedral church england church has stood site current cathedral over 1 000 years largely rebuilt 16th century st james church became st edmundsbury cathedral 1914 canterbury cathedral church england one oldest most famous christian buidlings england cathedral metropolitical church christ canterbury is seat t\n",
      "Cosine similarity: 0.3626805517086162\n",
      "\n",
      "Answer: ten things you thought you knew about scotland whisky cyclist whisky cyclist stations ten things you thought you knew about scotland updated 261211 well 6 so far links this page are undiscovered scotland wikipedia other interesting links that ive found 1 muckle flugga is most northerly island british isles nearly muckle flugga has most northerly lighthouse britain therefore used be most northerly inhabited island not that it could ever have sustained human inhabitants most northerly british isle is much less imaginatively named out stack aka oosta unst shetlopedia britains most northerly islands looking north herma ness unst more southerly guano covered rocks are vesta skerry rumblings tipta skerry muckle flugga lighthouse atop are indistinguishable this photo north lies out stack trees west yell 3 ardnamurchan point is most westerly point british mainland again nearly true actually you may not have realised that most westerly point scottish mainland is well west lands end because north island great britain leans considerably left ardnamurchan point has most westerly lighthouse mainland britain however as map right shows most westerly point is south ardnamurchan point 6 13 34 13 w corrachadh mÃ²r 6 13 37 70 w while dr syntaxs head lands end is mere 5 42 56 56 w see also wikipedia extreme points uk 2 there are no trees shetland isles not quite true there are very few trees shetlands as picture left shows there are few that do their best grow there yell is splendidly named second most northerly inhabited island british isles there are also some attempts trees unst most northerly inhabited island i dont have any good pictures them 4 john o groats is most northerly point mainland scotland wrong 5 john o groats is most north-easterly point mainland scotland wrong closer dunnet head is most northerly point duncansby head most north easterly as can be seen map above left click enlarge neither point is that far john o groats so bad news cyclists lands end john o groats if you want really go end end great britain mainland youve still got two more miles go 6 jura only has one road not quite even discounting few short private roads jura house ardlussa estate juras road does have few public branches main road jura is a846 starting as it means go commences islay ardbeg distillery tours number distilleries islay before reaching port askaig hops eilean dhiura ferry continues through craighouse lussagiven where it finally gives up being road not that you might realise it was road long before then single track often grass growing down middle it bears no resemblance its main stretch between port ellen port askaig let alone most roads mainland as can be seen these three map extracts it branches off pier craighouse opposite isle jura distillery has unclassified branch ardfernal another inverlussa it eventually peters out into rough track time it reaches barnhill cottage where george orwell wrote 1984 orwell famously described jura as ungetattable if youve ever been jura youll know just he meant it must have been even more difficult 1948\n",
      "Cosine similarity: 0.35588990583514246\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 5 : colour would magnesium flare burn\n",
      "Answer: 12 magnesium mg magnesium 2 62 grams per cubic centimeter normal phase greek word magnesia district thessaly date discovery magnesium sulfate mgso4 interesting facts it is eighth most common element earths crust is most commercially used element it is obtained seawater it is very flammable metal center chlorophyll contains magnesium pouring water burning magnesium will increase fire can cause explosions magnesium oxide is byproduct burning magnesium can cause respiratory problems like asthma emphysema common uses\n",
      "Cosine similarity: 0.28673117218166416\n",
      "\n",
      "Answer: its elemental element magnesium its elemental melting point 923 k 650c 1202f boiling point 1363 k 1090c 1994f density 1 74 grams per cubic centimeter phase room temperature solid element classification metal period number 3 group number 2 group name alkaline earth metal whats name magnesia district region thessaly greece say magnesium is pronounced as mag-nee-zhi-em history uses although it is eighth most abundant element universe seventh most abundant element earths crust magnesium is never found free nature magnesium was first isolated sir humphry davy english chemist through electrolysis mixture magnesium oxide mgo mercuric oxide hgo 1808 today magnesium can be extracted minerals dolomite caco3mgco3 carnallite kclmgcl26h2o is most often obtained seawater every cubic kilometer seawater contains about 1 3 billion kilograms magnesium 12 billion pounds per cubic mile magnesium burns brilliant white light is used pyrotechnics flares photographic flashbulbs magnesium is lightest metal that can be used build things although its use as structural material is limited since it burns relatively low temperatures magnesium is frequently alloyed aluminum makes aluminum easier roll extrude weld magnesium-aluminum alloys are used where strong lightweight materials are required such as airplanes missiles rockets cameras horseshoes baseball catchers masks snowshoes are other items that are made magnesium alloys magnesium oxide mgo also known as magnesia is second most abundant compound earths crust magnesium oxide is used some antacids making crucibles insulating materials refining some metals their ores some types cements combined water h2o magnesia forms magnesium hydroxide mg oh 2 better known as milk magnesia is commonly used as antacid as laxative hydrated magnesium sulphate mgso47h2o better known as epsom salt was discovered 1618 farmer epsom england his cows refused drink water certain mineral well he tasted water found that it tasted very bitter he also noticed that it helped heal scratches rashes his skin epsom salt is still used today treat minor skin abrasions other magnesium compounds include magnesium carbonate mgco3 magnesium fluoride mgf2 magnesium carbonate is used make some types paints inks is added table salt prevent caking thin film magnesium fluoride is applied optical lenses help reduce glare reflections estimated crustal abundance 2 33104 milligrams per kilogram estimated oceanic abundance 1 29103 milligrams per liter number stable isotopes 3 view all isotope data ionization energy 7 646 ev\n",
      "Cosine similarity: 0.2845551966122361\n",
      "\n",
      "Answer: magnesium com data bank safe handling magnesium safe handling magnesium magnesium is combustible metal however it can be melted processed without incident following well developed safety practices certain forms like thin ribbon magnesium ignites quite easily solid forms such as magnesium ingots combustion is difficult get started magnesium is excellent conductor heat as practical matter entire piece must be brought temperature near melting point before ignition will occur normally this will not occur unless solid magnesium piece is surrounded general conflagration other sources care must be exercised magnesium it is molten state finely divided form such as chips granules powder involved general conflagration molten magnesium safety clothing equipment molten magnesium like any other substance 600 Âºc will cause severe burns upon contact your skin those who work around molten magnesium must wear adequate protective clothing equipment this includes safety glasses hard hat safety shield fire retardant clothing insulated gauntlet gloves all safety clothing equipment should be tested ensure that protection is adequate first aid provisions should include fire blankets safety showers all personal protective equipment should meet applicable statutory codes protection melt molten magnesium will ignite burn exposed air so it must be protected during melting operations traditional method was cover chloride salts that fluidized excluding air contact surface common practice today although not universal is use protective gas such as sulfur hexafluoride very low concentrations air air carbon dioxide sulfur hexafluoride sf6 forms film melt surface prevents excessive oxidation gas feeding system gas feeding system should be designed prevent high concentrations sulfur hexafluoride over melt because it will severely corrode steel cover pot corrosion product can react molten magnesium could cause explosion system design should ensure minimal effect air flow disturbing gas blanket fuel supply lines should have combustion safety controls remote shut offs prevent contact water automatic sprinklers should not be installed over melting operations heat treating furnaces areas where magnesium finely divided form is produced stored if water comes into contact any molten magnesium whether it is foundry furnace puddle burning building there could be explosion water will expand 1 000 times its original volume so doing may throw molten metal considerable distance addition magnesiums great affinity oxygen will dissociate water releasing flammable hydrogen can be explosive mixed air pre-heat ingots tools any material such as ingots tools that are introduced into molten magnesium must be pre-heated well above 100 Âºc drive off all moisture other volatiles any cold surface should be suspected containing moisture condensed atmosphere keep melting pot clean molten magnesium can react exothermically iron oxide thermite reaction generates temperatures excess 2200 Âºc large amount heat since most magnesium melting pots are made steel it is extremely important keep inside pot clean free scale likewise scale should be removed regularly furnace prevent reaction molten magnesium event pot failure refractories used furnace should be high alumina magnesia since molten magnesium can react violently even small amounts silica may be present ceramic materials run-out pans should be provided event pot failure they should be kept clean free moisture scale all times fire ex\n",
      "Cosine similarity: 0.2460905535784756\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 6 : national holiday celebrated usa 4 july each year is commemorate events surrounding war\n",
      "Answer: us map usa map map united states america us map get custom mapping quote 1 408 637 0064 salesmapsofworld com disclaimer disclaimer all efforts have been made make this image accurate however compare infobase limited its directors employees do not own any responsibility correctness authenticity same map usa is available different formats learn more about state boundaries international boundaries important water bodies capitals all 50 states country buy map amazon com printed matte paper 36 inch size more options size along digital formats visit our store store mapsofworld com usa physical map us history back 1500s spanish explorer juan ponce de leÃ³n landed coast florida spain established first european colony north america 1700s britain gained control territories east mississippi river motto displayed great seal usa is e pluribus unum means out many one usa has no official language usa is divided into nine time zones total area usa is 9 857 306 sq km making it third largest country world major rivers country are colorado columbia mississippi missouri ohio rio grande sacramento san joaquin snake river yellowstone more than 800 rivers crisscross continental u s this map shows some longest rivers us mississippi river combines missouri river form fourth longest river system world five great lakes lake superior huron erie ontario are shared usa canada only michigan lies entirely usa highest point usa is mount mckinley alaska is 6 194 meters high lowest point is death valley california lies 86 meters below sea level usa has more diverse ecosystems than any other nation world iconic flora usa includes prairie grass giant redwood california giant saguaro cacti us deserts alaskas coastline is longer than coastlines all other states combined usa has 59 officially-designated national parks spread over 50 states here is list us national parks more us climate education health public education is free available all students apart public schools private schools home schools are two other options schooling united states some american colleges universities consistently rank among top 20 world here is list top universities usa literacy rate us is 99 life expectancy birth is 78 7 years however it is not list top 10 countries highest life expectancy us travel tourism usa receives around seven million international visitors every year some most visited cities usa are new york city los angeles miami orlando san francisco las vegas washington d c honolulu boston chicago san diego philadelphia seattle some favorite destinations domestic american tourists were us virgin islands hudson river valley four corners region california gold country yellowstone national park most visited tourist spots include times square las vegas strip national mall memorial parks disney worlds magic kingdom golden gate national recreation area niagara falls great smokey mountains national park navy pier state kentucky has longest cave system world universal studio disneyland are among best theme parks us famous americans\n",
      "Cosine similarity: 0.27544526738091707\n",
      "\n",
      "Answer: is rowing lower merion crew is rowing manual interested parents david greenspan introduction so you want know more about lower merion high school rowing some your questions may require specific answers that only this current years coaches can answer if your questions are more general then this document evolution be edited updated as you give me feedback is you so lets start most basic is rowing rowing is sport recreation competition athletes race against each other rivers lakes ocean boats move across water person power through use oars rowing competitions have been established juniors under 18 year olds masters 36-100 yrs is olympic sport whereas lmhs rowing has girls boys all sizes olympic aspirants must compete against some fittest athletes any sport typical male olympic rower would be over 6 feet tall weigh around 200 lbs have about 7 body fat fortunately it doesnt take anything like that find comfortable spot lmhs rowing team united states high school collegiate rowing is sometimes referred as crew www dictionary com crew kru kroo noun 4 team that rows racing shell varsity crew lmhs crew rows schuykill walking boat house row kelly drive is walk history rowing is second oldest sport played today cricket is just few years older philadelphia rowing spawned amateur athletics this country has been represented olympics since first modern games 1900 grand tradition philadelphia rowing continues this day coach olympic gold medal 2004 mens team mike teti having rowed monsignor bonner st josephs college lmhs crew rows out whitemarsh boat house hines rowing center conshohocken pa via trailer lmhs boats are transported race course schuykill river just upriver boat house row each week equipment nutshell rowing is done boat called shell perhaps this name comes very thin veneer like hull once made wax paper later thin layer wood fragile as egg shell currently shells are significantly sturdier made carbon fibers plastic still 60 foot long 2 foot wide shell big enough eight 200 pound rowers 120 pound coxswain almost ton total weigh little more than 210 pounds costs about 35 000 these days there are several different types boats they are classified referring one five variables use shorthand notation notation is crucial since race programs results use shorthand regularly number rowers shell all forms modern competition number is 1 2 4 8 position coxswain boats are either coxless straight bow coxed also called bowloaders stern coxed coxswain see page 8 bow is front stern back boat sweep scull sweep rowing each athlete has one oar either port starboard port is left facing bow boat so each athlete is either port starboard sculling each athlete has two oars one each hand sculling options notation single scull 1x double scull 2x quad quadruple scull 4x octuple scull 8x always coxed mainly juniors exhibition note designation _x this is shorthand denote sculling shell photo is womens openweight quad w4x ladies are sculling they have one oar each hand sweep options notation straight pair coxless pair 2 coxed pair 2 straight four coxless four 4 coxed four 4 eight 8 always coxed designation has no x sweeping indicates whether there is coxswain photo is mens openweight straight four m4 each man has one oar grasped two hands this is photo british 4 that dominated rowing\n",
      "Cosine similarity: 0.23419886631199016\n",
      "\n",
      "Answer: 1 if mercury is 1 venus is 2 is 6 jade wright liverpool echo 1 if mercury is 1 venus is 2 is 6 2 if william hartnell is 1 patrick troughton is 2 who is 4 share get daily updates directly your inbox subscribe could not subscribe try again laterinvalid email 2 if william hartnell is 1 patrick troughton is 2 who is 4 3 if alpha is 1 beta is 2 is 6 4 if tony blackburn won 2002 phil tuffnell won 2003 kerry katona won 2004 who won 2007 5 if david lloyd george is 1 andrew bonal law is 2 stanley baldwin is 3 who is 4 6 if liverpool won 2006 chelsea won 2007 who won 2008 7 many pints does 10 gallon hat hold 8 who was murdered fitzurse de tracy de morville le breton 9 who presents location location location phil spencer 10 ancient activity does word crestfallen come 11 non-mechanical sport achieves highest speeds 12 major city is island st lawrence river 13 who succeeded alf ramsey become caretaker manger english national football team 1974 14 did britains roads first acquire 1914 15 former liverpool player held record fastest hat-trick scoring 3 goals less than 5 minutes 16 myleen klass pictured now presents 10 years younger channel 4 was name pop band that gave her success 2001 17 who was presenter out town 1960s who went appear childrens tv programme 18 whose autobiography is called dear fatty 19 who were tom barbaras neighbours good life 20 cockney rhyming slang are your daisy roots 21 is surname twin brothers who compiled guinness book records together between 1955 1975 22 actor played columbo 23 does bactrian camel have one hump two 24 where is worlds largest four-faced chiming clock 25 concerned about impact uncontrolled development industrialisation national charity was founded 1895 three victorian philanthropists miss octavia hill sir robert hunter canon hardwicke rawnsley 26 famous make motorcycle was lawrence arabia riding he was tragically killed dorset 1936 27 colour flag should ship fly show it is quarantine 28 purple brittlegill velvet shank orange milkcap are three types 29 is name flats where trotters lived only fools horses 30 computing does abbreviation usb stand answers 1 saturn 2 tom baker doctor who actors 3 zeta 4 christopher biggins im celebrity get me out here joe pasquale 04 carol thatcher 05 matt willis 06 joe swash 08 5 ramsay macdonald prime ministers post ww1 6 portsmouth fa cup 7 6 8 thomas becket 9 kirstie allsopp 10 cockfighting 11 sky-diving 12 montreal 13 joe mercer 14 white lines 15 robbie fowler 16 hearsay 17 jack hargreaves 18 dawn french 19 margo jerry leadbetter 20 boots 21 mcwhirter ross norris 22 peter falk 23 two 24 clock tower palace westminster london big ben is nickname bell 25 national trust 26 brough superior 27 yellow 28 fungi 29 nelson mandela house 30 universal serial bus like us facebook\n",
      "Cosine similarity: 0.23325041459107987\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 7 : are names twins born brad pitt angelina jolie\n",
      "Answer: growing family angelina jolie brad pitt fly whole brood out la mirror online growing family angelina jolie brad pitt fly whole brood out la brangelina clan are picture family bliss as they fly together lax airport share brad pitt angelina departing flight their kids maddox pax zahara shiloh vivienne knox lax airport los angeles california photo flynet share get celebs updates directly your inbox subscribe could not subscribe try again laterinvalid email jolie-pitt family are impressive bunch arent they hollywood royalty parents six beautiful kids they turn heads wherever they go they certainly did as they departed flight lax airport this week angelina jolie husband brad pitt accompanied their kids maddox pax zahara shiloh vivienne knox california airport brad pitt angelina departing flight their kids maddox pax zahara shiloh vivienne knox lax airport los angeles california photo flynet parents angelina brad sported sunglasses low-key casual outfits as they led their family pack through terminal family recently celebrated mum angelinas 40th birthday last week quiet affair home shunning any offers glossy-magazine-covered affair treasured quality time behind closed doors angelina brad married just last year rumours have been rife that celebrity couple might adopt child syria add their brood this summer brad pitt angelina lead their kids l-r pax vivienne shiloh maddox knox zahara photo flynet brangelina clan consists three natural-born kids three adopted children twins vivienne knox were born 2008 shiloh who now wants be known as john dresses tomboy style was born 2006 brad angelina have become well-known adopting kids around world including maddox cambodia adopted 2002 pax vietnam adopted 2007 zahara ethopia adopted 2005 most read most recent most read most recent\n",
      "Cosine similarity: 0.4228131380653519\n",
      "\n",
      "Answer: pics vivienne knox jolie-pitt birthday branglina twins turn 6 years old hollywood life 26 photos wow six years sure flies fast happy 6th birthday adorable branglina twins vivienne knox jolie-pitt brad pitt 50 angelina jolie 39 have two huge reasons celebrate july 12 its vivienne knox s 6th birthday click inside take look pictures past six years their lives vivienne knox jolie-pitt turn 6 happy 6th birthday can you believe it branglina twins turned 6 years old saturday july 12 miracle twins were born beautiful city nice france 2008 now they are growing up before our own eyes however 2014 was probably twins biggest year yet after all precious little vivi made her big screen debut alongside her mommy angelina blockbuster film maleficent vivienne portrayed very young princess aurora she was perfect role jolie-pitt twins are very special couple they are second third biological children brad angelina came just two years after they welcomed their first child together shiloh jolie-pitt 8 however brangelina love all their children adopted biological same this includes their oldest son maddox 12 pax 10 zahara 9 hopefully we will vivi knox become big brother sister sometime soon wouldnt you love brad angelina welcome another child together vivi knox fun facts about jolie-pitt twins did you know that vivienne knoxs names pay tribute members both brad angelinas families vivienne her middle name marcheline bertrand is actually her grandmother angelinas mothers first name knox his first name was middle name brads grandfather hal knox hillhouse past angelina has said that out all their children knox is most like brad personality-wise she has also shared that vivienne is most girly all three her daughters that she absolutely loves all things pink princess-y happy birthday vivi knox hey hollywoodlifers leave your birthday wishes little vivienne knox jolie-pitt comments below lauren cox\n",
      "Cosine similarity: 0.3044077736591046\n",
      "\n",
      "Answer: list people bolton wow com list people bolton source http en wikipedia orgwikilist_of_people_from_bolton updated 2016-10-24t02 30z this is list notable people bolton north west england demonym bolton is boltonian this list also includes people towns farnworth horwich westhoughton kearsley little lever blackrod other smaller places within wider metropolitan borough bolton this list is arranged alphabetically surname table contents sir richard arkwright 17321792 inventor water frame born preston 8 henry ashworth 1794-1880 cotton mill owner egerton new eagley mills political reformer born birtenshaw farm turton 9 alan ball 19452007 professional footballer member 1966 football world cup winning side born farnworth 14 15 johnny ball born 1938 born bristol moved bolton childrens tv presenter father former bbc radio 1 dj tv host zoÃ« ball 16 17 tommy banks footballer born 1929 bolton wanderers england footballer born farnworth 18 jack bond born 1932 cricketer born kearsley liam boyle born 1985 tv film actor born bolton grew-up heywood 22 23 jack bruton 19031986 footballer bolton wanderers burnley england born westhoughton 24 andrew buchan born 1979 tv stage actor born stockport brought up lostock 25 26 27 c katy cavanagh born 12 december 1973 english actress best known her appearances coronation street role julie carp since 2008 grew up bolton samuel taylor chadwick 18091876 doctor politician philanthropist 28 born urmston grew up bolton sian charlesworth born 1987 member girlband parade d john davis 19432000 cricketer 44 hilary devey born 1957 entrepreneur tv personality dragon bbc2s dragons den 2011 45 born tonge moor sir benjamin alfred dobson 18471898 textile machinery manufacturer mayor bolton 48 f frank finlay 1926-2016 farnworth born stage film television actor 53 54 declan finn born 1965 drogheda educated st cuthberts rc school bolton religious author revolutionary political activist ordained 2005 peter freeman born 1946 heavyweight boxer fought leon spinks 59 g mark halsey born 1961 former english premier league referee lives little lever born essex 69 haseeb hameed born 1997 lancashire england cricketer born bolton 70 ruth hamilton author 71 annie haslam born 1947 lead singer progressive rock band renaissance 75 robert haslam born 1923 industrialist born bolton william haslam 18501898 gave his name town haslam south australia 76 paul heathcote born 1960 chef restaurateur born farnworth 77 stan heptinstall born 1946 professor thrombosis haemostasis university nottingham mayor broxtowe born bolton 78 jack hylton 18921965 band leader 83 born great lever i susan sutherland isaacs 18851948 educational psychologist psychoanalyst born turton 84 85 j david jack 1898-1958 footballer bolton wanderers who scored first goal wembley 1923 86 brian jackson born 1931 actor producer famous as man del monte born bolton as osmond brian jackson ethel johnson 19081964 sprinter who represented great britain 1932 summer olympics born westhoughton 87 danny jones born 1986 guitarist vocalist british pop-rock band mcfly 88 k\n",
      "Cosine similarity: 0.2837132814649211\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 8 : 1964 film goldfinger is name team goldfingers all-female pilots\n",
      "Answer: name define name dictionary com name noun 1 word combination words person place thing body class any object thought is designated called known 2 mere designation as distinguished fact he was king name only 3 appellation title epithet applied descriptively honor abuse etc 4 reputation particular kind given common opinion protect ones good name 5 distinguished famous great reputation fame make name oneself 6 widely known famous person celebrity shes name show business 7 unpleasant derogatory appellation expression dont call your brother names sticks stones may break my bones names will never hurt me 8 personal family name as exercising influence bringing distinction that name they can get loan any bank town 9 body persons grouped under one name as family clan 10 verbal other symbolic representation thing event property relation concept 11 initial capital letter symbol vehicle divinity take name vain power name verb used object named naming 12 give name name baby he was named as thief 14 call epithet they named her speedy identify specify mention name three persons were named report 16 designate some duty office nominate appoint i have named you position 17 give name can you name capital ohio 19 british house commons cite member contempt adjective designed carrying name 23 giving its name title collection anthology containing it name piece she was always careful address every employee name not personally repute i know him name only 25 call names scold speak abusively person better not call names unless one is larger considerably stronger than ones adversary 26 name mercy stop that screaming authority open name law behalf purchase something name another under name possession money deposited name son under designation excuse murder name justice 27 name names specify people name especially those who have been accomplices misdeed witness bribery investigation threatened name names 28 ones name ones possession i havent penny my name origin name old english 900 before 900 middle english old english nama cognate german name gothic namÃ´ akin old norse nafn latin nÅmen greek Ã³noma old irish ainm polish imiÄ™ czech jmÃ©no related forms rename verb used object renamed renaming self-named adjective see more synonyms thesaurus com 1 name title both refer label person is known name is simpler more general word appellation name is john title is official honorary term bestowed person specific designation book article etc he now has title doctor treasure island is title book 4 repute character credit 5 note distinction renown eminence 6 personality 14 nickname dub denominate 16 choose 17 mention dictionary names noun 1 dictionary given names that indicates whether name is usually male female unisex often includes origins as well as meanings example as indicating that evangeline meaning good news comes greek used primarily as aid selecting name baby dictionaries names may also include lists famous people who have shared name information about its current popularity ranking expand examples web name expand contemporary examples some also speculate that name could allude francis xavier co-founder society jesuisaka jesuits british dictionary definitions name expand noun 1 word term p\n",
      "Cosine similarity: 0.36591601269772434\n",
      "\n",
      "Answer: irene name meaning name irene is baby girl name meaning spanish meaning name irene is spanish baby name spanish meaning name irene is peace american meaning name irene is american baby name american meaning name irene is peace greek meaning name irene is greek baby name greek meaning name irene is peace early christian martyr later borne several byzantine empresses numerology soulurge number 1 people this name have deep inner desire use their abilities leadership have personal independence they would rather focus large important issues delegate details expression number 6\n",
      "Cosine similarity: 0.36119682191538494\n",
      "\n",
      "Answer: name marguerite meaning name meaning name toggle navigation name marguerite gender female usage marguerite basque origin is very popular first name it is more often used as girl female name people having name marguerite are general originating belgium france luxembourg switzerland united kingdom united states america another variant name marguerite across world see margarita meaning pearl please feel free read others say about this name share your comments if you have more information n b sometimes it happens that another name has same meaning there is nothing surprising this both names have same origin same numbers numerology test compatibility this name another enter name click growth number corresponding this first name is 9 interpretation learn more our free numerology tool popularity name name marguerite is ranked 1 683rd position most used names it means that this name is very frequently used we estimate that there are least 262900 persons world having this name is around 0 004 population name marguerite has ten characters it means that it is relatively long-length compared other names our database graph below represents number people who were given name marguerite each year since 1900 u s name day marguerite is 16 november other names check our name day calendar history origin marguerite is french form female given name english margaret spanish margarita derives greek Î¼Î±ÏÎ³Î±ÏÎ¯Ï„Î·Ï‚ meaning pearl see also margaret name peggy french form margaret also used english-speaking world where its use has been reinforced fact that name was adopted 19th century garden flower large cultivated variety daisy margaret was earlier used english as dialect word denoting ox-eye daisy french equivalent was borrowed into english just time catch vogue deriving female given names vocabulary words denoting flowers see also daisy section history origin this page contains content copyrighted wikipedia article marguerite given name that content is used under gnu free documentation license gfdl you may redistribute it verbatim modified providing that you comply terms gfdl\n",
      "Cosine similarity: 0.35333194593867\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 9 : christmas day 2000 country officially established new national anthem\n",
      "Answer: nmah national anthem national anthem sing national anthem during 19th century star-spangled banner became one nations best-loved patriotic songs it gained special significance during civil war time many americans turned music express their feelings flag ideals values it represented 1890s military had adopted song ceremonial purposes requiring it be played raising lowering colors despite its widespread popularity star-spangled banner did not become national anthem until 1931 collect stars complete flag found 00 15 did star-spangled banner officially become united statess national anthem 1931 use this resource your classroom armed forces instrumental arrangement during world war i war department established standard arrangement be used u s military bands although this arrangement is often used nonmilitary performances there is no single official version anthem designated civilian use courtesy maryland historical society soprano francis alda 1917 early 1900s star-spangled banner was fixture public ceremonies celebrations courtesy library congress military anthem first official step toward making star-spangled banner national anthem was taken 1889 secretary navy ordered it played morning flag-raising ceremonies 1917 both army navy considered tune be national anthem ceremonial purposes official national anthem 1931 due largely efforts mrs reuben ross holloway president maryland state society united states daughters 1812 congressman j charles linthicum baltimore congress made star-spangled banner official national anthem united states\n",
      "Cosine similarity: 0.3231452761087699\n",
      "\n",
      "Answer: uncategorized archives forked river gazette frgazette leave comment name 5 santas 8 reindeer twas night before christmas poem rudolph doesnt count dasher dancer prancer vixen blitzen comet cupid donner who played main character george bailey film its wonderful life james stewart date is st stephens day 26th december charles dickens novel christmas carol who was scrooges dead business partner jacob marley londons trafalgar square christmas tree is traditionally given country norway christmas carol includes lyrics save us all satans power we were gone astray god rest ye merry gentlemen character jack skellington appears 1993 tim burton film nightmare before christmas is new years eve called scotland hogmanay many maids were a-milking twelve days christmas song 8 who is officially credited as author auld lang syne robert burns song winter wonderland who do we pretend snowman is parson brown film does this quote appear bless this highly nutritious microwavable macaroni cheese dinner people who sold it sale amen home alone red-blooming christmas plant came originally mexico poinsetta actor is narrator 2000 film grinch who stole christmas anthony hopkins pine needles are said be good source vitamin c is zodiac sign people born 25 december capricorn christmas crackers was first christmas edition popular british sitcom only fools horses was queens 1984 christmas single called thank god its christmas many lords were a-leaping twelve days christmas song 10 jackie wilsons re-issued song reet petite became 1986 uk christmas number one after helping advertise brand levis la befana is legendary character who delivers christmas presents children european country italy before tradition hanging stockings up christmas did dutch children hang fireside shoes who banned christmas england between 1647 1660 oliver cromwell christmas island indian ocean is territory country australia child star jimmy boyd sang hugely popular 1950s christmas song was initially banned catholic church boston i saw mommy kissing santa claus is name simpsons pet greyhound santas little helper born christmas day 1954 she had hits such songs as walking broken glass no more i love yous is her name annie lennox word often associated christmas songs stems greek word circle dance carol country is st nicholas called sinterklaas netherlands 1983 who was uk christmas number one only you flying pickets everyone remembers band aid year were they number one uk charts 1984 christmas word means turning sun yuletide many pipers were piping twelve days christmas song 11 city is kevin left home alone christmas first movie chicago do george c scott daffy duck patrick stewart michael caine fred flintstone jim carrey all have common they have all played ebeneezer scrooge christmas song contains these lyrics yellow red ones lets stop all fight happy christmas war is over john lennon traditional english father christmas was not dressed red colour did he wear green who sang 1997 christmas hit i believe father christmas greg lake fruit is used make christingle orange wrestler starred 1996 film santa muscles hulk hogan who played fred claus 2007 movie same name vince vaughan was name boy tv film snowman james who was first british monarch broadcast christmas message george v is baby turkey called poult english victorian cook wrote definitive christmas cookbook mr\n",
      "Cosine similarity: 0.29097779461983225\n",
      "\n",
      "Answer: waitangi day new zealand treaty waitangi february 6th national day waitangi festivals celebrations home featured events waitangi day waitangi day new zealand 6th february 2010 waitangi day 6th february has been annual public holiday since 1974 commerates signing treaty waitangi new zealands founding document 1840 it is generally regarded as focus debate national identity multiculturalism new zealand is celebrated variety events throughout country treaty waitangi waitangi treaty grounds is new zealands pre-eminent historic site as it was here 6th february 1840 that treaty waitangi was first signed between maori british crown this date each year new zealanders all ethnic backgrounds creeds gather commemorate signing treaty about treaty grounds treaty grounds are part waitangi national trust estate gifted nation 1932 grounds are open daily public 9 00am excluding christmas day features treaty grounds include treaty house one new zealands oldest most visited historic homes te whare runanga fully-carved maori meeting house representing all iwi regional tribes new zealand ngatokimatawhaorua one worlds largest maori ceremonial war canoes naval flagstaff marking place where treaty waitangi was signed waitangi visitor centre featuring audio visual shows live cultural performances gift shop artefacts gallery cafe parkland guided tours educational programmes waitangi day events waitangi over 50 000 visitors are expected attend celebrations waitangi this year include maori cultural performances speeches maori pakeha european dignitaries re-launch worlds largest maori ceremonial waka war canoe free three-day family festival music dance sport food traditional maori customs including ki-o-rahi maori game that may be even older than rugby view more information about waitangi day festival 2010 waitangi auckland 8 30 am new zealands largest city national day is celebrated citys birthplace okahu bay domain free family-orientated festivities include traditional powhiri welcome ngati whatua o orakei okahu bay live entertainment cornerstone roots six60 herbs three houses down 1814 traditional food art stalls farm animals kids entertainment stage large childrens rides zone view more about aucklands waitangi day celebrations wellington free family celebrations start 10 00 am waitangi park include blessing ceremony followed musical performances congolese musician sam manzanza wellington pipe band batucada percussion group powhiri formal welcome midday wellington tenths trust traditional kapa haka performances christchurch okains bay akaroa about 90 minutes christchurch main local sites celebration are onuku marae okains bay events include traditional maori welcome onto marae 9 00 am two magnificent carved waka being paddled up river colonial displays exhibits crafts musket shooting cross-cut sawing vintage engines steam engine printing presses childrens games races tug-o-war traditional hangi lunch sausage sizzle refreshments music garden bar find waitangi day events area new zealand that youre visiting simply search online find more information celebrations festivals are held throughout country featured\n",
      "Cosine similarity: 0.2793860253749832\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 10 : who hosted early series pink panther cartoons\n",
      "Answer: torchwood tv series tardis fandom powered wikia show you may wish consult torchwood disambiguation other similarly-named pages torchwood was doctor who television spin-off as in-house bbc wales production digital television station bbc three it was first television spin-off doctor who since pilot k9 company 1981 first be commissioned full 13-part series it originally featured adventures torchwood branch located cardiff later torchwood team that succeeds it was set earth after events doomsday lead character jack harkness events parting ways spin-off series has not yet featured doctor himself though materialisation sound doctors tardis is heard final episode season one other dialogue references have been made most recently torchwood miracle day arc likewise appearance martha jones second series provides vital continuity between third fourth series doctor who conversely jack as well as his team gwen cooper ianto jones featured former team members owen harper toshiko sato are mentioned last two episodes fourth series doctor who regular characters have included gwen cooper jack harkness ianto jones toshiko sato owen harper rex matheson esther drummond martha jones suzie costello vera juarez have also been portrayed as part torchwood team led harkness semi-regulars rhys williams sgt andy davidson are only non-torchwood members who have recurred across all series 12 october 2016 marks 10th anniversary torchwood celebration that due its popularity cast crew have been invited chapter arts centre cardiff special screening very first ever episode be shown fans 1 big finish also produced special audio story celebrate shows anniversary origins edit 2002 before revival doctor who russell t davies began develop idea science-fictioncrime drama style american fantasy drama series like buffy vampire slayer its spin-off series angel this idea originally titled excalibur was abandoned until 2005 bbc three controller stuart murphy invited davies develop post watershed science fiction series channel during production 2005 series doctor who word torchwood anagram doctor who originated during production new doctor who series television pirates were eager get their hands tapes someone production office suggested that tapes be labelled torchwood instead doctor who disguise their contents as they were being sent london davies thought that was clever idea remembered name davies connected word torchwood his earlier excalibur idea decided make series doctor who spin-off subsequently word torchwood was seeded several doctor who episodes other media aired 2005 2006 premise edit series was set contemporary cardiff followed welsh branch covert agency called torchwood institute investigates extraterrestrial incidents earth scavenges alien technology its own use as established doctor who episodes tooth claw army ghosts institute had been formed queen victoria following incident involving tenth doctor werewolf ostensibly protect british empire aliens other creatures as well as doctor himself paraphrase torchwood threes commander-in-chief jack harkness organisation was separate government outside police beyond united nations last reference thereby placing torchwood different realm than unit although secret organisation existence torchwood was known public torchwood operatives made no secret their identity w\n",
      "Cosine similarity: 0.27372051221603927\n",
      "\n",
      "Answer: poll best long running british tv comedy imdb imdb poll best long running british tv comedy poll cartman_1337 these uk tv comedy shows that lasted least 4 series is funniest scripted mainly comedy shows no talk shows game shows shows where comedy part was secondaryincidental only entirely uk productions limited 31 most popular shows based imdb ratings 2 000 votes more plus 4 longest running shows fewer votes check out this poll shows that lasted less than 4 series 5 series significantly longer series than common uk see moresee less bit fry laurie 1987 4 series are you being served 1972 10 series benny hill show 1969 19 series not live your life 2007 4 series last summer wine 1973 31 series british men behaving badly 1992 7 series monty pythons flying circus 1969 4 series one foot grave 1990 6 series only fools horses 1981 9 series that mitchell webb look 2006 4 series thick it 2005 4 series vicar dibley 1994 5 series two pints lager packet crisps 2001 9 series\n",
      "Cosine similarity: 0.25398607948355867\n",
      "\n",
      "Answer: ant aardvark inspector crazylegs crane coming blu-ray ant aardvark inspector crazylegs crane coming blu-ray 12 animation director friz freleng may have died 21 years ago hes having more success hollywood this month than many living directors yesterday we announced that warner bros was developing animated feature starring speedy gonzales character that was popularized freleng 1950s later this month film distributor kino lorber will release complete collections shorts featuring ant aardvark crazylegs crane three characters that came out frelengs animation studio depatie-freleng he co-owned between 1963 1981 kino lorbers studio classics division is releasing new hd transfers shorts both blu-ray dvd editions later this year company plans release additional collections depatie-freleng series including roland rattfink tijuana toads blue racer sheriff hoot kloot dogfather misterjaw partner message made during last throes hollywood theatrical shorts production inspector ant aardvark series have much recommend including smartly made animation budget that often exceeds current american tv standards minimalist yet striking production design some surprising elements like jazz scores ant aardvark series performed top west coast jazz musicians unfortunately crazylegs crane post-theatrical tv series has much less offer terms quality depatie-freleng most famous its pink panther series never achieved true greatness any its productions these kino-lorber sets offer welcome opportunity contemporary viewers reassess their output lots talented people worked these cartoons theres creative inspiration waiting be discovered certain aspects studios output best news is that sets are quite affordable all them will include following documentaries greg ford goodbye warner bros hello depatie-freleng aardvarks ants inspectors cranes featuring jerry beck barbara donatelli will friedwald doug goodwin art leonardi joe siracusa archival audio friz freleng inspector collection includes all 34 theatrical shorts created between 1965-1969 ant aardvark collection contains all seventeen theatrical shorts created between 1969-1971 crazylegs crane disc includes all 16 made-for-tv shorts that appeared 1978 all new pink panther show heres cover art both tijuana toads roland rattfink courtesy amazon ea i had no idea those three dogs 1993 pink panther show were another cartoon series dogfather mesterius can we please get comment someone know about depatie-frelengs original pink panther shorts will be released blu-ray i know theyre different copyright its still bit absurd see all these lesser-known series d-f get hd treatment before their biggest star mister twister as long as its original 4 3 aspect ratio is kept transfer is done properly not disney does its old movies i am sold metlow rovenstein i saw screenshots blu-ray release transfer is both 4 3 was done properly mister twister funny cartoony appealing well-designed characters concept jhalpernkitcat i love that theyre finally getting released single inexpensive format im especially excited roland rattfink onevery underrated series my opinion abdullah zubair other than pink panther these 3 i havent watched any his other work are they just as good also i felt that was terrible way start article humor about death money jhalpernkitcat id avoid hoot kloot thats one about clueless western sheriff ive seen few shorts character is absolutely unlikable not very kind his horse blue racer is hit missi\n",
      "Cosine similarity: 0.22151504228718724\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def retrieve_k_relevant_results(query: str, k: int) -> dict:\n",
    "    retrieved = {}\n",
    "    e_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "    query_similarity = cosine_similarity_1_to_n(e_query, valid_answers_bows)\n",
    "    top_indices = top_k_indices(query_similarity, k)\n",
    "    for idx in top_indices:\n",
    "        ans = answers_dataset['validation'][idx]['answer']\n",
    "        cos_sim = query_similarity[idx]\n",
    "        retrieved[ans] = cos_sim\n",
    "    return retrieved \n",
    "\n",
    "for i, row in enumerate(sampled_queries.iterrows(), start=1):\n",
    "    idx, data = row \n",
    "    q = data['query']\n",
    "    oq = data['original_query']\n",
    "    print(f\"Query {i} : {oq}\")\n",
    "    retrieved = retrieve_k_relevant_results(q, 3)\n",
    "    for key, value in retrieved.items():\n",
    "        print(f\"Answer: {key}\")\n",
    "        print(f\"Cosine similarity: {value}\\n\")\n",
    "    print(50*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Term Frequency - Inverse Document Frequency\n",
    "\n",
    "In this section we will implement the TF-IDF algorithm. While BOW is a simple way to represent the documents, it has some limitations. For example, it does not take into account the importance of each word in the document. TF-IDF representation takes into account the frequency of each word in the document and the frequency of the word in the whole dataset. It is a widely used technique in information retrieval and text mining. Refer to the lecture slides for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inverse Document Frequency\n",
    "\n",
    "<a name='e9'></a>\n",
    "#### Exercise 9: Inverse Document Frequency (IDF)\n",
    "In this exercise, you will implement the TF-IDF algorithm. First, calculate Inverse Document Frequency (IDF) for each word in the vocabulary. Intuitively, it is a measure of how informative a word is based on the whole dataset. Consult the lecture slides for the details. The IDF is calculated as follows:\n",
    "$$\n",
    "IDF(t) = log_{10}(N/df(t))$$\n",
    "where $N$ is the total number of documents (sentences) in the dataset and $df(t)$ is the number of documents containing the word $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_idf(bows):\n",
    "    \"\"\"\n",
    "    Calculates the IDF for each word in the vocabulary\n",
    "    Args:\n",
    "        bows: numpy array of size (N x D) where N is the number of documents and D is the vocabulary size\n",
    "\n",
    "    Returns: a numpy array of size D with IDF values for each token\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    dim = bows.shape \n",
    "    D = dim[-1]\n",
    "    N = dim[0]\n",
    "    df = np.count_nonzero(bows, axis=0)\n",
    "    idf = np.log10(N / df)\n",
    "\n",
    "    return idf\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To avoid the data leakage, the IDF should be calculated the train subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47982/47982 [00:12<00:00, 3768.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_answers_bows = []\n",
    "for example in tqdm.tqdm(answers_dataset['train']):\n",
    "    train_answers_bows.append(bag_of_words(example['answer_tokens'], token_to_id))\n",
    "\n",
    "train_answers_bows = np.array(train_answers_bows)\n",
    "\n",
    "idf = calculate_idf(train_answers_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Full TF-IDF\n",
    "\n",
    "<a name='e10'></a>\n",
    "#### Exercise 10: TF-IDF\n",
    "- Calculate TF-IDF on the `test` subset of the dataset.\n",
    "- Analyze the search results based on your implemented TF-IDF. Does the search perform well? When does it fail? Discuss several examples that are we get an expected but also unexpected results (find at least 3 from each category). Provide reasons for the good/bad result in each case (e.g. is there some error in the data, is there some linguistic phenomenon that we don't capture, is something wrong with our modeling with average embeddings, ...)\n",
    "- Compare the results with the ones you got with the bag-of-words representation. Discuss the differences and similarities. Do you think TF-IDF is a better representation for this task? Why or why not? Provide examples to support your arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# You can implement the following functions, but you can also use your own design.\n",
    "\n",
    "def calculate_tf_idf_n(bows, idf):\n",
    "    \"\"\"\n",
    "    Calculates the TF-IDF for each word in the vocabulary\n",
    "    Args:\n",
    "        bows: numpty array of size (N x D) where N is the number of documents and D is the vocabulary size\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    Returns: a numpy array of size (N x D) with TF-IDF values for each document and each token\n",
    "\n",
    "    \"\"\"\n",
    "    tf = bows / np.sum(bows, axis=1, keepdims=True) # normalized tf\n",
    "    tf_idf = tf * idf \n",
    "    return  tf_idf\n",
    "\n",
    "\n",
    "def calculate_tf_idf(bow, idf):\n",
    "    \"\"\"\n",
    "    Calculates the TF-IDF for a single document\n",
    "    Args:\n",
    "        bow: a numpy array of size D with the bag-of-words representation of the document\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    Returns: a numpy array of size D with TF-IDF values for each token\n",
    "\n",
    "    \"\"\"\n",
    "    bow_sum = np.sum(bow)\n",
    "    if bow_sum > 0:\n",
    "        tf = bow / bow_sum\n",
    "    else:\n",
    "        tf = bow\n",
    "\n",
    "    tf_idf = tf * idf\n",
    "    return tf_idf\n",
    "\n",
    "\n",
    "def embed_tf_idf(sentence, token_to_id, idf):\n",
    "    \"\"\"\n",
    "    Embeds the sentence using TF-IDF\n",
    "    Args:\n",
    "        sentence: a list of tokens\n",
    "        token_to_id: a dictionary mapping each word to an index in the vocabulary\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    Returns: a numpy array of size D with TF-IDF values for each token\n",
    "\n",
    "    \"\"\"\n",
    "    bow = bag_of_words(sentence, token_to_id)\n",
    "    tf_idf = calculate_tf_idf(bow, idf)\n",
    "    return tf_idf\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: was name representative body pre-revolutionary russia that was revived 1905\n",
      "[[0.00111717 0.         0.00053272 ... 0.         0.         0.        ]\n",
      " [0.00078871 0.         0.00153572 ... 0.         0.         0.        ]\n",
      " [0.00012258 0.00099236 0.00013639 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.00013689 0.00249354 0.00015231 ... 0.         0.         0.        ]\n",
      " [0.00437899 0.         0.00100806 ... 0.         0.         0.        ]\n",
      " [0.00109748 0.00083295 0.00076319 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "query = dataset['validation'][0]['query']\n",
    "print('query:', query)\n",
    "query_tfidf = embed_text(query, clean, tokenize, lambda x: embed_tf_idf(x, token_to_id, idf))\n",
    "\n",
    "answers_tfidf = calculate_tf_idf_n(valid_answers_bows, idf)\n",
    "print(answers_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word Embeddings\n",
    "\n",
    "\n",
    "Word embeddings are a powerful model for representing words and their meaning (in terms of distributional similarity). As we discussed in class, we can use them in a wide variety of tasks with more complex architectures. Word vectors offer a dense vector for each word.\n",
    "\n",
    "In this section you will load the pre-trained word embeddings model - Glove. You can read more about it [here](https://aclanthology.org/D14-1162/) ([https://aclanthology.org/D14-1162/](https://aclanthology.org/D14-1162/)). The embeddings are trained on a large corpus of text and are available in different dimensions. We will start with the dimension of 100, but later you will be asked to experiment with other dimensions.\n",
    "\n",
    "You can download the embeddings manually from one of the following links:\n",
    "- https://www.kaggle.com/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/data?select=glove.6B.50d.txt\n",
    "- https://github.com/nishankmahore/word2vec-flask-api (check the table in the readme)\n",
    "\n",
    "The extracted files should contain several models but for now we will be using the 50-dimensional one. This means that each token is represented as a 50-dimensional floating point vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_embeddings_path = 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raulparau/Desktop/NLP/Lab_1/NLP_Labs1_Group18/Lab2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will load and parse this file line-by-line. Your job in the next exercise is the parsing part.\n",
    "\n",
    "<a name='e11'></a>\n",
    "#### Exercise 11: Parsing the embeddings\n",
    "Implement the following function to parse a single line of the glove embeddings file. The line contains string values separated by spaces. The first value is the token and the rest are the elements of the embedding vector (the values should be cast to float). You can inspect the file to get a better idea of what is there. Return both the token (as string) and the embedding (as a numpy array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_embeddings_row(line):\n",
    "    \"\"\"\n",
    "    Parses a single line from the GloVe embeddings file. The line contains a word followed by its embedding values separated by spaces.\n",
    "    Args:\n",
    "        line: a line from the GloVe embeddings file\n",
    "\n",
    "    Returns: a tuple (word, embedding) where 'word' is a string and 'embedding' is a numpy array of floats\n",
    "    \"\"\"\n",
    "    line_split = line.split()\n",
    "    ### YOUR CODE HERE\n",
    "    token = line_split[0]\n",
    "    embedding = np.array([float(x) for x in line_split[1:]])\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return token, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we load the file and iterate over the lines to load the tokens and their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "embeddings = []\n",
    "with open(glove_embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        token, embedding = parse_embeddings_row(line)\n",
    "        tokens.append(token)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "embeddings = np.stack(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will create a class `WordEmbeddings` that will hold embeddings and expose useful methods to embed a single token (`embed_token()`) and the whole sentence (`embed_sentence()`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sentence Embeddings by Averaging Word Embeddings\n",
    "In the course, we will see different architectures that take into account the sequence of words (by combining their vectors). A first naive but simple and sometimes (as we are going to see) quite effective approach would be to represent a sentence with an embedding vector that is the average of the word vectors that form the sentence.\n",
    "\n",
    "So formally, this is what we are aiming for:\n",
    "\n",
    "$\n",
    "\\text{Sentence_Embedding} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Word_Embedding}_i\n",
    "$\n",
    "\n",
    "where:\n",
    "* $N$ is the number of words in a sentence\n",
    "* $\\text{Word_Embedding}_i$ is the word vector for the $i$-th in the sentence.\n",
    "\n",
    "Things to note:\n",
    "* The embedding vector for the sentence will obviously have the same dimension as the word embedding.\n",
    "* This representation ignores the word order (like bag-of-words). During the course we will see how we can overcome this limitation by using sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e12'></a>\n",
    "#### Exercise 12: Word Embeddings Class\n",
    "Implement the two methods in the following class:\n",
    "- `embed_token()` - accepts a token to be embedded. Use `self.token_to_id` to find the row in the `self.embeddings` attribute. If the token is outside the vocabulary, return `None`.\n",
    "- `embed_sentence()` - accepts a list of tokens that form a sentence. Each token (that is inside the vocabulary) should be embedded. The second parameter `reduction` will determine how the embedded tokens are \"reduced\". There are three options: `mean` should average the tokens (resulting in a single numpy array of size `embedding_dim`, which is 50 for our model), `sum` should sum the tokens, and `none` should return the embeddings of all tokens as a single numpy array (the array should be of shape `(N, embedding_dim)`). Think about a situation where none of the tokens in a sentence is in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WordEmbeddings:\n",
    "    def __init__(self, vocabulary, embeddings):\n",
    "        \"\"\"\n",
    "        Initializes the WordEmbeddings object.\n",
    "        Args:\n",
    "            vocabulary: list of str\n",
    "            embeddings: np.ndarray of shape (vocab_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        self.token_to_id = {token: i for i, token in enumerate(vocabulary)}\n",
    "        self.id_to_token = {i: token for i, token in enumerate(vocabulary)}\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def embed_token(self, token):\n",
    "        \"\"\"\n",
    "        Embed a single token into its word embedding.\n",
    "        Args:\n",
    "            token: str, the token to embed\n",
    "\n",
    "        Returns: np.ndarray with the embedded token or None if the token is not in the vocabulary\n",
    "        \"\"\"\n",
    "        embedding = None\n",
    "        ### YOUR CODE HERE\n",
    "        tid = self.token_to_id.get(token)\n",
    "        if tid is not None:\n",
    "            embedding = self.embeddings[tid]\n",
    "\n",
    "\n",
    "        ### YOUR CODE ENDS HERE\n",
    "        return embedding\n",
    "\n",
    "    def embed_sentence(self, tokens, reduction='none'):\n",
    "        \"\"\"\n",
    "        Embed a sentence (list of tokens) into word embeddings. Reduction can be 'none', 'mean', or 'sum'.\n",
    "        If 'reduction' is 'none', returns a 2D array of shape (len(tokens), embedding_dim). If 'mean' or 'sum',\n",
    "        returns a 1D array of shape (embedding_dim,) with the values averaged or summed respectively.\n",
    "        Args:\n",
    "            tokens: list of str\n",
    "            reduction: str, one of 'none', 'mean', 'sum'\n",
    "\n",
    "        Returns: np.ndarray with the embedded sentence\n",
    "        \"\"\"\n",
    "        embedding = None\n",
    "        ### YOUR CODE HERE\n",
    "        embedding = np.zeros((len(tokens), self.embeddings.shape[1]))\n",
    "        for i, token in enumerate(tokens):\n",
    "            t_embedded = self.embed_token(token) \n",
    "            if t_embedded is not None:\n",
    "                embedding[i] = t_embedded\n",
    "    \n",
    "        if reduction == 'none':\n",
    "            return embedding\n",
    "        elif reduction == 'sum':\n",
    "           embedding = np.sum(embedding, axis=0) \n",
    "        elif reduction == 'mean':\n",
    "            embedding = np.mean(embedding, axis=0)\n",
    "\n",
    "        ### YOUR CODE ENDS HERE\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove50_model = WordEmbeddings(tokens, embeddings)\n",
    "del tokens, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's test the method `embed_sentence()`. Notice the shape of the returned arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 50)\n",
      "[[ 6.8938e-01 -1.0644e-01  1.7083e-01 -3.7583e-01  7.5170e-01  7.8149e-04\n",
      "  -5.3102e-01 -1.9903e-01 -1.4419e-01  1.2748e-01]\n",
      " [ 9.6193e-01  1.2516e-02  2.1733e-01 -6.5390e-02  2.6843e-01  3.3586e-01\n",
      "  -4.5112e-01 -6.0547e-01 -4.6845e-01 -1.8412e-01]\n",
      " [-1.0919e-03  3.3324e-01  3.5743e-01 -5.4041e-01  8.2032e-01 -4.9391e-01\n",
      "  -3.2588e-01  1.9972e-03 -2.3829e-01  3.5554e-01]\n",
      " [ 2.2106e-02 -3.7986e-01 -2.4854e-01 -5.2531e-01  1.8409e-01 -1.4138e-01\n",
      "  -3.8693e-01  1.0206e-01  1.4069e-02  2.9950e-01]\n",
      " [-1.4578e-01  5.0459e-01  4.7525e-02 -4.6463e-01  4.4249e-01 -1.6772e-01\n",
      "  -4.0334e-01 -3.9223e-01 -4.1543e-01  2.7637e-01]]\n",
      "(50,)\n",
      "[ 0.30530882  0.0728092   0.108915   -0.394314    0.493406   -0.0932737\n",
      " -0.419658   -0.21853456 -0.2504582   0.174954  ]\n"
     ]
    }
   ],
   "source": [
    "embedding = glove50_model.embed_sentence('how are you doing ?'.split(' '))\n",
    "print(embedding.shape)\n",
    "print(embedding[:, :10])\n",
    "embedding = glove50_model.embed_sentence('how are you doing ?'.split(' '), reduction='mean')\n",
    "print(embedding.shape)\n",
    "print(embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Similarities between words\n",
    "\n",
    "The function below returns the most similar words to the word provided. The returned list does not contain the word itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def most_similar_words(word, model:WordEmbeddings, k):\n",
    "    \"\"\"\n",
    "    Finds the k most similar words to the given word using cosine similarity.\n",
    "    The returned list should contain tuples (word, similarity) sorted by similarity (descending from the most similar).\n",
    "    Args:\n",
    "        word: str, the word to find similar words for\n",
    "        model: WordEmbeddings, the word embeddings model\n",
    "        k: int, the number of similar words to return\n",
    "\n",
    "    Returns: list of tuples (word, similarity)\n",
    "    \"\"\"\n",
    "    embedding = model.embed_token(word)\n",
    "    if embedding is None:\n",
    "        return []\n",
    "\n",
    "    word_id = model.token_to_id[word]\n",
    "    all_embeddings = model.embeddings\n",
    "    similarity = cosine_similarity_1_to_n(embedding, all_embeddings)\n",
    "    top_indices = top_k_indices(similarity, k=k + 1).tolist()\n",
    "    most_similar = []\n",
    "    for id in top_indices:\n",
    "        if id == word_id:\n",
    "            continue\n",
    "        most_similar.append((model.id_to_token[id], similarity[id].item()))\n",
    "    return most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('why', 0.9699442918090453), ('how', 0.963433857898416), ('nothing', 0.9529852102164589), ('something', 0.9517912498824408), ('think', 0.9498580859242691), ('anything', 0.9433502901683886), ('know', 0.9372829348226743), ('we', 0.9367746453514688), ('fact', 0.9330813240517835), ('certainly', 0.9317318823689156)]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar_words('what', glove50_model, k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next function contains the code to plot a similarity matrix between multiple words (e.g. if we want to compare 10 words and their pair-wise similarities). It requires a matrix with similarities (as input) and labels (aka the words) to display in the final figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_similarity_matrix(matrix, labels):\n",
    "    \"\"\"\n",
    "    Displays a plot of the `matrix` of size (N x N) with the labels specified as a list of size N\n",
    "    Args:\n",
    "        matrix: a square-sized (N x N) numpy array\n",
    "        labels: a list of strings of hte size N\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(matrix)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "    ax.set_yticks(np.arange(len(labels)), labels=labels)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{matrix[i, j]:.2f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e13'></a>\n",
    "#### Exercise 13: Plotting similarities between words\n",
    "\n",
    "In the following, we will explore some properties of word embeddings through some examples. We will use 6 example words for this purpose but experiment with other set of words as well. Fill in the next cell to create a similarity matrix between a list of words.\n",
    "\n",
    "Experiment with different words and their similarities plotted. Try at least 2 more (different) sets of words of at least 6 words each. Use the `plot_similarity_matrix` function to visualize the results.\n",
    "Comment on the results. Do they make sense? Why some words are closer to each other than others? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_words = ['love', 'hate', 'life', 'equal', 'alive', 'dead']\n",
    "\n",
    "similarity_matrix = np.zeros((len(list_of_words), len(list_of_words)), dtype=float)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "embeddings_list = []\n",
    "for word in list_of_words:\n",
    "    embedding = glove50_model.embed_token(word)\n",
    "    embeddings_list.append(embedding)\n",
    "\n",
    "embeddings_array = np.array(embeddings_list)\n",
    "\n",
    "similarity_matrix = embeddings_array @ embeddings_array.T\n",
    "\n",
    "norms = np.linalg.norm(embeddings_array, axis=1, keepdims=True)  # (6, 1)\n",
    "similarity_matrix = similarity_matrix / (norms @ norms.T)\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "plot_similarity_matrix(similarity_matrix, list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Back to Sentence Embeddings\n",
    "\n",
    "Let us go back to embedding the whole sentences by averaging the embeddings in the sentence. Below you can find a code snippet that uses our `embed_text()` function and glove model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = 'fox and deer'\n",
    "print(query)\n",
    "\n",
    "query_embedding = embed_text(query, clean, tokenize, lambda x: glove50_model.embed_sentence(x, reduction='mean'))\n",
    "print(query_embedding.shape)\n",
    "print(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e14'></a>\n",
    "#### Exercise 14: Analyze sentence embeddings\n",
    "- Calculate similarity between the word embeddings representations of the selected queries and the dataset sentences.\n",
    "- Analyze the search results. Does the search work as expected? Discuss the results.\n",
    "- Compare the results with the ones you got with the bag-of-words and TF-IDF representation. Discuss the differences and similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Evaluating Retrieval\n",
    "\n",
    "In this last section we will try to evaluate how good our sentence retrieval system is. To keep the computational resources manageable, we will use the test set for that as its size is more manageable.\n",
    "\n",
    "Recall from the lecture in IR that there are several metrics to evaluate retrieval performance by taking into account the relevance of the retrieved results to the query. We will use Recall@K here (for more metrics and more details refer to the lecture slides and the textbooks).\n",
    "\n",
    "Recall@K is a metric used to measure the effectiveness of a search system in retrieving relevant documents within the top $K$ retrieved documents. It calculates the proportion of relevant documents retrieved within the top-$K$ results, compared to the total number of relevant documents in the collection.\n",
    "\n",
    "$\n",
    "\\text{Recall@K} = \\frac{\\text{Number of relevant documents retrieved in the top }-K}{\\text{Total number of relevant documents}}\n",
    "$\n",
    "\n",
    "In our case, we have a sentence, and it's compressed version. To test our system, we will treat compressed sentences as the queries. Each query will have only a single relevant sentence - the corresponding uncompressed sentence.\n",
    "\n",
    "Therefore, for the calculation of Recall@K we will take into account whether the correct retrieved result is contained within the first $K$ retrieved results. For example, if for a query (i.e. a compressed sentence) we retrieve 10 results and within these we see the relevant one (i.e. the full sentence), then Recall@10 = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e15'></a>\n",
    "### Exercise 15: Cosine similarity between two sets of vectors\n",
    "\n",
    "In this exercise you will revisit your implementation of the cosine similarity. Generalize it so that it can accept two arrays containing two sets of vectors (first one containing $M$ vectors and the second one $N$ vectors). Compute the cosine similarity between each pair of vectors coming from the two sets. The result should be an array of size $M x N$.\n",
    "\n",
    "Once again, try to write an efficient code. This means no loops. Remember the relation between matrix multiplication and dot product. (Depending on your implementation of the previous function calculating cosine similarity, this one can be almost the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_m_to_n(vectors, other_vectors):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between a multiple vectors and other vectors.\n",
    "    Args:\n",
    "        vectors: a numpy array representing M number of vectors of D dimensions (of the size MxD)\n",
    "        other_vectors: a 2D numpy array representing other vectors (of the size NxD, where N is the number of vectors and D is their dimension)\n",
    "\n",
    "    Returns: a numpy array of cosine similarity between all the vectors and all the other vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will use your implementation to calculate Recall@K based on the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_recall(queries, sentences, labels, k, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Calculates recall@k given the embeddings of the queries and sentences.\n",
    "    Assumes that only a single sentence with the same index as query is relevant.\n",
    "    Batching is implemented to avoid high memory usage.\n",
    "    Args:\n",
    "        queries: a numpy array with the embeddings of N queries\n",
    "        sentences: a numpy array with the embeddings of N sentences available for retrieval\n",
    "        k: number of top results to search for the relevant sentence\n",
    "        batch_size: number of queries to process at a time\n",
    "\n",
    "    Returns: calculated recall@k\n",
    "\n",
    "    \"\"\"\n",
    "    n_queries = queries.shape[0]\n",
    "    correct = np.zeros(n_queries, dtype=bool)\n",
    "\n",
    "    with tqdm.tqdm(total=n_queries) as pbar:\n",
    "        for batch_start in range(0, n_queries, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, n_queries)\n",
    "            queries_batch = queries[batch_start:batch_end]\n",
    "            batch_similarity = cosine_similarity_m_to_n(queries_batch, sentences)\n",
    "\n",
    "            for i, similarity_row in enumerate(batch_similarity):\n",
    "                query_index = batch_start + i\n",
    "                top_k = top_k_indices(similarity_row, k=k, sorted=False)\n",
    "                label = labels[query_index]\n",
    "                if label in top_k:\n",
    "                    correct[query_index] = True\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    recall = np.sum(correct) / n_queries\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we embed both the queries and answers from the validation subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query_embeddings = []\n",
    "expected_answers = []\n",
    "for example in tqdm.tqdm(dataset['validation']):\n",
    "    query_tokens = example['query_tokens']\n",
    "    query_embeddings.append(glove50_model.embed_sentence(query_tokens, reduction='mean'))\n",
    "    expected_answers.append(example['answer_id'])\n",
    "query_embeddings = np.stack(query_embeddings, axis=0)\n",
    "expected_answers = np.array(expected_answers)\n",
    "\n",
    "answers_embeddings = []\n",
    "for example in tqdm.tqdm(answers_dataset['validation']):\n",
    "    answer_tokens = example['answer_tokens']\n",
    "    answers_embeddings.append(glove50_model.embed_sentence(answer_tokens, reduction='mean'))\n",
    "answers_embeddings = np.stack(answers_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use the recall function like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall_at_1 = calculate_recall(query_embeddings, answers_embeddings, expected_answers, k=1, batch_size=1000)\n",
    "print(f'\\n{recall_at_1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e16'></a>\n",
    "### Exercise 16: Evaluating retrieval methods\n",
    "\n",
    "Calculate recall for different values of $K$ for all methods:\n",
    "- BOW,\n",
    "- TF-IDF,\n",
    "- Pre-trained embeddings.\n",
    "- Another pre-trained embeddings (for example with larger embedding vectors)\n",
    "\n",
    "Make sure to test on the `test` split. Discuss the results. Comment on how recall changes based on the value of $K$. Are the results expected or surprising?\n",
    "\n",
    "The deliverable for this whole lab is a scientific poster and this last question should be the main thing you will include in the poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplab2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
