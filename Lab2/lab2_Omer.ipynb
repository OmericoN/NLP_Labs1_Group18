{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# NLP 2026\n",
    "# Lab 2: Word Vectors and Information Retrieval\n",
    "## *alt*-title: üöÄ Project CleanSearch AI, a DOGE initiative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## üèõÔ∏èüêï PRESS RELEASE ‚Äî For Immediate (and Maximum Efficiency) Distribution  \n",
    "\n",
    "### The Department of Outdated Government Encyclopedias (DOGE) Launches Revolutionary NLP Project to Rescue Public Knowledge  \n",
    "\n",
    "**Washington, D.C.** ‚Äî In a bold step toward modernizing the nation‚Äôs most chaotic digital archives, the   **Department of Outdated Government Encyclopedias (DOGE)** today announced the launch of its new initiative:  üöÄ **Project CleanSearch AI**.\n",
    "\n",
    "For decades, citizens have struggled to find simple answers hidden inside massive, noisy, and poorly structured government knowledge repositories.\n",
    "\n",
    "Questions such as:\n",
    "\n",
    "- ‚ÄúWho won the Nobel Prize in 1930?‚Äù  \n",
    "- ‚ÄúWhen did Angola become independent?‚Äù  \n",
    "\n",
    "have resulted in thousands of irrelevant web pages, confusing biographies and excessive scrolling üìâ\n",
    "\n",
    "> *‚ÄúFrankly, our archives are a mess,‚Äù* said a DOGE spokesperson.  \n",
    "> *‚ÄúThey‚Äôre long, noisy and about as searchable as a pile of printed Wikipedia pages thrown into a hurricane.‚Äù*\n",
    "\n",
    "### üß† The Solution  \n",
    "\n",
    "DOGE has assembled an elite team of AI specialists, hired from UM DACS 2nd year bachelor program with the following goals:\n",
    "\n",
    "‚úÖ Clean decades of messy digital text  \n",
    "‚úÖ Extract meaningful knowledge  \n",
    "‚úÖ Replace outdated keyword search with modern **retrieval systems**  \n",
    "‚úÖ Deliver instant, accurate answers to citizens  \n",
    "\n",
    "Using real-world noisy data similar to the government‚Äôs archives, the team will experiment with multiple retrieval models to determine the most efficient approach, methods which have been taught in the fabulous classes of some person quoted as J.S. \n",
    "\n",
    "Whispers across the digital corridors suggest that DOGE may soon supercede the legendary Project 2-2, though DACS management insist these rumours are ‚Äúunder control.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deliverable:\n",
    "\n",
    "- You are asked to deliver **two files only**:\n",
    "  - your executed notebook file (`.ipynb`), and\n",
    "  - your poster (`.pdf`).  \n",
    "  No other files will be taken into consideration.\n",
    "  \n",
    "‚ö†Ô∏è ‚ö†Ô∏è ‚ö†Ô∏è Each part of the poster will contribute to your grade proportionally to what we present below. If we can't find the relevant part in your notebook (e.g. the figure or the code to support your findings) we will reduce (or even zero-out) your grade for that part.\n",
    "\n",
    "### Instructions for the poster: \n",
    "\n",
    "The final deliverable for this lab is a **scientific poster** presenting your work on building and evaluating a sentence retrieval system using the TriviaQA dataset.\n",
    "- üìè **Size:** A0 or A1  \n",
    "- üß≠ **Orientation:** Portrait or landscape (your choice)  \n",
    "- üìë **Layout:** Clear section structure (e.g., columns or blocks)  \n",
    "\n",
    "#### Your poster should include the following sections:\n",
    "---\n",
    "#### 1Ô∏è‚É£ Problem & Motivation üéØ\n",
    "- Describe the retrieval task (query ‚Üí correct answer document) and the challenges\n",
    "- Briefly introduce the dataset and its challenges  \n",
    "#### 2Ô∏è‚É£ Data Preparation üßπ\n",
    "Explain:\n",
    "- Train / validation / test splitting  \n",
    "- Your cleaning pipeline (at least 6 preprocessing steps)  \n",
    "Include at least one **before vs after cleaning** example.\n",
    "#### 3Ô∏è‚É£ Retrieval Models ü§ñ\n",
    "Present and explain the modes you used:\n",
    "- Bag-of-Words + cosine similarity  \n",
    "- TF-IDF + cosine similarity  \n",
    "- Sentence embeddings (averaged word embeddings)  \n",
    "- [any other model?] \n",
    "Discuss strengths and limitations of each.\n",
    "#### 4Ô∏è‚É£ Qualitative Analysis üîç\n",
    "Provide:\n",
    "- At least **3 successful retrieval examples**  \n",
    "- At least **3 failure cases**  \n",
    "Explain why each worked or failed.\n",
    "#### 5Ô∏è‚É£ Quantitative Evaluation üìä (Main focus)\n",
    "Report **Recall@K** (and possibly other metrics) on the **test set** for all methods:\n",
    "- BOW  \n",
    "- TF-IDF  \n",
    "- Pre-trained embeddings  \n",
    "- [Additional models]  \n",
    "Include relevant table(s) and/or plot(s) and briefly discuss trends.\n",
    "#### 6Ô∏è‚É£ Discussion & Recommendations üí°\n",
    "Conclude with:\n",
    "- Which method you would recommend and why  \n",
    "- Key tradeoffs  \n",
    "- Possible improvements  \n",
    "### üé® Optional Creative Element (Bonus)\n",
    "\n",
    "You may (optionally) present your poster within the fictional storyline of üèõÔ∏è **DOGE ‚Äî Department of Outdated Government Encyclopedias**, where your retrieval system modernizes chaotic national archives and replaces legacy keyword search. Creativity is welcome, but scientific clarity is the priority. We will vote for the \"most creative poster\".\n",
    "\n",
    "---\n",
    "\n",
    "### üìè Evaluation Focus\n",
    "\n",
    "Posters will be assessed on:\n",
    "- Correctness of the pipeline incl. the code (25%)\n",
    "- Clarity of explanations and interpretations of results (25%)\n",
    "- Quality of analysis (20%)\n",
    "- Proper use of evaluation metrics (e.g. Recall@K) (10%)\n",
    "- Visual organization (10%)\n",
    "- Discussion and recommendations (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "As in the last lab, we will be using huggingface datasets library ([https://huggingface.co/datasets](https://huggingface.co/datasets)). We will work with TriviaQA dataset ([https://huggingface.co/datasets/sentence-transformers/trivia-qa](https://huggingface.co/datasets/sentence-transformers/trivia-qa)), which contains pairs of queries and articles that contain the answer.\n",
    "\n",
    "In this section we will prepare the dataset, aka clean the sentences and tokenize. We will additionally extract the answers, as some articles correspond to multiple queries. We will create a separate dataset from the unique answers. We will do that for each split separately, so that we can test our retrieval fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start with importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from datasets import DatasetDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading\n",
    "Now, we can begin loading the dataset and inspecting the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'answer'],\n",
      "        num_rows: 73346\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('sentence-transformers/trivia-qa')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Which American-born Sinclair won the Nobel Prize for Literature in 1930?', 'answer': 'The Nobel Prize in Literature 1930 The Nobel Prize in Literature 1930 Sinclair Lewis The Nobel Prize in Literature 1930 Sinclair Lewis Prize share: 1/1 The Nobel Prize in Literature 1930 was awarded to Sinclair Lewis \"for his vigorous and graphic art of description and his ability to create, with wit and humour, new types of characters\". Photos: Copyright ¬© The Nobel Foundation Share this: To cite this page MLA style: \"The Nobel Prize in Literature 1930\". Nobelprize.org. Nobel Media AB 2014. Web. 18 Jan 2017. <http://www.nobelprize.org/nobel_prizes/literature/laureates/1930/>'}\n",
      "{'query': 'Where in England was Dame Judi Dench born?', 'answer': 'Judi Dench - IMDb IMDb Actress | Music Department | Soundtrack Judi Dench was born in York, England, to Eleanora Olive (Jones), who was from Dublin, Ireland, and Reginald Arthur Dench, a doctor from Dorset, England. She attended Mount School in York, and studied at the Central School of Speech and Drama. She has performed with Royal Shakespeare Company, the National Theatre, and at Old Vic Theatre. She is a ... See full bio ¬ª Born: a list of 35 people created 02\\xa0Jul\\xa02011 a list of 35 people created 19\\xa0Apr\\xa02012 a list of 35 people created 28\\xa0May\\xa02014 a list of 25 people created 05\\xa0Aug\\xa02014 a list of 26 people created 18\\xa0May\\xa02015 Do you have a demo reel? Add it to your IMDbPage How much of Judi Dench\\'s work have you seen? User Polls Won     1     Oscar. Another    59 wins & 163 nominations. See more awards \\xa0¬ª Known For \\xa02016 The Hollow Crown (TV Series) Cecily, Duchess of York \\xa02015 The Vote (TV Movie) Christine Metcalfe - Total War (1996) ... Narrator (voice) - Stalemate (1996) ... Narrator (voice) \\xa01992 The Torch (TV Mini-Series) Aba \\xa01990 Screen One (TV Series) Anne \\xa01989 Behaving Badly (TV Mini-Series) Bridget \\xa01981 BBC2 Playhouse (TV Series) Sister Scarli \\xa01976 Arena (TV Series documentary) Sweetie Simpkins \\xa01973 Ooh La La! (TV Series) Am√©lie \\xa01966 Court Martial (TV Series) Marthe \\xa01963 Z Cars (TV Series) Elena Collins \\xa01963 Love Story (TV Series) Pat McKendrick \\xa01960 The Terrible Choice (TV Series) Good Angel Music department (1 credit) \\xa0 A Fine Romance (TV Series) (theme sung by - 14 episodes, 1981 - 1983) (theme song sung by - 12 episodes, 1983 - 1984) - A Romantic Meal (1984) ... (theme song sung by) - Problems (1984) ... (theme song sung by) \\xa02013 Fifty Years on Stage (TV Movie) (performer: \"Send in the Clowns\") \\xa02009 Nine (performer: \"Folies Berg√®re\") - What\\'s Wrong with Mrs Bale? (1997) ... (performer: \"Raindrops Keep Fallin\\' On My Head\" - uncredited) - Misunderstandings (1993) ... (performer: \"Walkin\\' My Baby Back Home\" - uncredited) \\xa01982-1984 A Fine Romance (TV Series) (performer - 2 episodes) - The Telephone Call (1984) ... (performer: \"Boogie Woogie Bugle Boy\" - uncredited) - Furniture (1982) ... (performer: \"Rule, Britannia!\" - uncredited) Hide\\xa0 \\xa02009 Waiting in Rhyme (Video short) (special thanks) \\xa02007 Expresso (Short) (special thanks) \\xa01999 Shakespeare in Love and on Film (TV Movie documentary) (thanks - as Dame Judi Dench) Hide\\xa0 \\xa02016 Rio Olympics (TV Mini-Series) Herself \\xa02015 In Conversation (TV Series documentary) Herself \\xa02015 Entertainment Tonight (TV Series) Herself \\xa02015 CBS This Morning (TV Series) Herself - Guest \\xa02015 The Insider (TV Series) Herself \\xa01999-2014 Cinema 3 (TV Series) Herself \\xa02013 Good Day L.A. (TV Series) Herself - Guest \\xa02013 Arena (TV Series documentary) Herself \\xa02013 At the Movies (TV Series) Herself \\xa02013 Shooting Bond (Video documentary) Herself \\xa02013 Bond\\'s Greatest Moments (TV Movie documentary) Herself \\xa02012 Made in Hollywood (TV Series) Herself \\xa01999-2012 Charlie Rose (TV Series) Herself - Guest \\xa02008-2012 This Morning (TV Series) Herself - Guest \\xa02012 The Secrets of Skyfall (TV Short documentary) Herself \\xa02012 Anderson Live (TV Series) Herself \\xa02012 J. Edgar: A Complicated Man (Video documentary short) Herself \\xa02011 The Many Faces of... (TV Series documentary) Herself / Various Characters \\xa02011 Na plov√°rne (TV Series) Herself \\xa02010 BBC Proms (TV Series) Herself \\xa02010 The South Bank Show Revisited (TV Series documentary) Herself - Episode #6.68 (2009) ... Herself - Guest (as Dame Judi Dench) \\xa02007-2009 Breakfast (TV Series) \\xa02009 Larry King Live (TV Series) Herself - Guest \\xa02009 The One Show (TV Series) Herself \\xa02009 Cranford in Detail (Video documentary short) Herself / Miss Matty Jenkins (as Dame Judi Dench) \\xa02005-2008 The South Bank Show (TV Series documentary) Herself \\xa02008 Tavis Smiley (TV Series) Herself - Guest \\xa02007 ITV News (TV Series) Herself - BAFTA Nominee \\xa02007 The Making of Cranford (Video documentary short) Herself / Miss Matty Jenkyns (as Dame Judi Dench) \\xa02006 Becoming Bond (TV Movie documentary) Herself \\xa02006 Coraz√≥n de... (TV Series) Hers'}\n",
      "{'query': 'In which decade did Billboard magazine first publish and American hit chart?', 'answer': 'The US Billboard song chart The US Billboard song chart Search this site with Google Song chart US Billboard The Billboard magazine has published various music charts starting (with sheet music) in 1894, the first \"Music Hit Parade\" was published in 1936 , the first \"Music Popularity Chart\" was calculated in 1940 . These charts became less irregular until the weekly \"Hot 100\" was started in 1958 . The current chart combines sales, airplay and downloads. A music collector that calls himself Bullfrog has been consolidating the complete chart from 1894 to the present day.  he has published this information in a comprehenive spreadsheet (which can be obtained at bullfrogspond.com/ ). The Bullfrog data assigns each song a unique identifier, something like \"1968_076\" (which just happens to be the Bee Gees song \"I\\'ve Gotta Get A Message To You\"). This \"Whitburn Number\" is provided to match with the books of Joel Whitburn and consists of the year and a ranking within the year. A song that first entered the charts in December and has a long run is listed the following year. This numbering scheme means that songs which are still in the charts cannot be assigned a final id, because their ranking might change. So the definitive listing for a year cannot be final until about April. In our listing we only use songs with finalised IDs, this means that every year we have to wait until last year\\'s entries are finalised before using them. (Source bullfrogspond.com/ , the original version used here was 20090808 with extra data from: the 2009 data from 20091219 the 2010 data from 20110305 the 2011 data from 20120929 the 2012 data from 20130330 the 2013 data from 20150328 The 20150328 data was the last one produced before the Billboard company forced the data to be withdrawn. As far as we know there are no more recent data sets available. This pattern of obtaining the data for a particular year in the middle of the following one comes from the way that the Bullfrog project generates the identifier for a song (what they call the \"Prefix\" in the spreadsheet). Recent entries are identified with keys like \"2015-008\" while older ones have keys like \"2013_177\". In the second case the underscore is significant, it indicates that this was the 177th biggest song released in 2013. Now, of course, during the year no one knows where a particular song will rank, so the underscore names can\\'t be assigned until every song from a particular year has dropped out of the charts, so recent records are temporarily assigned a name with a dash. In about May of the following year the rankings are calculated and the final identifiers are assigned. That is why we at the Turret can only grab this data retrospectively. Attributes The original spreadsheet has a number of attributes, we have limited our attention to just a few of them: 134 9 The songs with the most entries on the chart were White Christmas (with 33 versions and a total of 110 weeks) and Stardust (with 19 and a total of 106 weeks). position The peak position that songs reached in the charts should show an smooth curve from number one down to the lowest position. This chart has more songs in the lower peak positions than one would expect. Before 1991 the profile of peak positions was exactly as you would expect, that year Billboard introduced the concept of \"Recurrent\" tracks, that is they removed any track from the chart which had spent more than twenty weeks in the chart and had fallen to the lower positions. weeks The effect of the \"Recurrent\" process, by which tracks are removed if they have spent at least twenty weeks in the chart and have fallen to the lower reaches, can clearly be seen in the strange spike in this attribute. This \"adjustment\" was intended to promote newer songs and ensure the chart does not become \"stale\". In fact since it was introduced in 1991 the length of long chart runs has increased, this might reflect the more conscious efforts of record companies to \"game\" the charts by controlling release times and promotions, or it coul'}\n",
      "{'query': 'From which country did Angola achieve independence in 1975?', 'answer': \"Angola from past to present | Conciliation Resources Angola from past to present Angola from past to present From military peace to social justice? The Angolan peace process Publication date:\\xa0 David Birmingham When Angola achieved independence in 1975, a war was raging between competing national liberation movements and their foreign backers. Guus Meijer and David Birmingham revisit Angola‚Äôs colonial period and the independence struggle that followed and ask how the resulting social and economic divisions shaped and were manipulated by the warring parties. The article describes the introduction of authoritarian one-party rule under the MPLA and the impact of natural resource development and international and regional powers on the conflict. Tracing the conflict up to the signing of the Luena Memorandum, the authors conclude that Angola‚Äôs peace remains incomplete and that the country faces many challenges in achieving social and democratic reconstruction. Read full article Angola from past to present On 11 November 1975, the Popular Movement for the Liberation of Angola (MPLA) declared Angola's independence and installed Agostinho Neto as its first President in the former Portuguese colony's capital at Luanda. This outcome had long seemed uncertain and indeed even unlikely; the MPLA had not only had to deal with its own serious internal troubles and disaffections, but had also had to take on the Portuguese colonial army and the two rival armed movements, each backed by powerful allies. Holden Roberto's National Front for the Liberation of Angola (FNLA) had initially been the most powerful of the three competing national liberation movements and in the autumn of 1975 it came close to capturing Luanda from the north, backed by a heavily armed force supplied by President Mobuto Sese Seko of Zaire (now the Democratic Republic of Congo). In the south, two armoured columns of a South African invasion force, acting in military coordination with the Union for the Total Independence of Angola (UNITA), led by Jonas Savimbi, almost reached Luanda before they were stopped by Cuban troops which had been rushed to the assistance of the MPLA. The independent Angolan state was thus born out of turmoil and violence and amid serious national, regional and global rivalries. This heritage with its deep historical roots was to influence the unfolding of events for a long time. Angola, like most African countries, grew out of a conglomerate of peoples and groups each with its own distinct history and traditions. Gradually small local nations and states came into contact with each other and historical developments drove them to share a common destiny under increasing Portuguese influence. Long before the arrival of the Portuguese, Bantu-speaking communities had established a farming economy over most of the territory. They had absorbed many of the scattered Khoisan-speaking populations and developed a successful pastoral dimension to their agriculture as well as building up trading economies. One of the most successfully diverse market centres became the town of M'banza Kongo around which the Kongo kingdom evolved. Further east the concept of state formation related to the political ideology of the Lunda peoples while in the south later kingdoms took shape in the highlands of the Ovimbundu people. Angola under Portuguese rule Although the first Portuguese traders, explorers and soldiers set foot on this part of the African coast from 1483, modern colonisation of the whole territory was only formalised four centuries later after the Berlin Conference of 1884-85. Wide stretches of Angola experienced colonial rule for less than a century, and even after 1900 armed revolts broke out and resistance movements sprang up as among the Ovimbundu and the Bakongo from 1913, until the last northern resistance was put down in 1917. During its century of overrule the colonial regime left crucial marks on Angolan society. Its discriminatory legislation, particularly the Statute of the Portuguese Natives of the Provinces of Angola, Mozambique, and Guinea, separ\"}\n",
      "{'query': 'Which city does David Soul come from?', 'answer': 'David Soul - IMDb IMDb Actor | Soundtrack | Director David Soul achieved pop icon status as handsome, blond-haired, blue-eyed Detective Kenneth Hutchinson on the cult \"buddy cop\" TV series Starsky and Hutch (1975), Soul also had a very successful singing career recording several albums, with worldwide number one hit singles including \"Silver Lady\" & \"Don\\'t Give Up on Us Baby\". Born in Chicago, ... See full bio ¬ª Born: Share this page: Related News a list of 43 people created 14\\xa0Jan\\xa02011 a list of 37 people created 13\\xa0Mar\\xa02011 a list of 48 people created 26\\xa0Mar\\xa02012 a list of 973 people created 26\\xa0Feb\\xa02013 a list of 127 people created 05\\xa0Jul\\xa02014 Do you have a demo reel? Add it to your IMDbPage How much of David Soul\\'s work have you seen? User Polls 1 win & 3 nominations. See more awards \\xa0¬ª Known For Starsky and Hutch Det. Ken \\'Hutch\\' Hutchinson (1975-1979) \\xa02004 The Dark Lantern (TV Movie) Storyteller \\xa02004 Dalziel and Pascoe (TV Series) Detective Gus D\\'Amato \\xa01995 Vents contraires (TV Movie) Quill \\xa01994 High Tide (TV Series) Brian Landis \\xa01991-1993 Murder, She Wrote (TV Series) Jordan Barnett / Wes McSorley \\xa01990 The Young Riders (TV Series) Jeremy Styles \\xa01989 Prime Target (TV Movie) Peter Armetage \\xa01989 Deadly Nightmares (TV Series) Cooper Halliday \\xa01989 Alfred Hitchcock Presents (TV Series) Michael Dennison \\xa01987 Crime Story (TV Series) Dr. Newhouse \\xa01987 Harry\\'s Hong Kong (TV Movie) Harry Petros \\xa01986 The Fifth Missile (TV Movie) Capt. Kevin Harris \\xa01984 Partners in Crime (TV Series) Harry \\xa01983 Through Naked Eyes (TV Movie) William Parrish \\xa01982 World War III (TV Movie) Col. Jake Caffey \\xa01980 Homeward Bound (TV Movie) Jake Seaton \\xa01980 Swan Song (TV Movie) Jesse Swan \\xa01974 Medical Center (TV Series) Walter \\xa01974 McMillan & Wife (TV Series) Jerry \\xa01974 The Rookies (TV Series) Johnny Dane \\xa01973 Circle of Fear (TV Series) James Barlow \\xa01972 The F.B.I. (TV Series) Clifford Wade \\xa01972 Movin\\' On (TV Movie) Jeff \\xa01971 Dan August (TV Series) Lawrence Merrill III \\xa01967 Star Trek (TV Series) Makora \\xa02016 The Conjuring 2 (performer: \"Don\\'t Give Up On Us\") \\xa02013/I Filth (performer: \"Silver Lady\") \\xa02011 Johnny English Reborn (courtesy: \"Don\\'t Give Up On Us\") / (performer: \"Don\\'t Give Up On Us\") \\xa02010 Rabbit Hole (performer: \"Don\\'t Give Up On Us\") \\xa02007 The Hitcher (performer: \"Don\\'t Give Up on Us\") \\xa01977-1978 Top of the Pops (TV Series) (performer - 17 episodes) - Episode dated 22 June 1978 (1978) ... (performer: \"It Sure Brings Out the Love in Your Eyes\") - Episode dated 8 June 1978 (1978) ... (performer: \"It Sure Brings Out the Love in Your Eyes\")'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(dataset['train'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Splitting\n",
    "\n",
    "You might have noticed that the dataset is not split into subsets (it contains only the `train` subset). To maintain the good practice of working with ML, we should have three datasets: `train`, `validation`, and `test`. The code below splits our dataset into those three subsets. We set the size of both the `validation` and `test` sets as 10,000 and keep the rest in the `train` subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'answer'],\n",
      "        num_rows: 53346\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['query', 'answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=10_000)\n",
    "valid_dataset = dataset['test']\n",
    "dataset = dataset['train'].train_test_split(test_size=10_000)\n",
    "dataset['validation'] = valid_dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleaning\n",
    "\n",
    "Let's write the function to clean the text. It can be similar to the one from the previous lab (Lab1) but make sure that it makes sense for this dataset and task.\n",
    "\n",
    "More specifically, think about lower-casing, punctuation, stop-words and lemmatization/stemming and the impact it might have on the dataset. Also reflect on the fact that with word embeddings we want to uncover semantic relationships between words, whereas with bag-of-words we were trying to capture different morphological variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e1'></a>\n",
    "#### Exercise 1: Clean function\n",
    "Fill in the following function to clean the dataset. Implement at least 6 different steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the clean function:\n",
      "Original: Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Cleaned: american-born sinclair won nobel prize literature 1930\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Cleans the text\n",
    "    Args:\n",
    "        text: a string that will be cleaned\n",
    "\n",
    "    Returns: the cleaned text\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Empty text\n",
    "    if text == '':\n",
    "        return text\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    stop_words = set(['a', 'an', 'the', 'and', 'or', 'but', 'in', 'on', 'for', 'of', 'to', 'with', 'at', 'by', 'from', 'what', 'which', 'why', 'when', 'how'])\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "\n",
    "    # collapses and adds one white space before and one after for each punctutaion/parenthesis character\n",
    "    text = re.sub(r'\\s*([()\\[\\]{}.,;:!?])\\s*', r' \\1 ', text)\n",
    "    # remove trailing punctuation tokens like \"?\" and other hyphens not inside words\n",
    "    text = re.sub(r'(?<!\\w)-|-(?!\\w)', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "\n",
    "    # replaces multiple whitespaces with a single one\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # removing comma between numbers\n",
    "    text = re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "\n",
    "    # removing multiple characters\n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    text = text.strip()\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "sentence = 'Which American-born Sinclair won the Nobel Prize for Literature in 1930?'\n",
    "print('Testing the clean function:')\n",
    "print('Original:', sentence)\n",
    "print('Cleaned:', clean(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will apply the function you just wrote to the whole dataset. More specifically, it takes the `query` and `answer` fields, applies the `clean` function and saves the processed sentences back to the `query` and `answer` fields. This will override the original fields. If you want to have access to them, you can make a copy in separate fields before cleaning. As in the last lab, we will use the `map()` method of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcd228e992641c49516d6691ddb3cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning queries and answers:   0%|          | 0/53346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64fbd62279049d69e9d8b3c649ff327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning queries and answers:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0b242d437e4cdbb6214f1bf80712bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning queries and answers:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 53346\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['query', 'answer', 'original_query', 'original_answer'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def clean_example(example):\n",
    "    \"\"\"\n",
    "    Applies the clean() function to the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: update example with cleaned 'query' and 'answer' columns\n",
    "\n",
    "    \"\"\"\n",
    "    example['original_query'] = example['query']\n",
    "    example['original_answer'] = example['answer']\n",
    "\n",
    "    example['query'] = clean(example['query'])\n",
    "    example['answer'] = clean(example['answer'])\n",
    "    return example\n",
    "\n",
    "\n",
    "dataset = dataset.map(clean_example, desc=\"Cleaning queries and answers\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine some examples from the dataset and make sure that we got the results we wanted. At this step, it might be necessary to revisit some pre-processing steps if you are not happy with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 0\n",
      "query who is quoted as saying advertising attracts all bright creative ambitious young people leaving us mainly slow self-obsessed become our artists never field human history has so much been used so many say so little\n",
      "answer art words 5 best banksy quotes sound bites urbanist art words 5 best banksy quotes sound bites article delana filed under street art graffiti art category youre famously elusive artist who refuses be identified saying something words rather than pictures is rare occurrence just as banksys art spreads new unconventional ways so do his words few short interviews he has given rare quotes that appear his website few nuggets banksy wisdom can be culled this is part six our eight-part guide banksy art graffiti image via wikipedia thing i hate most about advertising is that it attracts all bright creative ambitious young people leaving us mainly slow self-obsessed become our artists modern art is disaster area never field human history has so much been used so many say so little banksy has been very vocal opponent mainstream art world as quote above illustrates he seems feel that artists are little more than self-aggrandizing thieves who trick public out their money he has very publicly refused be part this perceived thievery avoiding showing his art formal art galleries shows his work that he has endorsed participated have been unconventional shows abandoned warehouses traffic tunnels images via bbc time getting fame your name its own is over artwork that is only about wanting be famous will never make you famous any fame is by-product making something that means something you dont go restaurant order meal because you want have shit although there are many banksy critics who say that today banksys art is valuable precisely because his name there is little doubt that he rose fame based his art not his identity since he has never revealed his true identity notoriety that his art enjoys today is based solely message method myth man image via mail sunday i have no interest ever coming out im just trying make pictures look good im not into trying make myself look good besides its pretty safe bet that reality me would be crushing disappointment couple 15-year-old kids out there this quote again illustrates artists aversion embracing trappings that go along being well-known artist his main concern is making art that people enjoy rather than becoming so famous that he isnt able walk down street unhindered image via wikipedia people say graffiti is ugly irresponsible childish thats only if its done properly ever prankster banksy has engaged few antics didnt go over as well as most others above picture was taken glastonbury music festival 2007 banksy erected stonehenge model made portable toilets although it was most likely all good fun model was built near sacred circle where plastic is banned this proved be one his most unpopular stunts date though judging above quote banksy doesnt seem mind that some people dont enjoy he does image via mappamundi list jobs i havent done now is so much bigger than list jobs i have done its like reverse cv kinda weird based his artistic ability unique style cult status banksy has been asked perform various marketing work pay he says that he turns nearly everything down exception few choice projects like album art blurs think tank like so many aspects banksys career public life there is no way be sure that quotes attributed him actually came directly him even those who have interviewed banksy cant be entirely sure that they were speaking man himself thats it goes you try pin down one most elusive public figures ever\n",
      "\n",
      "example 1\n",
      "query creatures scandinavian folklore have evil powers malevolent dispositions\n",
      "answer creatures all mythology stories wiki fandom powered wikia adar llwch gwin welsh giant birds that understand human languages adaro solomon islands malevolent merfolk adhene manx nature spirit adlet inuit vampiric dog-human hybrid adroanzi lugbara nature spirit adze ewe people african vampiric-forest being aerico greek disease demon afanc welsh lake monster exact lake varies story agni hindu god fire sacrifices agathodaemon greek spirit vinefields grainfields agloolik inuit ice spirit that aids hunters fishermen agogwe east africa small ape-like humanoid ahkiyyini inuit animated skeleton that causes shipwrecks ahuizotl aztec anthropophagous dog-monkey hybrid aigamuxa khoikhoi anthropophagous humanoid eyes its instep aigikampoi etruscan fish-tailed goat aitu polynesian malevolent spirits demons aitvaras lithuanian household spirit akamataa japanese snake spirit okinawa akateko japanese tree-dwelling monster akka finnish female spirits minor goddesses akki japanese large grotesque humanoid akkorokamui ainu sea monster akupara hindu giant turtle that supports world akurojin-no-hi japanese ghostly flame causes disease al armenian persian spirit that steals unborn babies livers pregnant women ala slavic bad weather demon alal chaldean demon alan philippine winged humanoid that steals reproductive waste make children alce heraldic wingless griffin aleya bengali spirit dead fisherman alicanto chilean bird that eats gold silver alicorn winged unicorn latin ala wing corn horn alkonost slavic angelic bird human head breasts allocamelus heraldic ass-camel hybrid amaburakosagi japanese ritual disciplinary demon shikoku amala tsimshian giant who holds up world amamehagi japanese ritual disciplinary demon hokuriku amanojaku japanese small demon amarum quechua water boa spirit amazake-babaa japanese disease-causing hag ammit ancient egyptian female demon body that was part lion hippopotamus crocodile amor≈çnagu japanese tennyo island amami ≈çshima amphiptere heraldic winged serpent amphisbaena greek serpent head each end anakim jewish giant androsphinx ancient egyptian human-headed sphinx angel mainly christian jewish islamic traditions greek √°ngelos divine beings heaven who act as mediators between god humans counterparts ofdemons angha persian dog-lion-peacock hybrid ani hyuntikwalaski cherokee lightning spirit ankou french skeletal grave watcher lantern scythe anmo japanese ritual disciplinary demon iwate prefecture antaeus greek giant who was extremely strong as long as he remained contact ground antero vipunen finnish subterranean giant ao ao guaran√≠ anthropophagous peccary sheep aob≈çzu japanese blue monk who kidnaps children apkallu sumerian fish-human hybrid that attends god enki apsaras buddhist hindu female cloud spirit aqrabuamelu akkadian human-scorpion hybrid argus panoptes greek hundred-eyed giant arikura-no-baba japanese old woman magical powers arimaspi greek one-eyed humanoid arion greek extremely swift horse green mane power speech arkan sonney manx fairy hedgehog asag sumerian hideous rock demon asakku sumerian demon asanbosam west africa iron-toothed vampire asena turkic blue-maned wolf ashi-magari japanese invisible tendril that impedes movement asiman dahomey vampiric possession spirit askefrue germanic female tree spirit ask-wee-da-eed abenaki fire elemental spectral fire asobibi japanese spectral fire k≈çchi prefecture aspidochelone medieval bestiaries island-sized whale sea turtle asrai eng\n",
      "\n",
      "example 2\n",
      "query musical based characters created single-panel cartoons new yorker beginning 1938 opened broadway april 2010 after tryout chicago\n",
      "answer addams family musical songs lyrics addams family musical songs lyrics addams family musical songs lyrics addams family is musical music lyrics andrew lippa book marshall brickman rick elice show is based upon addams family characters created cartoonist charles addams his single-panel gag cartoons new yorker beginning 1938 depict ghoulish american family affinity all things macabre while numerous film television adaptations addams cartoons exist stage show does not draw these portrayals characters after tryout chicago show opened broadway april 2010 broadway production 2010\n",
      "\n",
      "example 3\n",
      "query is maximum no match points that can be held one time tennis match wimbledon\n",
      "answer facts figures faq championships wimbledon 2017 official site ibm facts figures faq facts figures about championships read more facts figures frequently asked topics about championships men 212 goran ivanisevic cro 2001 ladies 80 serena williams usa 2015 men 165 ivo karlovic four matches ladies 80 serena williams seven matches total attendance was 493 928 14 days includes middle sunday 24 623 484 391 2015 ball boys ball girls around 250 around 750 entries come through rigorous training routine balls 54 250 used during championships period stored 68 deg f new balls after first seven games allow warm-up then after every 9 games subject availability after use balls sold daily lta-affiliated clubs spectators grounds 2 50 per can three proceeds go ltas wimbledon balls schools scheme yellow balls used first time 1986 start day 48 tins taken onto centre no 1 courts 24 all outside courts bbc is host broadcaster agreement extended 2011 2017 inc global news access audience estimated over 1bn people 200 territories broadcast figures 2016 early headline audience figures uk bbc gentlemens singles final peaked 13 3 million 69 peak share ladies singles final audience peak was 4 8m website there were 10 2 million unique browsers 1 9 million requests wimbledon live stream mixed doubles final featuring heather watson peaked 2 8m gentlemens wheelchair singles final bbc2 gordon reid peaked 1 1m us espn most-watched wimbledon to-date watchespn up 35 vs 2015 tsn canada gentlemens singles final featuring milos raonic became most watched tennis match canada peaking 2 4 million unique devices 20 9m 21 1m 2015 visits 69 4m 72 0 2015 page views 395m 542m 2015 mobile com uniques 5 6m 2 1m 2014 125 mobile com visits 9 6m 8 4m 2015 98 mobile com page views 88 3m 73 7m 2015 app downloads 1 5m com apps uniques split 93 7 com apps page views split 51 49 social media audience 10 5m 8 5m 2015 video views 106m 85m 2015 live wimbledon tv 1 5m global excl spain austria italy germany 1 6m 2015 bespoke social media feeds chinese sina weibo wechat 65k followers wechat prediction game 55k users geo-targeted content posted japanese facebook line platform-specific social media activations facebook frame wimbledon experience facebook 360s wimbledon emojis beat legend vine activation thehill v theworld v thequeue wimbleskills euros challenge giphy channel live wimbledon youtube pinterest wimbledon food custom snapchat filters strawberry lens snapchat wimbledon live stories youtube 3d finals 39 000 spectators grounds any one time catering 2016 wimbledon is largest single annual sporting catering operation 1800 staff carried out europe average quantities supplied championships caterers fmc 177 135 glasses pimms 2772 kilos bananas players champions dinner instigated 1977 lta ball previously held final evening championships was moved middle saturday tradition dancing between two singles champions ceased then was brought back novak djokovic serena williams 2015 2015 held guildhall city london clothing players predominately white rule introduced 1963 almost entirely white rule introduced 1995 clothing submitted club comment earlier year both grand slam wta rules stipulate recognised tennis attire decision day as whether clothingplayers turnout is suitable discretion referee guidelines no solid mass colouring little no dark bold colours no fluorescent colours preference back o\n",
      "\n",
      "example 4\n",
      "query who made century his test debut england v new zealand 2004\n",
      "answer 1st test england v new zealand lords may 20-24 2004 cricket scorecard espn cricinfo new zealand 50 16 1 overs richardson 16 fleming 31 new zealand 100 32 3 overs richardson 36 astle 23 nathan astle 50 58 balls 8x4 new zealand 150 44 5 overs richardson 44 astle 60 mark richardson 50 140 balls 9x4 tea new zealand 172 3 richardson 56 mcmillan 4 new zealand 200 69 1 overs richardson 67 oram 16 oram 50 54 balls 9x4 new zealand 250 79 5 overs richardson 78 oram 51 new zealand 300 92 3 overs tuffey 2 cairns 15 new zealand 350 100 overs cairns 47 martin 1 cairns 50 37 balls 9x4 england 1st innings lunch england 27 0 trescothick 10 strauss 15 england 50 18 1 overs trescothick 19 strauss 26 england 100 28 3 overs trescothick 51 strauss 43 trescothick 50 95 balls 9x4 strauss 50 90 balls 5x4 tea england 136 0 trescothick 60 strauss 65 england 150 41 1 overs trescothick 66 strauss 74 england 200 54 4 overs strauss 91 butcher 5 strauss 100 276 mins off 199 balls 12x4 england 250 76 4 overs butcher 23 hoggard 3 england 300 95 5 overs hussain 29 flintoff 1 lunch england 330 6 flintoff 10 jones 11 england 350 104 1 overs flintoff 22 go jones 15 england 400 114 overs flintoff 47 go jones 37 flintoff 50 64 balls 6x4 2x6 100 run partnership between flintoff jones 108 balls new zealand 2nd innings new zealand 50 16 overs richardso 17 mccullum 26 brendon mccullum 50 54 balls 8x4 mh richardson 50 188 minutes off 127 balls including 5x4 150 2nd wicket partnership off 256 balls richardson 50 mccullum 87 lunch new zealand 1984 richardson 72 oram 3 new zealand 200 68 3 overs richardson 76 oram 4 new zealand 250 86 1 overs richardson 94 astle 24 mh richardson 100 402 mins off 289 balls 10x4 tea new zealand 269 5 richardson 101 astle 29 new zealand 300 109 3 overs cairns 9 vettori 5 england 2nd innings england 50 24 5 overs strauss 33 hussain 5 andrew strauss 50 97 balls 8x4 england 100 39 5 overs strauss 59 hussain 22 100 run partnership between strauss hussain 183 balls england 150 53 overs hussain 31 thorpe 5 50 run partnership between thorpe hussain 118 balls england 200 72 1 overs hussain 49 thorpe 34 nasser hussain 50 158 balls 7x4 100 run partnership between thorpe hussain 181 balls england 250 81 3 overs hussain 78 thorpe 44 thorpe 50 97 balls 6x4 n hussain 100 292 mins off 203 balls 15x4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('example', i)\n",
    "    print('query', dataset['train'][i]['query'])\n",
    "    print('answer', dataset['train'][i]['answer'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extracting answers\n",
    "\n",
    "Because the answers in our dataset are not unique, we will extract them and create a separate dataset containing only the unique answers. We will do this for each split separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_answers(subset):\n",
    "    \"\"\"\n",
    "    Extracts unique answers from the subset of the dataset and builds a dictionary with answers as keys and ids as values.\n",
    "    Args:\n",
    "        subset: a subset of the dataset\n",
    "\n",
    "    Returns: a dictionary mapping answers to their ids\n",
    "    \"\"\"\n",
    "    answer_to_id = {}\n",
    "    answers = list(set(subset['answer']))\n",
    "    for i, answer in enumerate(answers):\n",
    "        answer_to_id[answer] = i\n",
    "    return answer_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We apply this function separately to each subset and create the answers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'answer'],\n",
      "        num_rows: 47971\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'answer'],\n",
      "        num_rows: 9740\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'answer'],\n",
      "        num_rows: 9715\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_answer_to_id = get_answers(dataset['train'])\n",
    "valid_answer_to_id = get_answers(dataset['validation'])\n",
    "test_answer_to_id = get_answers(dataset['test'])\n",
    "\n",
    "answers_dataset = DatasetDict({\n",
    "    'train': datasets.Dataset.from_dict({'id': range(len(train_answer_to_id)), 'answer': train_answer_to_id.keys()}),\n",
    "    'validation': datasets.Dataset.from_dict(\n",
    "        {'id': range(len(valid_answer_to_id)), 'answer': valid_answer_to_id.keys()}),\n",
    "    'test': datasets.Dataset.from_dict({'id': range(len(test_answer_to_id)), 'answer': test_answer_to_id.keys()})\n",
    "})\n",
    "print(answers_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last thing we will have to do is to connect the answers in the original dataset to the ids of answers (in the answers dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e2'></a>\n",
    "#### Exercise 2: Setting answer ids\n",
    "Fill in the following function to find and set the `answer_id` field with the id of the answer. The function accepts one of the `answer_to_id` dictionaries that you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_answer_id(example, answer_to_id):\n",
    "    \"\"\"\n",
    "    Sets the answer_id field in the example based on the answer_to_id dictionary\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "        answer_to_id: a dictionary mapping answers to their ids\n",
    "\n",
    "    Returns: the updated example with the 'answer_id' field\n",
    "    \"\"\"\n",
    "    answer = example['answer']\n",
    "    ### YOUR CODE HERE\n",
    "    example['answer_id'] = answer_to_id[answer]\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we apply the function to each split separately making sure to pass the correct `answer_to_id` dictionary. We also remove the `answer` columns from the original dataset, as now we can reference the correct answer through the `answer_id` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad649740fca4629ac32eaf8e868d821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting ids for answers (train):   0%|          | 0/53346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74d2a1e0c244ab3864e81fdb40c20e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting ids for answers (validation):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1576c8eea8e4aa98979304d3339471e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting ids for answers (test:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].map(set_answer_id,\n",
    "                                        fn_kwargs={'answer_to_id': train_answer_to_id},\n",
    "                                        desc=\"Setting ids for answers (train)\")\n",
    "dataset['validation'] = dataset['validation'].map(set_answer_id,\n",
    "                                                  fn_kwargs={'answer_to_id': valid_answer_to_id},\n",
    "                                                  desc=\"Setting ids for answers (validation)\")\n",
    "dataset['test'] = dataset['test'].map(set_answer_id,\n",
    "                                      fn_kwargs={'answer_to_id': test_answer_to_id},\n",
    "                                      desc=\"Setting ids for answers (test\")\n",
    "\n",
    "dataset = dataset.remove_columns('answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenizing\n",
    "\n",
    "<a name='e3'></a>\n",
    "#### Exercise 3: Tokenizing\n",
    "As always, we will need to tokenize the dataset in order to create bat-of-words and TF-IDF representations in the next sections. You can use the function from the previous lab or use a library such as [Natural Language Toolkit (NLTK) library]([https://www.nltk.org/]) (https://www.nltk.org/). Complete the following function to split the text into tokens.\n",
    "\n",
    "Contrary to the previous lab, we will not include the special tokens (unknown, beginning, and end of the sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the text that is assumed to be cleaned first with the clean() function. The tokenized sequence should start with the `bos_token` token and end with the 'eos_token'.\n",
    "    Args:\n",
    "        text: a cleaned text\n",
    "\n",
    "    Returns: tokenized text as a list of tokens\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = None  # list of tokens, your code should fill this variable\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    tokens = text.split()\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We apply your function to both the `query` field in the original dataset and `answer` field in the answers dataset. We save the tokenized queries in `query_tokens` field and answers in `answer_tokens` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7afffca720c4444beb9bdac92c8c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing queries:   0%|          | 0/53346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09bd28ea71b4b56b44693309f6028e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing queries:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d525398ef235494f931693424dc27d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing queries:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'original_query', 'original_answer', 'answer_id', 'query_tokens'],\n",
      "        num_rows: 53346\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'original_query', 'original_answer', 'answer_id', 'query_tokens'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['query', 'original_query', 'original_answer', 'answer_id', 'query_tokens'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d82912df5a74c9f81b3163155dab1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing answers:   0%|          | 0/47971 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0bc2194f3d4c0c9ea270e46aa456bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing answers:   0%|          | 0/9740 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2f096eca4b4c73ad7a5dc81f404b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing answers:   0%|          | 0/9715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers_dataset\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'answer', 'answer_tokens'],\n",
      "        num_rows: 47971\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'answer', 'answer_tokens'],\n",
      "        num_rows: 9740\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'answer', 'answer_tokens'],\n",
      "        num_rows: 9715\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_example(example, src_column, tgt_column):\n",
    "    \"\"\"\n",
    "    Applies the tokenize() function to the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: update example containing 'query_tokens' column\n",
    "\n",
    "    \"\"\"\n",
    "    query = example[src_column]\n",
    "    example[tgt_column] = tokenize(query)\n",
    "    return example\n",
    "\n",
    "\n",
    "dataset = dataset.map(tokenize_example,\n",
    "                      fn_kwargs={'src_column': 'query', 'tgt_column': 'query_tokens'},\n",
    "                      desc=\"Tokenizing queries\")\n",
    "print('dataset')\n",
    "print(dataset)\n",
    "\n",
    "answers_dataset = answers_dataset.map(tokenize_example,\n",
    "                                      fn_kwargs={'src_column': 'answer', 'tgt_column': 'answer_tokens'},\n",
    "                                      desc=\"Tokenizing answers\")\n",
    "print('answers_dataset')\n",
    "print(answers_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine some examples of tokenized queries and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: 0\n",
      "query: who is quoted as saying advertising attracts all bright creative ambitious young people leaving us mainly slow self-obsessed become our artists never field human history has so much been used so many say so little\n",
      "query_tokens: ['who', 'is', 'quoted', 'as', 'saying', 'advertising', 'attracts', 'all', 'bright', 'creative', 'ambitious', 'young', 'people', 'leaving', 'us', 'mainly', 'slow', 'self-obsessed', 'become', 'our', 'artists', 'never', 'field', 'human', 'history', 'has', 'so', 'much', 'been', 'used', 'so', 'many', 'say', 'so', 'little']\n",
      "answer_id: 26021\n",
      "answer: art words 5 best banksy quotes sound bites urbanist art words 5 best banksy quotes sound bites article delana filed under street art graffiti art category youre famously elusive artist who refuses be identified saying something words rather than pictures is rare occurrence just as banksys art spreads new unconventional ways so do his words few short interviews he has given rare quotes that appear his website few nuggets banksy wisdom can be culled this is part six our eight-part guide banksy art graffiti image via wikipedia thing i hate most about advertising is that it attracts all bright creative ambitious young people leaving us mainly slow self-obsessed become our artists modern art is disaster area never field human history has so much been used so many say so little banksy has been very vocal opponent mainstream art world as quote above illustrates he seems feel that artists are little more than self-aggrandizing thieves who trick public out their money he has very publicly refused be part this perceived thievery avoiding showing his art formal art galleries shows his work that he has endorsed participated have been unconventional shows abandoned warehouses traffic tunnels images via bbc time getting fame your name its own is over artwork that is only about wanting be famous will never make you famous any fame is by-product making something that means something you dont go restaurant order meal because you want have shit although there are many banksy critics who say that today banksys art is valuable precisely because his name there is little doubt that he rose fame based his art not his identity since he has never revealed his true identity notoriety that his art enjoys today is based solely message method myth man image via mail sunday i have no interest ever coming out im just trying make pictures look good im not into trying make myself look good besides its pretty safe bet that reality me would be crushing disappointment couple 15-year-old kids out there this quote again illustrates artists aversion embracing trappings that go along being well-known artist his main concern is making art that people enjoy rather than becoming so famous that he isnt able walk down street unhindered image via wikipedia people say graffiti is ugly irresponsible childish thats only if its done properly ever prankster banksy has engaged few antics didnt go over as well as most others above picture was taken glastonbury music festival 2007 banksy erected stonehenge model made portable toilets although it was most likely all good fun model was built near sacred circle where plastic is banned this proved be one his most unpopular stunts date though judging above quote banksy doesnt seem mind that some people dont enjoy he does image via mappamundi list jobs i havent done now is so much bigger than list jobs i have done its like reverse cv kinda weird based his artistic ability unique style cult status banksy has been asked perform various marketing work pay he says that he turns nearly everything down exception few choice projects like album art blurs think tank like so many aspects banksys career public life there is no way be sure that quotes attributed him actually came directly him even those who have interviewed banksy cant be entirely sure that they were speaking man himself thats it goes you try pin down one most elusive public figures ever\n",
      "answer_tokens: ['art', 'words', '5', 'best', 'banksy', 'quotes', 'sound', 'bites', 'urbanist', 'art', 'words', '5', 'best', 'banksy', 'quotes', 'sound', 'bites', 'article', 'delana', 'filed', 'under', 'street', 'art', 'graffiti', 'art', 'category', 'youre', 'famously', 'elusive', 'artist', 'who', 'refuses', 'be', 'identified', 'saying', 'something', 'words', 'rather', 'than', 'pictures', 'is', 'rare', 'occurrence', 'just', 'as', 'banksys', 'art', 'spreads', 'new', 'unconventional', 'ways', 'so', 'do', 'his', 'words', 'few', 'short', 'interviews', 'he', 'has', 'given', 'rare', 'quotes', 'that', 'appear', 'his', 'website', 'few', 'nuggets', 'banksy', 'wisdom', 'can', 'be', 'culled', 'this', 'is', 'part', 'six', 'our', 'eight-part', 'guide', 'banksy', 'art', 'graffiti', 'image', 'via', 'wikipedia', 'thing', 'i', 'hate', 'most', 'about', 'advertising', 'is', 'that', 'it', 'attracts', 'all', 'bright', 'creative', 'ambitious', 'young', 'people', 'leaving', 'us', 'mainly', 'slow', 'self-obsessed', 'become', 'our', 'artists', 'modern', 'art', 'is', 'disaster', 'area', 'never', 'field', 'human', 'history', 'has', 'so', 'much', 'been', 'used', 'so', 'many', 'say', 'so', 'little', 'banksy', 'has', 'been', 'very', 'vocal', 'opponent', 'mainstream', 'art', 'world', 'as', 'quote', 'above', 'illustrates', 'he', 'seems', 'feel', 'that', 'artists', 'are', 'little', 'more', 'than', 'self-aggrandizing', 'thieves', 'who', 'trick', 'public', 'out', 'their', 'money', 'he', 'has', 'very', 'publicly', 'refused', 'be', 'part', 'this', 'perceived', 'thievery', 'avoiding', 'showing', 'his', 'art', 'formal', 'art', 'galleries', 'shows', 'his', 'work', 'that', 'he', 'has', 'endorsed', 'participated', 'have', 'been', 'unconventional', 'shows', 'abandoned', 'warehouses', 'traffic', 'tunnels', 'images', 'via', 'bbc', 'time', 'getting', 'fame', 'your', 'name', 'its', 'own', 'is', 'over', 'artwork', 'that', 'is', 'only', 'about', 'wanting', 'be', 'famous', 'will', 'never', 'make', 'you', 'famous', 'any', 'fame', 'is', 'by-product', 'making', 'something', 'that', 'means', 'something', 'you', 'dont', 'go', 'restaurant', 'order', 'meal', 'because', 'you', 'want', 'have', 'shit', 'although', 'there', 'are', 'many', 'banksy', 'critics', 'who', 'say', 'that', 'today', 'banksys', 'art', 'is', 'valuable', 'precisely', 'because', 'his', 'name', 'there', 'is', 'little', 'doubt', 'that', 'he', 'rose', 'fame', 'based', 'his', 'art', 'not', 'his', 'identity', 'since', 'he', 'has', 'never', 'revealed', 'his', 'true', 'identity', 'notoriety', 'that', 'his', 'art', 'enjoys', 'today', 'is', 'based', 'solely', 'message', 'method', 'myth', 'man', 'image', 'via', 'mail', 'sunday', 'i', 'have', 'no', 'interest', 'ever', 'coming', 'out', 'im', 'just', 'trying', 'make', 'pictures', 'look', 'good', 'im', 'not', 'into', 'trying', 'make', 'myself', 'look', 'good', 'besides', 'its', 'pretty', 'safe', 'bet', 'that', 'reality', 'me', 'would', 'be', 'crushing', 'disappointment', 'couple', '15-year-old', 'kids', 'out', 'there', 'this', 'quote', 'again', 'illustrates', 'artists', 'aversion', 'embracing', 'trappings', 'that', 'go', 'along', 'being', 'well-known', 'artist', 'his', 'main', 'concern', 'is', 'making', 'art', 'that', 'people', 'enjoy', 'rather', 'than', 'becoming', 'so', 'famous', 'that', 'he', 'isnt', 'able', 'walk', 'down', 'street', 'unhindered', 'image', 'via', 'wikipedia', 'people', 'say', 'graffiti', 'is', 'ugly', 'irresponsible', 'childish', 'thats', 'only', 'if', 'its', 'done', 'properly', 'ever', 'prankster', 'banksy', 'has', 'engaged', 'few', 'antics', 'didnt', 'go', 'over', 'as', 'well', 'as', 'most', 'others', 'above', 'picture', 'was', 'taken', 'glastonbury', 'music', 'festival', '2007', 'banksy', 'erected', 'stonehenge', 'model', 'made', 'portable', 'toilets', 'although', 'it', 'was', 'most', 'likely', 'all', 'good', 'fun', 'model', 'was', 'built', 'near', 'sacred', 'circle', 'where', 'plastic', 'is', 'banned', 'this', 'proved', 'be', 'one', 'his', 'most', 'unpopular', 'stunts', 'date', 'though', 'judging', 'above', 'quote', 'banksy', 'doesnt', 'seem', 'mind', 'that', 'some', 'people', 'dont', 'enjoy', 'he', 'does', 'image', 'via', 'mappamundi', 'list', 'jobs', 'i', 'havent', 'done', 'now', 'is', 'so', 'much', 'bigger', 'than', 'list', 'jobs', 'i', 'have', 'done', 'its', 'like', 'reverse', 'cv', 'kinda', 'weird', 'based', 'his', 'artistic', 'ability', 'unique', 'style', 'cult', 'status', 'banksy', 'has', 'been', 'asked', 'perform', 'various', 'marketing', 'work', 'pay', 'he', 'says', 'that', 'he', 'turns', 'nearly', 'everything', 'down', 'exception', 'few', 'choice', 'projects', 'like', 'album', 'art', 'blurs', 'think', 'tank', 'like', 'so', 'many', 'aspects', 'banksys', 'career', 'public', 'life', 'there', 'is', 'no', 'way', 'be', 'sure', 'that', 'quotes', 'attributed', 'him', 'actually', 'came', 'directly', 'him', 'even', 'those', 'who', 'have', 'interviewed', 'banksy', 'cant', 'be', 'entirely', 'sure', 'that', 'they', 'were', 'speaking', 'man', 'himself', 'thats', 'it', 'goes', 'you', 'try', 'pin', 'down', 'one', 'most', 'elusive', 'public', 'figures', 'ever']\n",
      "\n",
      "example: 1\n",
      "query: creatures scandinavian folklore have evil powers malevolent dispositions\n",
      "query_tokens: ['creatures', 'scandinavian', 'folklore', 'have', 'evil', 'powers', 'malevolent', 'dispositions']\n",
      "answer_id: 11055\n",
      "answer: creatures all mythology stories wiki fandom powered wikia adar llwch gwin welsh giant birds that understand human languages adaro solomon islands malevolent merfolk adhene manx nature spirit adlet inuit vampiric dog-human hybrid adroanzi lugbara nature spirit adze ewe people african vampiric-forest being aerico greek disease demon afanc welsh lake monster exact lake varies story agni hindu god fire sacrifices agathodaemon greek spirit vinefields grainfields agloolik inuit ice spirit that aids hunters fishermen agogwe east africa small ape-like humanoid ahkiyyini inuit animated skeleton that causes shipwrecks ahuizotl aztec anthropophagous dog-monkey hybrid aigamuxa khoikhoi anthropophagous humanoid eyes its instep aigikampoi etruscan fish-tailed goat aitu polynesian malevolent spirits demons aitvaras lithuanian household spirit akamataa japanese snake spirit okinawa akateko japanese tree-dwelling monster akka finnish female spirits minor goddesses akki japanese large grotesque humanoid akkorokamui ainu sea monster akupara hindu giant turtle that supports world akurojin-no-hi japanese ghostly flame causes disease al armenian persian spirit that steals unborn babies livers pregnant women ala slavic bad weather demon alal chaldean demon alan philippine winged humanoid that steals reproductive waste make children alce heraldic wingless griffin aleya bengali spirit dead fisherman alicanto chilean bird that eats gold silver alicorn winged unicorn latin ala wing corn horn alkonost slavic angelic bird human head breasts allocamelus heraldic ass-camel hybrid amaburakosagi japanese ritual disciplinary demon shikoku amala tsimshian giant who holds up world amamehagi japanese ritual disciplinary demon hokuriku amanojaku japanese small demon amarum quechua water boa spirit amazake-babaa japanese disease-causing hag ammit ancient egyptian female demon body that was part lion hippopotamus crocodile amor≈çnagu japanese tennyo island amami ≈çshima amphiptere heraldic winged serpent amphisbaena greek serpent head each end anakim jewish giant androsphinx ancient egyptian human-headed sphinx angel mainly christian jewish islamic traditions greek √°ngelos divine beings heaven who act as mediators between god humans counterparts ofdemons angha persian dog-lion-peacock hybrid ani hyuntikwalaski cherokee lightning spirit ankou french skeletal grave watcher lantern scythe anmo japanese ritual disciplinary demon iwate prefecture antaeus greek giant who was extremely strong as long as he remained contact ground antero vipunen finnish subterranean giant ao ao guaran√≠ anthropophagous peccary sheep aob≈çzu japanese blue monk who kidnaps children apkallu sumerian fish-human hybrid that attends god enki apsaras buddhist hindu female cloud spirit aqrabuamelu akkadian human-scorpion hybrid argus panoptes greek hundred-eyed giant arikura-no-baba japanese old woman magical powers arimaspi greek one-eyed humanoid arion greek extremely swift horse green mane power speech arkan sonney manx fairy hedgehog asag sumerian hideous rock demon asakku sumerian demon asanbosam west africa iron-toothed vampire asena turkic blue-maned wolf ashi-magari japanese invisible tendril that impedes movement asiman dahomey vampiric possession spirit askefrue germanic female tree spirit ask-wee-da-eed abenaki fire elemental spectral fire asobibi japanese spectral fire k≈çchi prefecture aspidochelone medieval bestiaries island-sized whale sea turtle asrai eng\n",
      "answer_tokens: ['creatures', 'all', 'mythology', 'stories', 'wiki', 'fandom', 'powered', 'wikia', 'adar', 'llwch', 'gwin', 'welsh', 'giant', 'birds', 'that', 'understand', 'human', 'languages', 'adaro', 'solomon', 'islands', 'malevolent', 'merfolk', 'adhene', 'manx', 'nature', 'spirit', 'adlet', 'inuit', 'vampiric', 'dog-human', 'hybrid', 'adroanzi', 'lugbara', 'nature', 'spirit', 'adze', 'ewe', 'people', 'african', 'vampiric-forest', 'being', 'aerico', 'greek', 'disease', 'demon', 'afanc', 'welsh', 'lake', 'monster', 'exact', 'lake', 'varies', 'story', 'agni', 'hindu', 'god', 'fire', 'sacrifices', 'agathodaemon', 'greek', 'spirit', 'vinefields', 'grainfields', 'agloolik', 'inuit', 'ice', 'spirit', 'that', 'aids', 'hunters', 'fishermen', 'agogwe', 'east', 'africa', 'small', 'ape-like', 'humanoid', 'ahkiyyini', 'inuit', 'animated', 'skeleton', 'that', 'causes', 'shipwrecks', 'ahuizotl', 'aztec', 'anthropophagous', 'dog-monkey', 'hybrid', 'aigamuxa', 'khoikhoi', 'anthropophagous', 'humanoid', 'eyes', 'its', 'instep', 'aigikampoi', 'etruscan', 'fish-tailed', 'goat', 'aitu', 'polynesian', 'malevolent', 'spirits', 'demons', 'aitvaras', 'lithuanian', 'household', 'spirit', 'akamataa', 'japanese', 'snake', 'spirit', 'okinawa', 'akateko', 'japanese', 'tree-dwelling', 'monster', 'akka', 'finnish', 'female', 'spirits', 'minor', 'goddesses', 'akki', 'japanese', 'large', 'grotesque', 'humanoid', 'akkorokamui', 'ainu', 'sea', 'monster', 'akupara', 'hindu', 'giant', 'turtle', 'that', 'supports', 'world', 'akurojin-no-hi', 'japanese', 'ghostly', 'flame', 'causes', 'disease', 'al', 'armenian', 'persian', 'spirit', 'that', 'steals', 'unborn', 'babies', 'livers', 'pregnant', 'women', 'ala', 'slavic', 'bad', 'weather', 'demon', 'alal', 'chaldean', 'demon', 'alan', 'philippine', 'winged', 'humanoid', 'that', 'steals', 'reproductive', 'waste', 'make', 'children', 'alce', 'heraldic', 'wingless', 'griffin', 'aleya', 'bengali', 'spirit', 'dead', 'fisherman', 'alicanto', 'chilean', 'bird', 'that', 'eats', 'gold', 'silver', 'alicorn', 'winged', 'unicorn', 'latin', 'ala', 'wing', 'corn', 'horn', 'alkonost', 'slavic', 'angelic', 'bird', 'human', 'head', 'breasts', 'allocamelus', 'heraldic', 'ass-camel', 'hybrid', 'amaburakosagi', 'japanese', 'ritual', 'disciplinary', 'demon', 'shikoku', 'amala', 'tsimshian', 'giant', 'who', 'holds', 'up', 'world', 'amamehagi', 'japanese', 'ritual', 'disciplinary', 'demon', 'hokuriku', 'amanojaku', 'japanese', 'small', 'demon', 'amarum', 'quechua', 'water', 'boa', 'spirit', 'amazake-babaa', 'japanese', 'disease-causing', 'hag', 'ammit', 'ancient', 'egyptian', 'female', 'demon', 'body', 'that', 'was', 'part', 'lion', 'hippopotamus', 'crocodile', 'amor≈çnagu', 'japanese', 'tennyo', 'island', 'amami', '≈çshima', 'amphiptere', 'heraldic', 'winged', 'serpent', 'amphisbaena', 'greek', 'serpent', 'head', 'each', 'end', 'anakim', 'jewish', 'giant', 'androsphinx', 'ancient', 'egyptian', 'human-headed', 'sphinx', 'angel', 'mainly', 'christian', 'jewish', 'islamic', 'traditions', 'greek', '√°ngelos', 'divine', 'beings', 'heaven', 'who', 'act', 'as', 'mediators', 'between', 'god', 'humans', 'counterparts', 'ofdemons', 'angha', 'persian', 'dog-lion-peacock', 'hybrid', 'ani', 'hyuntikwalaski', 'cherokee', 'lightning', 'spirit', 'ankou', 'french', 'skeletal', 'grave', 'watcher', 'lantern', 'scythe', 'anmo', 'japanese', 'ritual', 'disciplinary', 'demon', 'iwate', 'prefecture', 'antaeus', 'greek', 'giant', 'who', 'was', 'extremely', 'strong', 'as', 'long', 'as', 'he', 'remained', 'contact', 'ground', 'antero', 'vipunen', 'finnish', 'subterranean', 'giant', 'ao', 'ao', 'guaran√≠', 'anthropophagous', 'peccary', 'sheep', 'aob≈çzu', 'japanese', 'blue', 'monk', 'who', 'kidnaps', 'children', 'apkallu', 'sumerian', 'fish-human', 'hybrid', 'that', 'attends', 'god', 'enki', 'apsaras', 'buddhist', 'hindu', 'female', 'cloud', 'spirit', 'aqrabuamelu', 'akkadian', 'human-scorpion', 'hybrid', 'argus', 'panoptes', 'greek', 'hundred-eyed', 'giant', 'arikura-no-baba', 'japanese', 'old', 'woman', 'magical', 'powers', 'arimaspi', 'greek', 'one-eyed', 'humanoid', 'arion', 'greek', 'extremely', 'swift', 'horse', 'green', 'mane', 'power', 'speech', 'arkan', 'sonney', 'manx', 'fairy', 'hedgehog', 'asag', 'sumerian', 'hideous', 'rock', 'demon', 'asakku', 'sumerian', 'demon', 'asanbosam', 'west', 'africa', 'iron-toothed', 'vampire', 'asena', 'turkic', 'blue-maned', 'wolf', 'ashi-magari', 'japanese', 'invisible', 'tendril', 'that', 'impedes', 'movement', 'asiman', 'dahomey', 'vampiric', 'possession', 'spirit', 'askefrue', 'germanic', 'female', 'tree', 'spirit', 'ask-wee-da-eed', 'abenaki', 'fire', 'elemental', 'spectral', 'fire', 'asobibi', 'japanese', 'spectral', 'fire', 'k≈çchi', 'prefecture', 'aspidochelone', 'medieval', 'bestiaries', 'island-sized', 'whale', 'sea', 'turtle', 'asrai', 'eng']\n",
      "\n",
      "example: 2\n",
      "query: musical based characters created single-panel cartoons new yorker beginning 1938 opened broadway april 2010 after tryout chicago\n",
      "query_tokens: ['musical', 'based', 'characters', 'created', 'single-panel', 'cartoons', 'new', 'yorker', 'beginning', '1938', 'opened', 'broadway', 'april', '2010', 'after', 'tryout', 'chicago']\n",
      "answer_id: 4340\n",
      "answer: addams family musical songs lyrics addams family musical songs lyrics addams family musical songs lyrics addams family is musical music lyrics andrew lippa book marshall brickman rick elice show is based upon addams family characters created cartoonist charles addams his single-panel gag cartoons new yorker beginning 1938 depict ghoulish american family affinity all things macabre while numerous film television adaptations addams cartoons exist stage show does not draw these portrayals characters after tryout chicago show opened broadway april 2010 broadway production 2010\n",
      "answer_tokens: ['addams', 'family', 'musical', 'songs', 'lyrics', 'addams', 'family', 'musical', 'songs', 'lyrics', 'addams', 'family', 'musical', 'songs', 'lyrics', 'addams', 'family', 'is', 'musical', 'music', 'lyrics', 'andrew', 'lippa', 'book', 'marshall', 'brickman', 'rick', 'elice', 'show', 'is', 'based', 'upon', 'addams', 'family', 'characters', 'created', 'cartoonist', 'charles', 'addams', 'his', 'single-panel', 'gag', 'cartoons', 'new', 'yorker', 'beginning', '1938', 'depict', 'ghoulish', 'american', 'family', 'affinity', 'all', 'things', 'macabre', 'while', 'numerous', 'film', 'television', 'adaptations', 'addams', 'cartoons', 'exist', 'stage', 'show', 'does', 'not', 'draw', 'these', 'portrayals', 'characters', 'after', 'tryout', 'chicago', 'show', 'opened', 'broadway', 'april', '2010', 'broadway', 'production', '2010']\n",
      "\n",
      "example: 3\n",
      "query: is maximum no match points that can be held one time tennis match wimbledon\n",
      "query_tokens: ['is', 'maximum', 'no', 'match', 'points', 'that', 'can', 'be', 'held', 'one', 'time', 'tennis', 'match', 'wimbledon']\n",
      "answer_id: 10661\n",
      "answer: facts figures faq championships wimbledon 2017 official site ibm facts figures faq facts figures about championships read more facts figures frequently asked topics about championships men 212 goran ivanisevic cro 2001 ladies 80 serena williams usa 2015 men 165 ivo karlovic four matches ladies 80 serena williams seven matches total attendance was 493 928 14 days includes middle sunday 24 623 484 391 2015 ball boys ball girls around 250 around 750 entries come through rigorous training routine balls 54 250 used during championships period stored 68 deg f new balls after first seven games allow warm-up then after every 9 games subject availability after use balls sold daily lta-affiliated clubs spectators grounds 2 50 per can three proceeds go ltas wimbledon balls schools scheme yellow balls used first time 1986 start day 48 tins taken onto centre no 1 courts 24 all outside courts bbc is host broadcaster agreement extended 2011 2017 inc global news access audience estimated over 1bn people 200 territories broadcast figures 2016 early headline audience figures uk bbc gentlemens singles final peaked 13 3 million 69 peak share ladies singles final audience peak was 4 8m website there were 10 2 million unique browsers 1 9 million requests wimbledon live stream mixed doubles final featuring heather watson peaked 2 8m gentlemens wheelchair singles final bbc2 gordon reid peaked 1 1m us espn most-watched wimbledon to-date watchespn up 35 vs 2015 tsn canada gentlemens singles final featuring milos raonic became most watched tennis match canada peaking 2 4 million unique devices 20 9m 21 1m 2015 visits 69 4m 72 0 2015 page views 395m 542m 2015 mobile com uniques 5 6m 2 1m 2014 125 mobile com visits 9 6m 8 4m 2015 98 mobile com page views 88 3m 73 7m 2015 app downloads 1 5m com apps uniques split 93 7 com apps page views split 51 49 social media audience 10 5m 8 5m 2015 video views 106m 85m 2015 live wimbledon tv 1 5m global excl spain austria italy germany 1 6m 2015 bespoke social media feeds chinese sina weibo wechat 65k followers wechat prediction game 55k users geo-targeted content posted japanese facebook line platform-specific social media activations facebook frame wimbledon experience facebook 360s wimbledon emojis beat legend vine activation thehill v theworld v thequeue wimbleskills euros challenge giphy channel live wimbledon youtube pinterest wimbledon food custom snapchat filters strawberry lens snapchat wimbledon live stories youtube 3d finals 39 000 spectators grounds any one time catering 2016 wimbledon is largest single annual sporting catering operation 1800 staff carried out europe average quantities supplied championships caterers fmc 177 135 glasses pimms 2772 kilos bananas players champions dinner instigated 1977 lta ball previously held final evening championships was moved middle saturday tradition dancing between two singles champions ceased then was brought back novak djokovic serena williams 2015 2015 held guildhall city london clothing players predominately white rule introduced 1963 almost entirely white rule introduced 1995 clothing submitted club comment earlier year both grand slam wta rules stipulate recognised tennis attire decision day as whether clothingplayers turnout is suitable discretion referee guidelines no solid mass colouring little no dark bold colours no fluorescent colours preference back o\n",
      "answer_tokens: ['facts', 'figures', 'faq', 'championships', 'wimbledon', '2017', 'official', 'site', 'ibm', 'facts', 'figures', 'faq', 'facts', 'figures', 'about', 'championships', 'read', 'more', 'facts', 'figures', 'frequently', 'asked', 'topics', 'about', 'championships', 'men', '212', 'goran', 'ivanisevic', 'cro', '2001', 'ladies', '80', 'serena', 'williams', 'usa', '2015', 'men', '165', 'ivo', 'karlovic', 'four', 'matches', 'ladies', '80', 'serena', 'williams', 'seven', 'matches', 'total', 'attendance', 'was', '493', '928', '14', 'days', 'includes', 'middle', 'sunday', '24', '623', '484', '391', '2015', 'ball', 'boys', 'ball', 'girls', 'around', '250', 'around', '750', 'entries', 'come', 'through', 'rigorous', 'training', 'routine', 'balls', '54', '250', 'used', 'during', 'championships', 'period', 'stored', '68', 'deg', 'f', 'new', 'balls', 'after', 'first', 'seven', 'games', 'allow', 'warm-up', 'then', 'after', 'every', '9', 'games', 'subject', 'availability', 'after', 'use', 'balls', 'sold', 'daily', 'lta-affiliated', 'clubs', 'spectators', 'grounds', '2', '50', 'per', 'can', 'three', 'proceeds', 'go', 'ltas', 'wimbledon', 'balls', 'schools', 'scheme', 'yellow', 'balls', 'used', 'first', 'time', '1986', 'start', 'day', '48', 'tins', 'taken', 'onto', 'centre', 'no', '1', 'courts', '24', 'all', 'outside', 'courts', 'bbc', 'is', 'host', 'broadcaster', 'agreement', 'extended', '2011', '2017', 'inc', 'global', 'news', 'access', 'audience', 'estimated', 'over', '1bn', 'people', '200', 'territories', 'broadcast', 'figures', '2016', 'early', 'headline', 'audience', 'figures', 'uk', 'bbc', 'gentlemens', 'singles', 'final', 'peaked', '13', '3', 'million', '69', 'peak', 'share', 'ladies', 'singles', 'final', 'audience', 'peak', 'was', '4', '8m', 'website', 'there', 'were', '10', '2', 'million', 'unique', 'browsers', '1', '9', 'million', 'requests', 'wimbledon', 'live', 'stream', 'mixed', 'doubles', 'final', 'featuring', 'heather', 'watson', 'peaked', '2', '8m', 'gentlemens', 'wheelchair', 'singles', 'final', 'bbc2', 'gordon', 'reid', 'peaked', '1', '1m', 'us', 'espn', 'most-watched', 'wimbledon', 'to-date', 'watchespn', 'up', '35', 'vs', '2015', 'tsn', 'canada', 'gentlemens', 'singles', 'final', 'featuring', 'milos', 'raonic', 'became', 'most', 'watched', 'tennis', 'match', 'canada', 'peaking', '2', '4', 'million', 'unique', 'devices', '20', '9m', '21', '1m', '2015', 'visits', '69', '4m', '72', '0', '2015', 'page', 'views', '395m', '542m', '2015', 'mobile', 'com', 'uniques', '5', '6m', '2', '1m', '2014', '125', 'mobile', 'com', 'visits', '9', '6m', '8', '4m', '2015', '98', 'mobile', 'com', 'page', 'views', '88', '3m', '73', '7m', '2015', 'app', 'downloads', '1', '5m', 'com', 'apps', 'uniques', 'split', '93', '7', 'com', 'apps', 'page', 'views', 'split', '51', '49', 'social', 'media', 'audience', '10', '5m', '8', '5m', '2015', 'video', 'views', '106m', '85m', '2015', 'live', 'wimbledon', 'tv', '1', '5m', 'global', 'excl', 'spain', 'austria', 'italy', 'germany', '1', '6m', '2015', 'bespoke', 'social', 'media', 'feeds', 'chinese', 'sina', 'weibo', 'wechat', '65k', 'followers', 'wechat', 'prediction', 'game', '55k', 'users', 'geo-targeted', 'content', 'posted', 'japanese', 'facebook', 'line', 'platform-specific', 'social', 'media', 'activations', 'facebook', 'frame', 'wimbledon', 'experience', 'facebook', '360s', 'wimbledon', 'emojis', 'beat', 'legend', 'vine', 'activation', 'thehill', 'v', 'theworld', 'v', 'thequeue', 'wimbleskills', 'euros', 'challenge', 'giphy', 'channel', 'live', 'wimbledon', 'youtube', 'pinterest', 'wimbledon', 'food', 'custom', 'snapchat', 'filters', 'strawberry', 'lens', 'snapchat', 'wimbledon', 'live', 'stories', 'youtube', '3d', 'finals', '39', '000', 'spectators', 'grounds', 'any', 'one', 'time', 'catering', '2016', 'wimbledon', 'is', 'largest', 'single', 'annual', 'sporting', 'catering', 'operation', '1800', 'staff', 'carried', 'out', 'europe', 'average', 'quantities', 'supplied', 'championships', 'caterers', 'fmc', '177', '135', 'glasses', 'pimms', '2772', 'kilos', 'bananas', 'players', 'champions', 'dinner', 'instigated', '1977', 'lta', 'ball', 'previously', 'held', 'final', 'evening', 'championships', 'was', 'moved', 'middle', 'saturday', 'tradition', 'dancing', 'between', 'two', 'singles', 'champions', 'ceased', 'then', 'was', 'brought', 'back', 'novak', 'djokovic', 'serena', 'williams', '2015', '2015', 'held', 'guildhall', 'city', 'london', 'clothing', 'players', 'predominately', 'white', 'rule', 'introduced', '1963', 'almost', 'entirely', 'white', 'rule', 'introduced', '1995', 'clothing', 'submitted', 'club', 'comment', 'earlier', 'year', 'both', 'grand', 'slam', 'wta', 'rules', 'stipulate', 'recognised', 'tennis', 'attire', 'decision', 'day', 'as', 'whether', 'clothingplayers', 'turnout', 'is', 'suitable', 'discretion', 'referee', 'guidelines', 'no', 'solid', 'mass', 'colouring', 'little', 'no', 'dark', 'bold', 'colours', 'no', 'fluorescent', 'colours', 'preference', 'back', 'o']\n",
      "\n",
      "example: 4\n",
      "query: who made century his test debut england v new zealand 2004\n",
      "query_tokens: ['who', 'made', 'century', 'his', 'test', 'debut', 'england', 'v', 'new', 'zealand', '2004']\n",
      "answer_id: 5475\n",
      "answer: 1st test england v new zealand lords may 20-24 2004 cricket scorecard espn cricinfo new zealand 50 16 1 overs richardson 16 fleming 31 new zealand 100 32 3 overs richardson 36 astle 23 nathan astle 50 58 balls 8x4 new zealand 150 44 5 overs richardson 44 astle 60 mark richardson 50 140 balls 9x4 tea new zealand 172 3 richardson 56 mcmillan 4 new zealand 200 69 1 overs richardson 67 oram 16 oram 50 54 balls 9x4 new zealand 250 79 5 overs richardson 78 oram 51 new zealand 300 92 3 overs tuffey 2 cairns 15 new zealand 350 100 overs cairns 47 martin 1 cairns 50 37 balls 9x4 england 1st innings lunch england 27 0 trescothick 10 strauss 15 england 50 18 1 overs trescothick 19 strauss 26 england 100 28 3 overs trescothick 51 strauss 43 trescothick 50 95 balls 9x4 strauss 50 90 balls 5x4 tea england 136 0 trescothick 60 strauss 65 england 150 41 1 overs trescothick 66 strauss 74 england 200 54 4 overs strauss 91 butcher 5 strauss 100 276 mins off 199 balls 12x4 england 250 76 4 overs butcher 23 hoggard 3 england 300 95 5 overs hussain 29 flintoff 1 lunch england 330 6 flintoff 10 jones 11 england 350 104 1 overs flintoff 22 go jones 15 england 400 114 overs flintoff 47 go jones 37 flintoff 50 64 balls 6x4 2x6 100 run partnership between flintoff jones 108 balls new zealand 2nd innings new zealand 50 16 overs richardso 17 mccullum 26 brendon mccullum 50 54 balls 8x4 mh richardson 50 188 minutes off 127 balls including 5x4 150 2nd wicket partnership off 256 balls richardson 50 mccullum 87 lunch new zealand 1984 richardson 72 oram 3 new zealand 200 68 3 overs richardson 76 oram 4 new zealand 250 86 1 overs richardson 94 astle 24 mh richardson 100 402 mins off 289 balls 10x4 tea new zealand 269 5 richardson 101 astle 29 new zealand 300 109 3 overs cairns 9 vettori 5 england 2nd innings england 50 24 5 overs strauss 33 hussain 5 andrew strauss 50 97 balls 8x4 england 100 39 5 overs strauss 59 hussain 22 100 run partnership between strauss hussain 183 balls england 150 53 overs hussain 31 thorpe 5 50 run partnership between thorpe hussain 118 balls england 200 72 1 overs hussain 49 thorpe 34 nasser hussain 50 158 balls 7x4 100 run partnership between thorpe hussain 181 balls england 250 81 3 overs hussain 78 thorpe 44 thorpe 50 97 balls 6x4 n hussain 100 292 mins off 203 balls 15x4\n",
      "answer_tokens: ['1st', 'test', 'england', 'v', 'new', 'zealand', 'lords', 'may', '20-24', '2004', 'cricket', 'scorecard', 'espn', 'cricinfo', 'new', 'zealand', '50', '16', '1', 'overs', 'richardson', '16', 'fleming', '31', 'new', 'zealand', '100', '32', '3', 'overs', 'richardson', '36', 'astle', '23', 'nathan', 'astle', '50', '58', 'balls', '8x4', 'new', 'zealand', '150', '44', '5', 'overs', 'richardson', '44', 'astle', '60', 'mark', 'richardson', '50', '140', 'balls', '9x4', 'tea', 'new', 'zealand', '172', '3', 'richardson', '56', 'mcmillan', '4', 'new', 'zealand', '200', '69', '1', 'overs', 'richardson', '67', 'oram', '16', 'oram', '50', '54', 'balls', '9x4', 'new', 'zealand', '250', '79', '5', 'overs', 'richardson', '78', 'oram', '51', 'new', 'zealand', '300', '92', '3', 'overs', 'tuffey', '2', 'cairns', '15', 'new', 'zealand', '350', '100', 'overs', 'cairns', '47', 'martin', '1', 'cairns', '50', '37', 'balls', '9x4', 'england', '1st', 'innings', 'lunch', 'england', '27', '0', 'trescothick', '10', 'strauss', '15', 'england', '50', '18', '1', 'overs', 'trescothick', '19', 'strauss', '26', 'england', '100', '28', '3', 'overs', 'trescothick', '51', 'strauss', '43', 'trescothick', '50', '95', 'balls', '9x4', 'strauss', '50', '90', 'balls', '5x4', 'tea', 'england', '136', '0', 'trescothick', '60', 'strauss', '65', 'england', '150', '41', '1', 'overs', 'trescothick', '66', 'strauss', '74', 'england', '200', '54', '4', 'overs', 'strauss', '91', 'butcher', '5', 'strauss', '100', '276', 'mins', 'off', '199', 'balls', '12x4', 'england', '250', '76', '4', 'overs', 'butcher', '23', 'hoggard', '3', 'england', '300', '95', '5', 'overs', 'hussain', '29', 'flintoff', '1', 'lunch', 'england', '330', '6', 'flintoff', '10', 'jones', '11', 'england', '350', '104', '1', 'overs', 'flintoff', '22', 'go', 'jones', '15', 'england', '400', '114', 'overs', 'flintoff', '47', 'go', 'jones', '37', 'flintoff', '50', '64', 'balls', '6x4', '2x6', '100', 'run', 'partnership', 'between', 'flintoff', 'jones', '108', 'balls', 'new', 'zealand', '2nd', 'innings', 'new', 'zealand', '50', '16', 'overs', 'richardso', '17', 'mccullum', '26', 'brendon', 'mccullum', '50', '54', 'balls', '8x4', 'mh', 'richardson', '50', '188', 'minutes', 'off', '127', 'balls', 'including', '5x4', '150', '2nd', 'wicket', 'partnership', 'off', '256', 'balls', 'richardson', '50', 'mccullum', '87', 'lunch', 'new', 'zealand', '1984', 'richardson', '72', 'oram', '3', 'new', 'zealand', '200', '68', '3', 'overs', 'richardson', '76', 'oram', '4', 'new', 'zealand', '250', '86', '1', 'overs', 'richardson', '94', 'astle', '24', 'mh', 'richardson', '100', '402', 'mins', 'off', '289', 'balls', '10x4', 'tea', 'new', 'zealand', '269', '5', 'richardson', '101', 'astle', '29', 'new', 'zealand', '300', '109', '3', 'overs', 'cairns', '9', 'vettori', '5', 'england', '2nd', 'innings', 'england', '50', '24', '5', 'overs', 'strauss', '33', 'hussain', '5', 'andrew', 'strauss', '50', '97', 'balls', '8x4', 'england', '100', '39', '5', 'overs', 'strauss', '59', 'hussain', '22', '100', 'run', 'partnership', 'between', 'strauss', 'hussain', '183', 'balls', 'england', '150', '53', 'overs', 'hussain', '31', 'thorpe', '5', '50', 'run', 'partnership', 'between', 'thorpe', 'hussain', '118', 'balls', 'england', '200', '72', '1', 'overs', 'hussain', '49', 'thorpe', '34', 'nasser', 'hussain', '50', '158', 'balls', '7x4', '100', 'run', 'partnership', 'between', 'thorpe', 'hussain', '181', 'balls', 'england', '250', '81', '3', 'overs', 'hussain', '78', 'thorpe', '44', 'thorpe', '50', '97', 'balls', '6x4', 'n', 'hussain', '100', '292', 'mins', 'off', '203', 'balls', '15x4']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('example:', i)\n",
    "    print('query:', dataset['train'][i]['query'])\n",
    "    print('query_tokens:', dataset['train'][i]['query_tokens'])\n",
    "    answer_id = dataset['train'][i]['answer_id']\n",
    "    print('answer_id:', answer_id)\n",
    "    print('answer:', answers_dataset['train'][answer_id]['answer'])\n",
    "    print('answer_tokens:', answers_dataset['train'][answer_id]['answer_tokens'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice the difference in the types of the different structures we use. Run the following cell to check the types. Do they make sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "--\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "--\n",
      "who is quoted as saying advertising attracts all bright creative ambitious young people leaving us mainly slow self-obsessed become our artists never field human history has so much been used so many say so little\n",
      "<class 'str'>\n",
      "--\n",
      "['who', 'is', 'quoted', 'as', 'saying', 'advertising', 'attracts', 'all', 'bright', 'creative', 'ambitious', 'young', 'people', 'leaving', 'us', 'mainly', 'slow', 'self-obsessed', 'become', 'our', 'artists', 'never', 'field', 'human', 'history', 'has', 'so', 'much', 'been', 'used', 'so', 'many', 'say', 'so', 'little']\n",
      "<class 'list'>\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#type of original dataset\n",
    "print(type(dataset))\n",
    "print(\"--\")\n",
    "#type of the split of the dataset\n",
    "print(type(dataset['test']))\n",
    "print(\"--\")\n",
    "#type of original query\n",
    "print(dataset['train'][0]['query'])\n",
    "print(type(dataset['train'][0]['query']))\n",
    "print(\"--\")\n",
    "#type of tokenized query\n",
    "print(dataset['train'][0]['query_tokens'])\n",
    "print(type(dataset['train'][0]['query_tokens']))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bag of Words\n",
    "\n",
    "In this section you will built a bag-of-words representation of the dataset. We will use numpy arrays to store the results. The bag-of-words representation is a simple and effective way to represent text data. It involves creating a vocabulary of unique words from the dataset and representing each sentence as a vector of word counts. We first need the vocabulary, which we will build from both the full sentences and the compressed sentences. Similar to the first lab, the vocabulary will be a list of unique words from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extracting Vocabulary\n",
    "\n",
    "<a name='e4'></a>\n",
    "#### Exercise 4: Extracting vocabulary counts\n",
    "\n",
    "In the following cell, you will implement a function that takes two datasets (`dataset`, and `answers_dataset`) and returns a dictionary with the counts of each word in the vocabulary. The dictionary should be of the form {word: count}. As in previous lab, you will use the `Counter` class from the `collections` module to do this. Iterate over the two datasets and count the tokens in `query_tokens` and `answer_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_vocabulary_counts(dataset, answers_dataset):\n",
    "    \"\"\"\n",
    "    Extracts the vocabulary from the tokenized sentences\n",
    "    Args:\n",
    "        dataset: a Dataset from which 'query_tokens' are used to build vocabulary\n",
    "        answers_dataset: a Dataset from which 'answer_tokens' are used to build vocabulary\n",
    "\n",
    "    Returns: a Counter object with the counts of each word in the vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    vocab = Counter()\n",
    "    ### YOUR CODE HERE\n",
    "    for atoken in answers_dataset['answer_tokens']:\n",
    "        vocab.update(atoken)\n",
    "    for qtoken in dataset['query_tokens']:\n",
    "        vocab.update(qtoken)\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>new evidence jet milky ways black hole todays ...</td>\n",
       "      <td>[new, evidence, jet, milky, ways, black, hole,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dick turpin highwaymen highway robbery dick tu...</td>\n",
       "      <td>[dick, turpin, highwaymen, highway, robbery, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>felix baumgartner death felix baumgartner net ...</td>\n",
       "      <td>[felix, baumgartner, death, felix, baumgartner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bbc news uk scotland alexander quits as labour...</td>\n",
       "      <td>[bbc, news, uk, scotland, alexander, quits, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>definition stapes definition stapes causes hea...</td>\n",
       "      <td>[definition, stapes, definition, stapes, cause...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             answer  \\\n",
       "0   0  new evidence jet milky ways black hole todays ...   \n",
       "1   1  dick turpin highwaymen highway robbery dick tu...   \n",
       "2   2  felix baumgartner death felix baumgartner net ...   \n",
       "3   3  bbc news uk scotland alexander quits as labour...   \n",
       "4   4  definition stapes definition stapes causes hea...   \n",
       "\n",
       "                                       answer_tokens  \n",
       "0  [new, evidence, jet, milky, ways, black, hole,...  \n",
       "1  [dick, turpin, highwaymen, highway, robbery, d...  \n",
       "2  [felix, baumgartner, death, felix, baumgartner...  \n",
       "3  [bbc, news, uk, scotland, alexander, quits, as...  \n",
       "4  [definition, stapes, definition, stapes, cause...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "temp = pd.DataFrame(answers_dataset['train'])\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we use the function you implemented. Notice that we build our vocabulary based on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446571\n",
      "[('is', 287014), ('was', 228857), ('as', 181998), ('that', 174838), ('it', 148236), ('his', 140600), ('he', 128948), ('this', 107538), ('are', 107275), ('be', 87880)]\n"
     ]
    }
   ],
   "source": [
    "vocab_counter = extract_vocabulary_counts(dataset['train'], answers_dataset['train'])\n",
    "print(len(vocab_counter))\n",
    "print(vocab_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will truncate the vocabulary. We also create the handy `token_to_id` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 20_000\n",
    "vocab = vocab_counter.most_common(max_vocab_size)\n",
    "# cast to list of words\n",
    "vocab = [word for word, _ in vocab]\n",
    "token_to_id = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "\n",
    "<a name='e5'></a>\n",
    "#### Exercise 5: Bag of Words\n",
    "Here we will create the bag-of-words representation of the sentences. The function will take a single sentence (list of tokens) and return an array of size `vocab_size` with the counts of each word in the vocabulary. The\n",
    "`vocab_size` is calculated as the length of the passed `token_to_id` dictionary. The resulting array should have zeros everywhere but the indices corresponding to the words in the vocabulary where it should have the counts of the words in the sentence. For example, if the sentence is `['fox', 'and', 'deer']` and the vocabulary is `{'fox': 0, 'and': 1, 'deer': 2}`, the resulting array should be `[1, 1, 1]`. If the sentence is `['fox', 'and', 'fox', 'deer']`, the resulting array should be `[2, 1, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bag_of_words(sentence_tokens, token_to_id):\n",
    "    \"\"\"\n",
    "    Creates a bag-of-words representation of the sentence\n",
    "    Args:\n",
    "        sentence_tokens: a list of tokens\n",
    "        token_to_id: a dictionary mapping each word to an index in the vocabulary\n",
    "\n",
    "    Returns:: a numpy array of size vocab_size with the counts of each word in the vocabulary\n",
    "    \"\"\"\n",
    "    vocab_size = len(token_to_id)\n",
    "    bow = np.zeros(vocab_size, dtype=int)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    for token in sentence_tokens:\n",
    "        vocab_idx = token_to_id.get(token)\n",
    "        if vocab_idx is not None:\n",
    "            bow[vocab_idx] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's test the function. The output should be a numpy array of size `vocab_size` with the counts of each word in the vocabulary. Notice that most of the elements of the BOW representation are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence:\n",
      "['late', '1940s', 'soldier', 'named', 'constantin', 'esmont', 'made', 'detailed', 'records', 'various', 'types', 'dog', 'known', 'as', 'borzoi', 'concerned', 'that', 'breed', 'was', 'degenerating', 'where', 'did', 'breed', 'originate']\n",
      "Bag of words:\n",
      "[0 1 1 ... 0 0 0]\n",
      "Type of bag of words:\n",
      "<class 'numpy.ndarray'>\n",
      "Shape of bag of words:\n",
      "(20000,)\n",
      "Non-zero elements in bag of words:\n",
      "[   1    2    3   62   63   68  107  249  383  549  756  861  957 2897\n",
      " 2949 3042 3222 4805 9181]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized sentence:')\n",
    "print(dataset['test'][0]['query_tokens'])\n",
    "query_bow = bag_of_words(dataset['test'][0]['query_tokens'], token_to_id)\n",
    "query_non_zero_bow = np.nonzero(query_bow)[0]\n",
    "\n",
    "print('Bag of words:')\n",
    "print(query_bow)\n",
    "print('Type of bag of words:')\n",
    "print(type(query_bow))\n",
    "print('Shape of bag of words:')\n",
    "print(query_bow.shape)\n",
    "print('Non-zero elements in bag of words:')\n",
    "print(query_non_zero_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine further the non-zero elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements in bag of words:\n",
      "[   1    2    3   62   63   68  107  249  383  549  756  861  957 2897\n",
      " 2949 3042 3222 4805 9181]\n",
      "was : 1\n",
      "as : 1\n",
      "that : 1\n",
      "made : 1\n",
      "where : 1\n",
      "known : 1\n",
      "did : 1\n",
      "named : 1\n",
      "late : 1\n",
      "various : 1\n",
      "records : 1\n",
      "types : 1\n",
      "dog : 1\n",
      "breed : 2\n",
      "concerned : 1\n",
      "soldier : 1\n",
      "detailed : 1\n",
      "1940s : 1\n",
      "originate : 1\n"
     ]
    }
   ],
   "source": [
    "print('Non-zero elements in bag of words:')\n",
    "print(query_non_zero_bow)\n",
    "for i in query_non_zero_bow:\n",
    "    print(vocab[i], ':', query_bow[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Function for Embedding Text\n",
    "\n",
    "The following function will apply all the steps we implemented to a single sentence. It returns a bag of words representation that we will use to calculate the similarity between different sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "[   0    7  457 3450]\n"
     ]
    }
   ],
   "source": [
    "def embed_text(text, clean_fn, tokenize_fn, embed_fn):\n",
    "    \"\"\"\n",
    "    Embeds the text using the provided functions. The pipeline applies cleaning (clean_fn), tokenization (tokenize_fn), and embedding (embed_fn).\n",
    "    Args:\n",
    "        text: the text to be embedded\n",
    "        clean_fn: function/Callable clean_fn(text:str):str\n",
    "        tokenize_fn: function/Callable tokenize_fn(text:str): List[str]\n",
    "        embed_fn: function/Callable embed_fn(tokens:List[str]): np.ndarray\n",
    "\n",
    "    Returns: the embedding of the text as a numpy array\n",
    "    \"\"\"\n",
    "    cleaned = clean_fn(text)\n",
    "    tokens = tokenize_fn(cleaned)\n",
    "    embedding = embed_fn(tokens)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "embedding = embed_text(\"This is an example of a sentence\", clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "print(embedding.shape)\n",
    "print(np.nonzero(embedding)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "<a name='e6'></a>\n",
    "#### Exercise 6: Cosine Similarity between two vectors\n",
    "\n",
    "Complete the following function that given any two vectors will compute the cosine similarity. If you don't remember the formula for the cosine similarity, revisit the course material. Notice that the function receives numpy arrays and recall that you can express cosine similarity as a dot product. Use numpy functions to write an efficient implementation. Two more exercises builds upon this one, so make sure to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors\n",
    "    Args:\n",
    "        vector1: numpy array of the first vector\n",
    "        vector2: numpy array of the second vector\n",
    "\n",
    "    Returns: cosine similarity\n",
    "\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    cosine = 0.0\n",
    "    dot_prod = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    if norm1 != 0 and norm2 != 0: \n",
    "        cosine = dot_prod / (norm1 * norm2) \n",
    "    return cosine\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999999999999998)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(np.array([0, 1, 2]), np.array([0, 2, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see how similar are the BOW representations of some sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: fox and deer\n",
      "Cosine Similarity: 0.2673 - Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Cosine Similarity: 0.0000 - Sentence: Some interesting document containing sentences.\n",
      "Cosine Similarity: 0.2236 - Sentence: The quick brown fox jumps over the lazy cat and some other stuff.\n",
      "Cosine Similarity: 0.6325 - Sentence: Fox and deer are not friends.\n",
      "Cosine Similarity: 0.3015 - Sentence: Fox and deer are not friends. But this document is a lot longer than the previous one. We can add sentence by sentence and see how the embeddings change.\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog.',\n",
    "    'Some interesting document containing sentences.',\n",
    "    'The quick brown fox jumps over the lazy cat and some other stuff.',\n",
    "    'Fox and deer are not friends.',\n",
    "    'Fox and deer are not friends. But this document is a lot longer than the previous one. We can add sentence by sentence and see how the embeddings change.',\n",
    "]\n",
    "embedded_sentences = [\n",
    "    embed_text(sentence, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "query = 'fox and deer'\n",
    "embedded_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "\n",
    "cosine_similarities = [\n",
    "    cosine_similarity(embedded_query, embedded_sentence)\n",
    "    for embedded_sentence in embedded_sentences\n",
    "]\n",
    "print(f'Query: {query}')\n",
    "for sent, cos_sim in zip(sentences, cosine_similarities):\n",
    "    print(f'Cosine Similarity: {cos_sim:.4f} - Sentence: {sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Retrieval\n",
    "\n",
    "In this section, we will use the BOW representations to finally search for the answers to our questions. We start by calculating the BOWs of queries and answers of the whole `validation` subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:01<00:00, 7260.59it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9740/9740 [00:05<00:00, 1932.81it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_queries_bows = []\n",
    "for example in tqdm.tqdm(dataset['validation']):\n",
    "    valid_queries_bows.append(bag_of_words(example['query_tokens'], token_to_id))\n",
    "\n",
    "valid_answers_bows = []\n",
    "for example in tqdm.tqdm(answers_dataset['validation']):\n",
    "    valid_answers_bows.append(bag_of_words(example['answer_tokens'], token_to_id))\n",
    "\n",
    "valid_queries_bows = np.array(valid_queries_bows)\n",
    "valid_answers_bows = np.array(valid_answers_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e7'></a>\n",
    "#### Exercise 7: Cosine Similarity between a vector and an array of vectors\n",
    "\n",
    "The next step in our retrieval system, would be to calculate the proximity of a query to our retrieval corpus (in our case that is all the sentences).\n",
    "\n",
    "Complete the following function to calculate the cosine similarity between a vector (first parameter `vector`, that will usually be the query vector) and all other vectors (second parameter `other_vectors`, that will be the sentence embeddings in our case). Note that the `other_vectors` parameter is a single numpy array of size `N x D`, where $N$ is the number of vectors and $D$ is the dimension of each vector.\n",
    "\n",
    "For maximum efficiency (we will need it) do not use loops. Try to write the implementation with numpy functions. Hint: matrix multiplication can be seen as calculating the dot product between rows and columns of the multiplied matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_1_to_n(vector, other_vectors):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between a single vector and other vectors.\n",
    "    Args:\n",
    "        vector: a numpy array representing a vector of D dimensions\n",
    "        other_vectors: a 2D numpy array representing other vectors (of the size NxD, where N is the number of vectors and D is their dimension)\n",
    "\n",
    "    Returns: a 1D numpy array of size N containing the cosine similarity between the vector and all the other vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    dot_prods = other_vectors @ vector\n",
    "    \n",
    "    v_norm = np.linalg.norm(vector)\n",
    "    ov_norms = np.linalg.norm(other_vectors, axis=1)\n",
    "\n",
    "    denom = v_norm * ov_norms\n",
    "    cos_similarities = np.zeros_like(dot_prods, dtype=float)\n",
    "    nonzero = denom != 0\n",
    "    cos_similarities[nonzero] = dot_prods[nonzero] / denom[nonzero]\n",
    "\n",
    "    return cos_similarities\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now can try out our retrieval system by calculating the cosine similarities between the query and all answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9740,)\n",
      "[0.13763941 0.05975289 0.01057801 0.05181349 0.00835425 0.01944407\n",
      " 0.15092204 0.00809644 0.03619502 0.0608995 ]\n"
     ]
    }
   ],
   "source": [
    "query = 'Which vegetable is Blackadder‚Äôs servant obsessed with in the UK television series ‚ÄòBlackadder II‚Äô?'\n",
    "embedded_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "\n",
    "query_similarity = cosine_similarity_1_to_n(embedded_query, valid_answers_bows)\n",
    "print(query_similarity.shape)\n",
    "print(query_similarity[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6548\n",
      "0.32311021885505176\n",
      "[16  1 12 ...  0  0  0]\n",
      "blackadder main page see live article alphabetical index blackadder blackadder is british television comedy programme bbc surreal take british history blackadder is not title any specific series is general term programmes four series several one-off episodes taken as whole series were written rowan atkinson ben elton richard curtis produced john lloyd four series were made each one set different period history featuring anti-hero blackadder it is implied that each series blackadder character is descendant previous one each observed generation blackadders social standing is reduced prince nobleman royal butler army captain end nothing more than cannon-fodder all series starred rowan atkinson as blackadder tony robinson as his sidekick baldrick each series also tended feature same set actors different period settings thus stephen fry played lord melchett advisor queen second series general melchett blustering buffoon fourth anachronistic references were plentiful mainly humorous it popularised use simile associated devices comic effect britain examples include madder than mad jack mcmad winner last years mr madman competition ive got plan so cunning you could put tail it call it weasel as cunning as fox whos just been appointed professor cunning oxford university im as happy as frenchman whos just invented pair self-removing trousers im as weary as dog no legs thats just climbed ben nevis table contents blackadder cavalier years 1988 15 minute insert comic relief night blackadders christmas carol 1988 45 minute christmas special blackadder back forth 1999 45 minute millennium dome special series 1 black adder set middle ages this is fact alternate history it opens battle bosworth field 1485 being won richard iii played peter cook instead henry tudor who won real life however richard iii is then accidentally killed shortly after battle late kings nephew richard duke york is crowned as richard iv richard his wife queen gertrude flowers witch queen have two sons harry prince wales prince regent captain guard grand warden northern eastern marches chief lunatic duchy gloucester viceroy wales sheriff nottingham marquis midlands lord hoe-maker ordinary harbinger doomed rat 1460 1498 prince edmund black adder duke edinburgh warden royal privvies laird roxburg selkirk peebles archbishop canterbury great gumblededook duke hastings 1461 1498 it is later revealed episode born be king that after harrys birth preceding edmunds queen gertrude had affair donald mcangus third duke argyll there is possibility that edmund was this affairs result if so then edmund is harrys half-brother also has another half-brother lord dougal mcangus supreme commander kings army c 1462 1487 end series events converge our timeline king richard iv his entire family are poisoned allowing henry tudor take throne as king henry vii he then proceeds rewrite history presenting richard iii as monster eliminating richard ivs reign history books this series character black adder is somewhat different later incarnations being largely unintelligent relying more plans baldrick episode list foretelling richard iii wins historic battle bosworth field is promptly killed his bumbling grandnephew edmund understandably late king is livid this wont let edmund forget it born be king edmunds elder brother harry is looking after throne while t\n"
     ]
    }
   ],
   "source": [
    "most_similar = int(np.argmax(query_similarity))\n",
    "print(most_similar)\n",
    "print(query_similarity[most_similar])\n",
    "print(valid_answers_bows[most_similar])\n",
    "print(answers_dataset['validation'][most_similar]['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function returns the indices of the top-k elements in the array. If the `sorted` parameter is `True` (it is by default) the returned array will be sorted in the descending order (of the corresponding values in array). For example, if the `array` is `[3, 2, 4, 1]` and `k=2` the returned numpy array will be `[2, 0]` if `sorted` is True (the top values are `3` and `4` with indices `0` and `2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def top_k_indices(array, k, sorted=True):\n",
    "    \"\"\"\n",
    "    Returns top-k indices from the 1D array. If `sorted` is `True` the returned indices are sorted in the descending order\n",
    "    Args:\n",
    "        array: a 1D numpy array\n",
    "        k: a number of top indices to return\n",
    "        sorted: if True, the returned indices are sorted in descending order\n",
    "\n",
    "    Returns: a 1D numpy array containing top-k indices\n",
    "\n",
    "    \"\"\"\n",
    "    top_k = np.argpartition(array, -k)[-k:]\n",
    "    if sorted:\n",
    "        selected = array[top_k]\n",
    "        sorted_selected = (-selected).argsort()\n",
    "        top_k = top_k[sorted_selected]\n",
    "    return top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackadder main page see live article alphabetical index blackadder blackadder is british television comedy programme bbc surreal take british history blackadder is not title any specific series is general term programmes four series several one-off episodes taken as whole series were written rowan atkinson ben elton richard curtis produced john lloyd four series were made each one set different period history featuring anti-hero blackadder it is implied that each series blackadder character is descendant previous one each observed generation blackadders social standing is reduced prince nobleman royal butler army captain end nothing more than cannon-fodder all series starred rowan atkinson as blackadder tony robinson as his sidekick baldrick each series also tended feature same set actors different period settings thus stephen fry played lord melchett advisor queen second series general melchett blustering buffoon fourth anachronistic references were plentiful mainly humorous it popularised use simile associated devices comic effect britain examples include madder than mad jack mcmad winner last years mr madman competition ive got plan so cunning you could put tail it call it weasel as cunning as fox whos just been appointed professor cunning oxford university im as happy as frenchman whos just invented pair self-removing trousers im as weary as dog no legs thats just climbed ben nevis table contents blackadder cavalier years 1988 15 minute insert comic relief night blackadders christmas carol 1988 45 minute christmas special blackadder back forth 1999 45 minute millennium dome special series 1 black adder set middle ages this is fact alternate history it opens battle bosworth field 1485 being won richard iii played peter cook instead henry tudor who won real life however richard iii is then accidentally killed shortly after battle late kings nephew richard duke york is crowned as richard iv richard his wife queen gertrude flowers witch queen have two sons harry prince wales prince regent captain guard grand warden northern eastern marches chief lunatic duchy gloucester viceroy wales sheriff nottingham marquis midlands lord hoe-maker ordinary harbinger doomed rat 1460 1498 prince edmund black adder duke edinburgh warden royal privvies laird roxburg selkirk peebles archbishop canterbury great gumblededook duke hastings 1461 1498 it is later revealed episode born be king that after harrys birth preceding edmunds queen gertrude had affair donald mcangus third duke argyll there is possibility that edmund was this affairs result if so then edmund is harrys half-brother also has another half-brother lord dougal mcangus supreme commander kings army c 1462 1487 end series events converge our timeline king richard iv his entire family are poisoned allowing henry tudor take throne as king henry vii he then proceeds rewrite history presenting richard iii as monster eliminating richard ivs reign history books this series character black adder is somewhat different later incarnations being largely unintelligent relying more plans baldrick episode list foretelling richard iii wins historic battle bosworth field is promptly killed his bumbling grandnephew edmund understandably late king is livid this wont let edmund forget it born be king edmunds elder brother harry is looking after throne while t\n",
      "similarity: 0.32311021885505176\n",
      "\n",
      "robert powell tv shows starring robert powell 6 items g options b comments embed 1 canned carrott jasper carrott hugh dennis robert powell canned carrott is comedy stand-up sketch-show jasper carrott two regular sketches were wiggy detectives first sketch wiggy followed 2 doomwatch robert powell amanda ooms john paul doomwatch was british science fiction television programme produced bbc ran bbc1 between 1970 1972 series was set then present-day dealt scientific 3 fantomcat robert powell jimmy hibbert rob rackstraw fantomcat is animated series produced cosgrove hall films it was first broadcast 1995 was animated after avenger penguins 1994 alfonso productions spanish animation studio it 4 great crimes trials robert powell great crimes trials is early 1990s bbc documentary television series program consists archival material combined never before seen interviews reconstruct renowned crime 5 hannay robert powell hannay was 1988 spin-off 1978 film version john buchans novel thirty-nine steps had starred robert powell as richard hannay 6 holby city hugh quarshie tina hobley rosie marcel holby city is british medical drama television series that airs weekly bbc one series was created tony mchale mal young as spin-off established bbc medical drama casualty 7 jesus nazareth james earl jones laurence olivier christopher plummer jesus nazareth is 1977 british-italian television miniseries directed franco zeffirelli co-written zeffirelli anthony burgess suso cecchi damico dramatises birth life 8 jude obscure robert powell john franklyn-robbins daphne heard jude obscure is 1971 tv mini-series written harry green directed hugh david 9 looking clancy catherine schell robert powell t p mckenna 10 shaka zulu christopher lee trevor howard edward fox shaka zulu is television series directed william c faure written joshua sinclair south african broadcasting corporation based sinclairs novel same name it is based 11 detectives jasper carrott hugh dennis robert powell detectives is british comedy television series starring jasper carrott robert powell george sewell it aired bbc one was spoof police dramas it was written mike whitehill 12 legends treasure island hugh laurie dawn french richard e grant legends treasure island is animated cartoon uk that ran 1993-1995 it had two series 13 episodes each each episode runs 2225 minutes series was loosely based\n",
      "similarity: 0.27096567310831304\n",
      "\n",
      "enter value into either text box select units using drop-down boxes is electrical conductance electrical conductance is measure flow electricity through electrical component given potential difference si unit conductance is siemens it is inverse electrical resistance so that conductance g 1r where r is resistance ohms hence playful alternative name si unit is √¢mho√¢ electrical conductance should not be confused related measure conductance is property material itself conductance is also connected susceptance admittance ac alternating current circuits y g jb g re y where y admittance j is imaginary number b is susceptance kirchhoffs voltage law is applied we find that voltage is sum voltages across each conductance g g1 g2 g1g2 semiconductors conductance components such as diodes transistors is usually evaluated small signal conditions appropriate bias so that operation is linear region their characteristics conductance is therefore inverse small-signal resistance electrical conductance is represented symbol g electrical conductance is very useful concept dealing parallel dc circuits this reason inverse impedance is defined as admittance is similarly useful parallel ac circuits generally there are resistive reactive elements then equation that is formed g is r r2 x2 where x is reactance bookmark this page your browser using ctrl√¢ and√¢ d using one these services opens new window\n",
      "similarity: 0.26565863720081345\n",
      "\n",
      "spectacular series director oliver stone this jewel nations crown is being re-released celebrate 40th anniversary its first broadcast took place 31st october 1973 world war is regarded many be one greatest documentary series all time this bafta emmy award winning documentary series was first broadcast 40 years ago was first factual series its kind document full history world war ii series was memorably narrated legendary screen actor stage icon sir laurence olivier world war has been inspiring film makers historians past 40 years including such programmes as bbcs nazis warning history produced laurence reece more recently oliver stones untold history united states both series creators laying claim being inspired world war available now buy amazon synopsis world war was conceived produced sir jeremy isaacs was first broadcast itv network 31st october 1973 making use rare black white colour film archive footage supplied imperial war museum this 26 part documentary series investigates events surrounding world war ii features interviews major members allied axis campaigns including civilian eyewitnesses enlisted men officers government advisors politicians create is widely agreed be definitive history world war ii landmark british television history 2010 series went through major digital restoration upgrade hd archive film used series is only world war ii footage its kind be restored remastered hd 16 9 5 1 sound lord olivier provided brilliant narration series dvd blu-ray specifications\n",
      "similarity: 0.26229986607815103\n",
      "\n",
      "characteristics toxic gases service support crowcon detection characteristics toxic gases 0 59 nh3 ammonia is only common alkaline gas its density is about half that air it has characteristic smell its maximum safe level is 25ppm its alkalinity makes it highly reactive acid gases chlorine its presence atmospheres containing other gases is often masked this instance if ammonia chlorine are present equal concentrations result is cloud ammonium chloride neither two gases ammonia is flammable lel 15 it is produced vast quantities all over world provide fertilisers urea resins explosives fibres such as nylon it is also used as refrigerant gas this application is increasing demise cfcs another application is maintain sterility water supplies after treatment chlorine sulphur dioxide 2 7 ash3 arsine is colourless flammable highly toxic gas it has garlic-like fishy odour that can be detected concentrations 0 5ppm above because arsine is not irritating produces no immediate symptoms persons exposed hazardous levels may be unaware its presence it is generally shipped cylinders as liquefied compressed gas arsine gas is generated metals crude ores containing arsenic impurities are treated acid arsine gas is also used semiconductor industry depositing arsenic microchips 5 5 br2 bromine is used manufacture wide variety compounds used industry agriculture bromine is also used manufacture fumigants flame-proofing agents water purification compounds dyes medicines sanitizers inorganic bromides photography etc it is also used form intermediates organic synthesis where it is preferred iodine due its much lower cost bromine is used make brominated vegetable oil is used as emulsifier many citrus flavoured soft drinks elemental bromine is strong irritant concentrated form will produce painful blisters exposed skin especially mucous membranes even low concentrations bromine vapour 10 ppm can affect breathing inhalation significant amounts bromine can seriously damage respiratory system carbon dioxide 1 53 co2 despite fact that we breathe out carbon dioxide that it is present atmosphere extent about 400ppm its maximum safe level is 5000ppm 0 5 it is produced during combustion brewing distillation other fermentation processes is one main constituents methane landfill gas sewage treatment digester gas co2 presents significant hazard brewing industry particularly as gas is heavier than air collects low levels there is some degree risk crowded badly ventilated places this problem is often worsened oxygen deficiency co2 is also used increase plant growth elevating normal levels greenhouses etc it is odourless colourless difficult measure ppm levels infrared absorption is usual detection technique adopted carbon monoxide 0 97 co carbon monoxide is odourless colourless is most abundant toxic gas having similar density air it mixes easily is readily inhaled it is renowned silent killer domestic environments any process where there is incomplete combustion carbon fuel is likely produce carbon monoxide example petrol diesel engines coal gas oil boilers even smoking its presence mines is due slow combustion coal it is also used enormous quantities as cheap chemical reducing agent example steel production other metal refining heat treatment processes production methanol reaction hydrogen chlorine 2 5 cl2 chlorine is pungent smelling corrosive greenyellow gas best known use is water purification domestic supplies swimming pools it is used\n",
      "similarity: 0.2613221032032594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_indices = top_k_indices(query_similarity, k=5).tolist()\n",
    "for idx in top_indices:\n",
    "    print(answers_dataset['validation'][idx]['answer'])\n",
    "    print(f'similarity: {query_similarity[idx]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e8'></a>\n",
    "#### Exercise 8: Analyzing and improving BOW search results\n",
    "\n",
    "Experiment with different queries (taking into account the nature of the dataset and your insights from the analysis so far).\n",
    "Answer the following questions:\n",
    "- Does the search perform well? When does it fail? Discuss several examples that are we get an expected but also unexpected results (find at least 3 from each category). Provide reasons for the good/bad result in each case (e.g. is there some error in the data, is there some linguistic phenomenon that we don't capture, is something wrong with our modeling, ...)\n",
    "- If you see problems with search, how could you improve your implementation? Change the functions above, if you think there is room for improvement. Describe your changes and how they made the search better or (in case you made no changes) explain what made the search robust enough to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>original_query</th>\n",
       "      <th>original_answer</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>query_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sept 17 1976 saw unveiling nasa space shuttle ...</td>\n",
       "      <td>Sept 17, 1976 saw the unveiling of which NASA ...</td>\n",
       "      <td>BAA - News &amp; Events: Calendar news &amp; events Re...</td>\n",
       "      <td>1200</td>\n",
       "      <td>[sept, 17, 1976, saw, unveiling, nasa, space, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995 film clueless starring alicia silverstone...</td>\n",
       "      <td>The 1995 film Clueless starring Alicia Silvers...</td>\n",
       "      <td>Clueless (film) - Wikiquote Clueless (film) Cl...</td>\n",
       "      <td>5764</td>\n",
       "      <td>[1995, film, clueless, starring, alicia, silve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>largest state territory area australia is west...</td>\n",
       "      <td>The largest state or territory by area in Aust...</td>\n",
       "      <td>Australian Cities, States and Territories - To...</td>\n",
       "      <td>8804</td>\n",
       "      <td>[largest, state, territory, area, australia, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was name character played alyson hannigan tv s...</td>\n",
       "      <td>What was the name of the character played by A...</td>\n",
       "      <td>Buffy the Vampire Slayer (TV Series 1997‚Äì2003)...</td>\n",
       "      <td>7774</td>\n",
       "      <td>[was, name, character, played, alyson, hanniga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial stretch water hyde park kensington ...</td>\n",
       "      <td>What artificial stretch of water in Hyde Park ...</td>\n",
       "      <td>Hyde Park (London) |authorSTREAM Hyde Park (Lo...</td>\n",
       "      <td>8842</td>\n",
       "      <td>[artificial, stretch, water, hyde, park, kensi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  sept 17 1976 saw unveiling nasa space shuttle ...   \n",
       "1  1995 film clueless starring alicia silverstone...   \n",
       "2  largest state territory area australia is west...   \n",
       "3  was name character played alyson hannigan tv s...   \n",
       "4  artificial stretch water hyde park kensington ...   \n",
       "\n",
       "                                      original_query  \\\n",
       "0  Sept 17, 1976 saw the unveiling of which NASA ...   \n",
       "1  The 1995 film Clueless starring Alicia Silvers...   \n",
       "2  The largest state or territory by area in Aust...   \n",
       "3  What was the name of the character played by A...   \n",
       "4  What artificial stretch of water in Hyde Park ...   \n",
       "\n",
       "                                     original_answer  answer_id  \\\n",
       "0  BAA - News & Events: Calendar news & events Re...       1200   \n",
       "1  Clueless (film) - Wikiquote Clueless (film) Cl...       5764   \n",
       "2  Australian Cities, States and Territories - To...       8804   \n",
       "3  Buffy the Vampire Slayer (TV Series 1997‚Äì2003)...       7774   \n",
       "4  Hyde Park (London) |authorSTREAM Hyde Park (Lo...       8842   \n",
       "\n",
       "                                        query_tokens  \n",
       "0  [sept, 17, 1976, saw, unveiling, nasa, space, ...  \n",
       "1  [1995, film, clueless, starring, alicia, silve...  \n",
       "2  [largest, state, territory, area, australia, i...  \n",
       "3  [was, name, character, played, alyson, hanniga...  \n",
       "4  [artificial, stretch, water, hyde, park, kensi...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df = pd.DataFrame(dataset['validation'])\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>original_query</th>\n",
       "      <th>original_answer</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>query_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>prepatellar bursitis is more commonly known as</td>\n",
       "      <td>Prepatellar bursitis is more commonly known as...</td>\n",
       "      <td>Prepatellar Bursitis of the Kneecap Limited ra...</td>\n",
       "      <td>7139</td>\n",
       "      <td>[prepatellar, bursitis, is, more, commonly, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>is currency indonesia</td>\n",
       "      <td>What is the currency of Indonesia?</td>\n",
       "      <td>IDR - Indonesian Rupiah rates, news, and tools...</td>\n",
       "      <td>8983</td>\n",
       "      <td>[is, currency, indonesia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>television actor played neville hope auf wiede...</td>\n",
       "      <td>On television which actor played Neville Hope ...</td>\n",
       "      <td>Auf Wiedersehen, Pet ‚Äì where are they now? - B...</td>\n",
       "      <td>7193</td>\n",
       "      <td>[television, actor, played, neville, hope, auf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>tynwald day is celebrated island july</td>\n",
       "      <td>Tynwald Day is celebrated on which island in J...</td>\n",
       "      <td>Tynwald Day - Facts of the Day Calendar Back t...</td>\n",
       "      <td>1920</td>\n",
       "      <td>[tynwald, day, is, celebrated, island, july]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>formula one world champions james hunt nigel m...</td>\n",
       "      <td>Formula One world champions James Hunt, Nigel ...</td>\n",
       "      <td>Nigel Mansell | The Formula 1 Wiki | Fandom po...</td>\n",
       "      <td>9665</td>\n",
       "      <td>[formula, one, world, champions, james, hunt, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "3327     prepatellar bursitis is more commonly known as   \n",
       "1052                              is currency indonesia   \n",
       "180   television actor played neville hope auf wiede...   \n",
       "7872              tynwald day is celebrated island july   \n",
       "1677  formula one world champions james hunt nigel m...   \n",
       "\n",
       "                                         original_query  \\\n",
       "3327  Prepatellar bursitis is more commonly known as...   \n",
       "1052                 What is the currency of Indonesia?   \n",
       "180   On television which actor played Neville Hope ...   \n",
       "7872  Tynwald Day is celebrated on which island in J...   \n",
       "1677  Formula One world champions James Hunt, Nigel ...   \n",
       "\n",
       "                                        original_answer  answer_id  \\\n",
       "3327  Prepatellar Bursitis of the Kneecap Limited ra...       7139   \n",
       "1052  IDR - Indonesian Rupiah rates, news, and tools...       8983   \n",
       "180   Auf Wiedersehen, Pet ‚Äì where are they now? - B...       7193   \n",
       "7872  Tynwald Day - Facts of the Day Calendar Back t...       1920   \n",
       "1677  Nigel Mansell | The Formula 1 Wiki | Fandom po...       9665   \n",
       "\n",
       "                                           query_tokens  \n",
       "3327  [prepatellar, bursitis, is, more, commonly, kn...  \n",
       "1052                          [is, currency, indonesia]  \n",
       "180   [television, actor, played, neville, hope, auf...  \n",
       "7872       [tynwald, day, is, celebrated, island, july]  \n",
       "1677  [formula, one, world, champions, james, hunt, ...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR CODE HERE\n",
    "sampled_queries = queries_df.sample(n=10)\n",
    "\n",
    "sampled_queries.head()\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 : Prepatellar bursitis is more commonly known as what?\n",
      "Answer: pharmlabs february 20 2015 09 24 pm pst 1-butanol n-butanol occurs naturally as minor product fermentation sugars other carbohydrates is present many foods beverages it is also permitted artificial flavorant united states used butter cream fruit rum whiskey ice cream ices candy baked goods cordials it is also used wide range consumer products 1-propanol propanol technically known as 1-propanol is primary alcohol formula ch3ch2ch2oh this colorless liquid is also known as propan-1-ol 1-propyl alcohol n-propyl alcohol n-propanol it is isomer isopropanol 2-propanol isopropyl alcohol it is formed naturally small amounts during many fermentation processes used as solvent pharmaceutical industry mainly resins cellulose esters 2-butanone butanone also known as methyl ethyl ketone mek is organic compound formula ch3c o ch2ch3 this colorless liquid ketone has sharp sweet odor reminiscent butterscotch acetone it is produced industrially large scale also occurs trace amounts nature it is soluble water is commonly used as industrial solvent 2-propanol isopropanol isopropyl alcohol isopropyl alcohol iupac name 2-propanol is chemical compound molecular formula c3h8o c3h7oh ch3chohch3 it is colorless flammablechemical compound strong odor it is simplest example secondary alcohol where alcohol carbon atom is attached two other carbon atoms sometimes shown as ch3 2choh it is structural isomer propanol isopropyl alcohol is denatured certain uses 4-methyl-2-pentanone methyl isobutyl ketone mibk is organic compound formula ch3 2chch2c o ch3 this colourless liquid ketone is widely used as solvent anisole anisole methoxybenzene is organic compound formula ch3oc6h5 it is colorless liquid smell reminiscent anise seed fact many its derivatives are found natural artificial fragrances compound is mainly made synthetically is precursor other synthetic compounds ethanol commonly referred simply as alcohol spirits ethanol Àà…õŒ∏…ôn…íl is also called ethyl alcohol drinking alcohol it is principal type alcohol found alcoholic beverages produced fermentation sugars yeasts it is neurotoxic psychoactive drug one oldest recreational drugs used humans it can cause alcohol intoxication consumed sufficient quantity ethanol is used as solvent antiseptic fuel active fluid modern post-mercury thermometers since it has low freezing point it is volatile flammable colorless liquid strong chemical odor its structural formula ch ethyl acetate ethyl acetate systematically ethyl ethanoate commonly abbreviated etoac ea is organic compound formula ch3-coo-ch2-ch3 this colorless liquid has characteristic sweet smell similar pear drops is used glues nail polish removers decaffeinating tea coffee cigarettes see list additives cigarettes ethyl acetate is ester ethanol acetic acid it is manufactured large scale use as solvent combined annual production 1985 japan north america europe was about 400 000 tons 2004 estimated 1 3m tons were produced worldwide isobutyl acetate chemical compound isobutyl acetate also known as 2-methylpropyl ethanoate iupac name Œ≤-methylpropyl acetate is common solvent it is produced esterification isobutanol acetic acid it is used as solvent lacquer nitrocellulose like many esters it has fruity floral smell low concentrations occurs naturally raspberries pears other plants higher concentrations odor can be unpleasant may cause symptoms central nervous system depression such as nausea dizziness headache isopropylbenzene cumene is common nam\n",
      "Cosine similarity: 0.4769916229907621\n",
      "\n",
      "Answer: list eight main islands hawaii 1 hawaii big island island hawaii also known as big island is largest hawaiis main islands total area 4 028 square miles 10 432 sq km it is also largest island united states it like other islands hawaii was formed hotspot earths crust it is most recently formed hawaiis islands as such it is only one that is still volcanically active big island is home three active volcanoes kilauea is one most active volcanoes world highest point big island is dormant volcano mauna kea 13 796 feet 4 205 m big island as total population 148 677 as 2000 its largest cities are hilo kailua-kona normally called kona more continue reading below our video are seven wonders world 2 maui maui is second largest hawaiis main islands total area 727 square miles 1 883 5 sq km it has population 117 644 people as 2000 its largest town is wailuku mauis nickname is valley isle its topography reflects its name there are lowlands along its coasts several different mountain ranges that are separated valleys highest point maui is haleakala 10 023 feet 3 055 m maui is known its beaches natural environment mauis economy is based mainly agriculture tourism its main agricultural products are coffee macadamia nuts flowers sugar papaya pineapple wailuku is largest city maui other towns include kihei lahaina paia kula hana more 3 oahu oahu is third largest island hawaii total area 597 square miles 1 545 sq km it is called gathering place because it is largest islands population it is center hawaiis government economy oahus population 953 307 people 2010 estimate largest city oahu is honolulu is also capital state hawaii oahu is also home largest u s navy fleet pacific pearl harbor oahus topography consists two main mountain ranges that are separated valley as wella as coastal plains that ring island oahus beaches shops make it one hawaiis most visited islands some oahus top attractions are pearl harbor north shore waikiki more 4 kauai kauai is fourth largest hawaiis main islands it has total area 562 square miles 1 430 sq km it is oldest main islands as it is located farthest away hotspot that formed islands as such its mountains are more highly eroded its highest point is kawaikini 5 243 feet 1 598 m kauais mountain ranges are rugged however island is known its steep cliffs rugged coastline kauai is known as garden isle its undeveloped land forests it is also home waimea canyon na pali coast state parks tourism is main industry kauai it is located 105 miles 170 km northwest oahu kauais population is 65 689 as 2008 more 5 molokai molokai has total area 260 square miles 637 sq km it is located 25 miles 40 km east oahu across kaiwi channel north island lanai most molokai is also part maui county it has population 7 404 people as 2000 molokais topography consists two distinct volcanic ranges they are known as east molokai west molokai highest point island kamakou 4 961 feet 1 512 m is part east molokai these mountains however are extinct volcanoes that have since collapsed their remains give molokai some highest cliffs world addition molokai is known its coral reefs its south shore has worlds longest fringing reef more 6 lanai lanai is sixth largest main hawaiian islands total area 140 square miles 364 sq km only town island is lanai city island has population only\n",
      "Cosine similarity: 0.4572305589525176\n",
      "\n",
      "Answer: anubis anubis stephanie cass anubis who ancient egyptians called ienpw phonetically yinepu is mysterious canid funerary deity ancient egypt even meaning his name is unknown speculations range royal child having derived world putrefy both certainly fit deity who was various points time egyptian history known as lord dead before osiris later became popularly known as son osiris just type animal anubis is represented is unknown as well definitely canid most likely jackal wild dog hybrid both as case seth alterations that deliberately smudge lines reality deep black color anubiss animal is not reflective its actual coat is instead symbolic his position as funerary deity reason anubiss animal being canid is based ancient egyptians themselves observed creature dogs jackals often haunted edges desert especially cemeteries where dead were buried anubis is extremely ancient deity oldest mastabas old kingdom have prayers him carved into their walls he is mentioned pyramid texts his most celebrated role as guardian protector dead standard offering formula dead old kingdom began thusly offering king gives anubis who is upon his mountain place embalming lord necropolis as mentioned previously anubis began position that osiris would later command earliest period egyptian religion anubis was clearly lord dead osiris embalmed god while anubis performed act embalming titles that were invested unto osiris such as khenty-imentiu foremost westerners were originally anubiss as drama osiriss death vindication unfolded over centuries anubis assumed role guide who holds steady scales their hearts are measured against feather maat as he who counts hearts should heart be light as feather soul would then be lead anubis some cases harseisis be presented osiris should heart be heavy it is fed ammit soul destroyed as imy-ut he who is place embalming anubis is embalmer who washes entrails dead guards over their physical bodies as well as places that house them tomb necropolis priests wearing mask anubis were responsible opening mouth ceremony that reawakened dead persons senses reflection royal seal used tombs valley kings depicting pharaohs victory over nine bows enemies egypt anubis is shown recumbent over nine bows meant be hostile forces underworld who he as jackal ruler bows has triumphed over anubiss parentage is mystery one tradition he is son nebt-het nephthys ra yet another coffin text period cow goddess hesat is his mother same source bastet is even accounted as his mother most likely pun ointment jars that comprise her hieroglyphs same jars that were used during embalming process anubis was lord pyramid texts even supply anubis daughter form goddess qeb-hwt cooling water celestial serpent ostrich who purifies quenches monarch anubis is depicted most often as man head black canid alert pointed ears he is also represented full black canid wearing ribbons holding flagellum crook its arm very rarely is he ever shown fully human though there are some cases such as temple ramesses ii abydos this perhaps most famous representation anubis gold-gilded wooden canid found tomb tutankhamen was doubtlessly placed there as protector dead guardian tomb anubis\n",
      "Cosine similarity: 0.4548855033020612\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 2 : What is the currency of Indonesia?\n",
      "Answer: idr indonesian rupiah rates news tools idr indonesian rupiah indonesia rupiah indonesian rupiah is currency indonesia our currency rankings show that most popular indonesia rupiah exchange rate is idr aud rate currency code rupiahs is idr currency symbol is rp below youll find indonesian rupiah rates currency converter you can also subscribe our currency newsletters daily rates analysis read xe currency blog take idr rates go our xe currency apps website\n",
      "Cosine similarity: 0.6825236327899352\n",
      "\n",
      "Answer: bgn bulgarian lev rates news tools bgn bulgarian lev bulgaria lev bulgarian lev is currency bulgaria our currency rankings show that most popular bulgaria lev exchange rate is bgn gbp rate currency code leva is bgn currency symbol is –ª–≤ below youll find bulgarian lev rates currency converter you can also subscribe our currency newsletters daily rates analysis read xe currency blog take bgn rates go our xe currency apps website\n",
      "Cosine similarity: 0.49236596391733095\n",
      "\n",
      "Answer: indonesia map map indonesia rivers indonesia indonesian archipelago has been inhabited up 1 5 million years ago homo erectus 45 000 years ago homo sapiens modern indonesians arrived region taiwan about 2000 bc replacing melaneasians strategic location indonesian islands they became important international trade india this trade brought cultural exchanges as well namely religions hinduism buddhism expanded indonesia 4th century archipelago was ruled srivijaya kingdom beginning around 7th century grew as trade power buddhist hindu communities over 13th century hindu kingdom majapahit stretched across islands muslims arrived 13th century islands had mostly adopted religion 16th century europeans arrived portuguese 1512 search spices indonesia dutch east india company became major power region about 1602 1800 dutch colonized parts indonesia expanding cover modern-day boundaries it held until world war ii japanese occupied country japan surrendered 1945 indonesia declared independence though dutch attempted regain control after achieving independence indonesia became ruled communist party democratic processes were later strengthened indonesia held its first elections 2004 neighboring countries though it is island nation indonesia shares land borders papua new guinea east timor malaysia is close singapore philippines australia palau major cities jayapura geography indonesia is archipelago located southeast asia oceania straddling equator indonesia is made up 17 508 islands islets 6 000 inhabited islands largest include java sumatra borneo new guinea sulawesi island borneo is also shared neighboring nations brunei malaysia while new guinea is also home country papua new guinea island timor was once completely included within indonesias territory east timor seceded country indonesia has equatorial tropical climate 150 active volcanoes including krakatoa tambora toba as region volcanic activity indonesia has mountain ranges its highest peak papua puncak jaya standing 4 884 meters 16 024 feet above sea level major rivers indonesia include mahakam barito rivers countrys largest lake is lake toba sumatra points interest indonesia is known its culture influenced hinduism buddhism islam chinese dutch cultures reflecting its varied historical influences markets indonesia are great place explore indonesian culture handicrafts local foods capital jakarta is bustling crowded city architectural wonders like its old town national monument monas government buildings like presidential palace several major theme parks including countrys largest jungleland sentul city jakarta has cultural sites like museums mosques churches open air markets natural sites indonesia include second largest tropical forests world including those sumatra borneo papua rainforests borneo are 130 million years old are some oldest world beaches bali are most popular destination indonesia water recreation like surfing historical architectural sites transportation indonesia has three major airports jakartas soekarno-hatta ngurah rai east javas juanda these international airports offer service major cities all around world domestic flights are best way get around indonesia as they are fast inexpensive getting across islands quickly under 100 as island nation boat is important way getting around can be used travel singapore mal\n",
      "Cosine similarity: 0.4754623596271882\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 3 : On television which actor played Neville Hope in 'Auf Wiedersehen Pet' and Robbie Lewis in 'Morse'?\n",
      "Answer: inspector morse lewis endeavor episode guide documents documents share inspector morse lewis endeavor episode guide embed iframe srchttp docslide usembedinspector-morse-lewis-endeavor-episode-guide html width750 height600 frameborder0 marginwidth0 marginheight0 scrollingno styleborder 1px solid ccc border-width 1px margin-bottom 5px max-width 100 allowfullscreen iframe div stylemargin-bottom 5px strong hrefhttp docslide usdocumentsinspector-morse-lewis-endeavor-episode-guide html titleinspector morse lewis endeavor episode guide target_blankinspector morse lewis endeavor episode guideadiv size px inspector morse lewis endeavor episode guide rkish-2 inspector morse lewis endeavor episode guide download inspector morse lewis endeavor episode guide transcript pdf generated using open source mwlib toolkit see http code pediapress com more information pdf generated sun 17 jun 2012 13 49 59 utc inspector morse inspector lewis endeavor episode guide contents articles inspector morse 1 inspector morse tv series 5 list inspector morse episodes 9 inspector lewis 13 lewis tv series 15 list lewis episodes 19 endeavour tv series 24 references article sources contributors 28 article licenses license 29 inspector morse 1 inspector morse inspector morse created colin dexter written russell lewis composer s barrington pheloung inspector morse is fictional character eponymous series detective novels british author colin dexter as well as 33-episode 19872000 television adaptation same name character was portrayed john thaw morse is senior cid criminal investigation department officer thames valley police oxford england jaguar car originally lancia novels thirst english real ale penchant music especially opera wagner poetry art classics classic cars cryptic crossword puzzles morse presents likeable persona despite his sullen temperament name family morses first name endeavour was kept secret until end death is now my neighbour traditionally morse claimed that he should be called morse joked that his first name was inspector series it is noted that his reticence about his christian name led public school stamford school where colin dexter his brother were both pupils nickname pagan origin his name is vessel hms endeavour as morses mother was quaker quakers have tradition virtue names his father was fan captain james cook morses father was trade taxi driver 1 morse likes explain origin his additional private income saying that he used drive aga khan 2 author morse novels colin dexter is fan cryptic crosswords morse is named after champion setter jeremy morse one dexters arch-rivals as clue-writer crossword world 3 dexter used walk along bank river thames oxford opposite boathouse belonging 22nd oxford sea scout group building is named t s endeavour during episode cherubim seraphim it is learned that morses parents divorced he was 12 he remained his mother until her death three years later he had return his father he had dreadful relationship his stepmother gwen 4 claimed he only read poetry annoy her that her petty bullying almost drove him suicide he has half-sister joyce whom he is better terms was devastated joyces daughter marilyn took her own life habits personality morse is ostensibly embodiment white male upper-middle-class englishness set prejudices assumptions match he may thus be considered late example gentleman detective staple british detective fiction this background is sharp juxtaposition working class origins his assistant lewis named after\n",
      "Cosine similarity: 0.25492449597844646\n",
      "\n",
      "Answer: auf wiedersehen pet where are they now bt auf wiedersehen pet where are they now lewis star kevin whately shot fame as brickie neville 80s comedy drama auf wiedersehen pet happened other members magnificent seven print this story kevin whately reprises his most famous role this week as he returns our screens as inspector morses former partner final series lewis before he had his hands full unfeasibly high oxford murder rate whately came our attention as part stellar ensemble auf wiedersehen pet hit comedy drama following exploits builders who leave britain search work overseas show spanned four series 1983 2004 as construction crew travelled world search work whately was core series as neville hope neville was always most anxious member gang travelling germany against his better judgement always homesick family he left behind newcastle somewhat improbably he had got himself mixed up some sort espionage end shows run where are other members magnificent seven lets take look oz oz known his mum newcastles law enforcement community as leonard osbourne was played jimmy nail jimmy known his mum as james bradford earned his colourful soubriquet working building site he had next no acting experience before auf wiedersehen went star couple major tv shows including gritty detective series spender country western-themed comedy drama crocodile shoes related old coppers never retire latter connected nails acting his first love music yielded top 10 album 1994 year later scrubbed-up nail was sharing big screen madonna alan parkers evita while most recently he has worked another geordie sting musical project themed around newcastles shipbuilding industry moxey reformed arsonist electrician moxey was always outsider group actor christopher fairbank seems contrast quite gregarious soul reuniting during his long successful career nail crocodile shoes whately morse hes also had successful run character roles films most recently box office smash space adventure guardians galaxy wayne wayne winston norris his ebony cockade hair eye ladies was type fellow once known as jack lad cockney carpenter wasnt it seems so different actor who played him gary holton former leader proto-punk ban heavy metal kids was notorious hellraiser who lived life full onscreen off 1985 he was offered part nick cotton new television series called eastenders turned it down recommending instead his friend john altman holton died drugs overdose late 1985 while second series auf wiedersehen pet was still being filmed his absence is glossed over use hasty script changes hazily-seen body doubles dennis tim healy played dennis teams de facto leader moral conscience although he had fallen into shady company auf wiedersehens third series after show finished tim was rarely out work list credits as varied as benidorm phoenix nights citv series tickle tum his marriage denise welch was stuff gossip magazine speculation while they divorced 2012 they have son matthew who is currently charts teen sensations 1975 barry because it was first time many us had seen distinguished london-born character actor tim spall lot auf wiedersehen viewers assumed that he really was brummie although he had performed while birmingham rep spall was fact battersea born bred after coming public attention as dull pseudointellectual strangely likeable electrician barry taylor spall went enjoy stellar career tv film most recently\n",
      "Cosine similarity: 0.22835481765616664\n",
      "\n",
      "Answer: lewis set final case as kevin whately laurence fox bow out television radio guardian lewis set final case as kevin whately laurence fox bow out itv confirms long-running morse spin-off will end two-part episode concluding next week laurence fox as james hathaway kevin whately as robert lewis pair have played roles almost 10 years photograph itv press association monday 2 november 2015 12 51 est last modified monday 2 november 2015 13 05 est close this article is 1 year old lewis stars kevin whately laurence fox are bow out popular crime drama after nearly 10 years itv confirmed lewis would end two-part episode called lies tangled first part will be broadcast tuesday it will conclude next tuesday whately said i feel incredibly fortunate have shared decade fantastic worldwide success laurence most brilliant crew cast production team anyone could wish all that time loyal support so many fans our backers itv wgbh boston thanks everybody ride it has been northumberland-born actor first played role lewis 1987 opposite late john thaw itv drama inspector morse its spin-off lewis premiered 2006 fox member famous acting dynasty that includes his father james uncle edward cousins emilia freddie as james hathaway whos best new tv cop rivers nicola walker unforgottens nicola walker read more set five years after death his long-term partner morse lewis found himself teamed up much younger partner reporting new boss form ch supt jean innocent rebecca front fox said extraordinary 10 years i feel so lucky have worked absolutely best crew business lewis i will really miss hanging out kev half year i am however fairly confident that he will not miss my flawless geordie accent between takes thank you so much watching supporting us lies tangled written nick hicks-beach directed david drury opens idyllic oxford summer day being blighted parcel bomb lewis is race against time not only find killer also save his career his relationship final episode also includes series regular angela griffin as ds lizzie maddox executive producer michele buck said have produced same amount films as morse is honour i will miss lewis itvs director drama steve november said it is great sadness that we say goodbye robbie lewis one itvs most loved enduring characters we owe kevin huge debt gratitude nearly 30 fantastic years morse lewis course many thanks too laurence fox who has been kevins side last 10 years we respect their decision not continue into further series wish them very best whatever comes next\n",
      "Cosine similarity: 0.22553355540891162\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 4 : Tynwald Day is celebrated on which island in July?\n",
      "Answer: seychelles islands mah√© praslin la digue silhouette indian ocean seychelles islands seychelles islands mah√© mah√© is main island seychelles archipelago 115 islands even if each island islets come their very own characteristics uniqueness mah√© stands as most complete island seychelles mah√© is seychelles largest island hosting main business administrative center capital city victoria mah√© is home majority seychelles multiethnic population is estimated be around 90 000 persons its international airport mah√© is gateway seychelles archipelago if you are coming seychelles you definitely have visit mah√© its historical city victoria island is connecting point all other smaller surrounding islands being largest island mah√© has wide range beaches enjoy just island mah√© comprises more than fifty breathtaking beaches popular pristine beaches mah√© can give full satisfaction traveler unique holidays mahe island praslin island praslin lies 44km northeast mah√© island is second largest island seychelles terms area 38km¬≤ population island has estimated population around 6 500 people praslin is relatively small island it takes approximately two hours make leisure car trip around island despite being small praslin has inherited luxurious nature spectacular beaches praslin is also home world known mai valley rich nature park naturally grows rarest endemic species seychelles site was designated as world heritage site unesco is main attraction seychelles like mah√© praslin has got some stunning beaches places natural beauty anse lazio is one many beaches island beach is located northwest praslin is considered be best beach praslin one top seychelles praslin la digue lying between east praslin west felicite island la digue is measured many be best beach earth fact according cnn two la digues beaches grand anse anse source dargent were top five worlds most beautiful beaches terms size this is fourth largest island seychelles after mah√© praslin silhouette island area 10km¬≤ island is rather small making it easy walk travel around bicycle there are no cars island some traditional oxcarts will get you through instead island la digue has one worlds prettiest population approximately 2 000 inhabitants there is no airport la digue most its population live west coast villages la passe links mah√© praslin other islands ferry everyone seychelles will tell you that no visit seychelles is complete without visiting la digue its splendid granitic rock elevation heavenly beaches island has its own lodge hotel welcome its visitors anse source dargent la digue north island north island seychelles is true barefoot paradise this small granitic island lies 5 km north silhouette along mah√© praslin north island forms part inner islands seychelles particularity north island is that it has been developed as private resort just 11 villas its guests island is 2km¬≤ large has four wonderful beaches east beach west beach honeymoon cove dive beach symbolic seychelles archipelago island is small piece heaven indian ocean it has been very well preserved drives more towards eco-tourism market island came popular after royal visit duke duchess cambridge who selected site their honeymoon fregate island fregate island sometimes referred as frigate island is small island located east mah√© fregate also forms part inner granitic islands seychelles bu\n",
      "Cosine similarity: 0.45902112054355226\n",
      "\n",
      "Answer: christmas island environment heritage home territories australia christmas island christmas island environment heritage christmas island environment heritage heritage geography climate island is summit submarine mountain it rises steeply central plateau dominated rainforest plateau reaches heights up 360 metres consists mainly limestone layers volcanic rock islands 80 kilometre coastline is almost continuous sea cliff reaching heights up 20 metres there are thirteen places where breaks cliff give way shallow bays small sand coral beaches largest these bays forms islands port flying fish cove island is surrounded coral reef there is virtually no coastal shelf sea plummets depth about 5000 metres within 200 metres shore climate is tropical temperatures range 21 c 32 c humidity is around 8090 per cent south-east trade winds provide pleasant weather most year however during wet season between november april it is common some storm activity occur producing swell seas around island average rainfall is approximately 2000 mm per annum population christmas island has resident population approximately 2072 ethnic composition approximately 60 per cent chinese 25 per cent malay 15 per cent european history christmas island was named christmas day 1643 captain william mynors master passing ship first landing was recorded william dampier 1688 next two centuries little interest was shown island due its rugged coastline following discovery phosphate deposits island was annexed britain 1888 island was occupied japanese forces march 1942 until end second world war 1946 became dependency singapore agreement united kingdom sovereignty was transferred commonwealth australia 1 october 1958 under christmas island act 1958 this day is still celebrated as territory day flora fauna see photos christmas island please see christmas island photo gallery page includes photos flora fauna islands close proximity south-east asia equator has resulted diverse range flora fauna there are 411 recorded plant species christmas island approximately 18 these are native distribution plants island is related soil depth moisture retention as well as exposure distance sea dense rainforest has evolved deep soils plateau some terraces forests are dominated several tree species ferns orchids vines flourish branches humid atmosphere beneath canopy land crabs sea birds are most noticeable animals island date 20 terrestrial intertidal crabs have been described diversity abundance land crabs is not matched any other island huge robber crabs known elsewhere as coconut crabs are also found christmas island are capable opening devouring coconuts their strong claws red crabs are dotted around forest floor all over christmas island annual red crab mass migration sea spawn has been described ecologists as one wonders natural world this migration takes place each year after start wet season synchronised cycle moon island is also focal point sea birds various species eight species subspecies sea birds nest island most numerous is red-footed booby nests colonies trees many parts shore terrace widespread brown booby nests ground near edge sea cliff inland cliffs abbotts booby listed as endangered nests tall emergent trees western northern southern plateau rainforest christmas island forest is only known nestin\n",
      "Cosine similarity: 0.4388352985050015\n",
      "\n",
      "Answer: tristan da cunha travel guide wikitravel understand edit tristan da cunha is most remote inhabited island world nearest speck land st helena is whopping 2430km away its over 2800km nearest continent africa entire population some 300 inhabitants is concentrated only flat bit this volcanic landmass hamlet edinburgh seven seas main island there are few other islands archipelago all uninhabited inaccessible island nightingale island middle island stoltenhoff island gough island some 300km away hosts weather scientific research outpost get edit no visas are required however visitors intending stay ashore tristan da cunha must receive permission administratorisland council have landing stamp that effect inserted their passport write email admin secretary enquiriestdc1gmail com specify you plan go where you intend stay purpose your visit landing stamps may also be issued passengers crew vessels not intending go ashore who wish their travel document be endorsed as souvenir visit foot edit due rugged steep terrain going all way around island is difficult if just staying settlement tristan flat grassy ground is easy manage transport edit there is paved road m1 edinburgh aka settlement potato patches are about 3 miles away local transport is available potato patches this local transport could be islanders car tractor during mornings bus service also operates note that bus is targeted pensioners who can ride bus free charge is 5 return note that you cannot rent any vehicles island do edit add listing island organises fishing excursions walks climbs even golf visitors take trip inaccessible island main tristan da cunha island despite name it is possible visit island only visitors escorted guides tristan da cunha are permitted visit island most visitors come as part cruise ship itinerary there are no permanent settlements island you should bring your own food drinks along relatively nearby gough island inaccessible island was made world heritage site unesco 1995 gough island edit take trip gough island gough island was first known as diego alvarez it was sighted again 1721 captain gough his ship richmond this brought new name bit more attention place although gough island is uk territory only permanent settlement you will find there is south african south africa leases portion island uk use sanap as only permanently manned south atlantic ocean meteorological station island is unesco world heritage site gough island has no sheltered harbour anchorage only suitable landing place boats is glen anchorage quest bay islands east coast sa agulhas relief expedition departs cape town tristan da cunha then onwards gough island annual relief voyage this ship carries cargo passengers there is presently no access tourists even crew members passing yachts may not go ashore except case extreme emergency getting around comes great difficulty combination excessively steep terrain incredibly dense vegetation no paths speak there are no public accommodations gough island as well eat drink edit visit cafe da cunha hot cold drinks sandwiches hot meals located post office tourism centre albatross bar islands only pub is open evening monday saturday few hours sunday afternoon range food drink items are also available purchase island store has sufficient stocks all visitors home stays edit pr\n",
      "Cosine similarity: 0.43392304122119124\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 5 : Formula One world champions James Hunt, Nigel Mansell, Damon Hill, Lewis Hamilton and Jenson Button are all from which country?\n",
      "Answer: lewis hamilton lewis hamilton next previous enlarge 1 8 race 2 winner lewis hamilton gbr asm formule 3 dallara f305 mercedes formula three euroseries rd10 motopark oschersleben germany 26 june 2005 lewis hamilton gbr art grand prix celebrates his second position parc ferme gp2 series rd 10 race 2 istanbul park turkey 27 august 2006 lewis hamilton gbr teammbm com cik-fia world karting championship formula super rd5 kerpen germany 26-28 october 2001 lewis hamilton gbr mclaren parc ferme formula one world championship rd15 japanese grand prix race day fuji speedway fuji japan sunday 30 september 2007 lewis hamilton gbr mclaren celebrates his world championship parc ferme formula one world championship rd 18 brazilian grand prix race interlagos sao paulo brazil sunday 2 november 2008 lewis hamilton gbr karting feature 1996 race winner lewis hamilton gbr mclaren mercedes mp423 takes chequered flag formula one world championship rd 9 british grand prix race silverstone england sunday 6 july 2008 race winner lewis hamilton gbr mercedes amg f1 w05 celebrates formula one world championship rd9 british grand prix race day silverstone england sunday 6 july 2014 best image info close few drivers have entered formula one racing as big bang as lewis hamilton whose sensational maiden season 2007 he lost out world championship single point remains one most remarkable rookie campaigns history intervening period supremely gifted british driver has won three world championships established himself as one most complete drivers grid terrific qualifier tenacious racer fierce wheel-to-wheel combatant deadly eye overtake put simply it comes driving formula one car there are very few areas hamilton does not excel hamilton attributes much his success his humble upbringing stevenage english town he began racing as hobby winning came naturally young driver soon he was cutting his teeth national events age 10 little less than two years experience he was crowned youngest-ever winner british cadet kart championship equipped assured racing style that belied his years it wasnt long before hamiltons trophy cabinet was groaning under weight more karting titles hamilton made sure that ron dennis was one first notice his swift rise through ranks 1998 mclaren boss signed him teams young driver programme indeed denniss belief hamiltons talents was such that contract even included option 13 year-old should he ever make it into formula one racing this stage however it was mclarens financial support that proved bigger blessing hamilton who up that point had been supported his dutiful father future manager anthony who worked several jobs keep his son racing once able compete much larger stage hamilton jnr won multitude european karting titles ease age 15 he was grabbing further headlines this time being crowned sports youngest number one record he still retains\n",
      "Cosine similarity: 0.36881235711450294\n",
      "\n",
      "Answer: world champions formula one art genius formula one art genius search world champions only 33 men have won formula one world championship 67 seasons since modern era began 1950 while ten schumacher fangio prost brabham stewart lauda piquet senna vettel hamilton have topped season leader board three more times making f1 driving crown most elusive title world statistics though 2016 season\n",
      "Cosine similarity: 0.35186577527449836\n",
      "\n",
      "Answer: formula 1 nigel mansell damon hill ayrton senna etc ebay formula 1 10 january 2009 formula 1 this is one many illustrated classic f1 racing guides ive created community i hope you enjoy it if you wish find out more about classic f1 racing art featured this guide please click here this guide features several legendary f1 drivers satoru nakajima satoru nakajima was hondas representative grid late eighties was japans first regular formula one grand prix driver ayrton sennas team-mate lotus 1987 then teamed nelson piquet 1988 1989 lotus satoru was worthy ambassador honda company without posing threat his more highly regarded team-mates his best finish was fourth adelaide 1989 his last two seasons were spent tyrrell team before he quit end 1991 his best finish championship was eleventh position overall 1987 driving lotus total grand prix drives 74 since his retirement formula one he has run team both japanese formula 3000 formula three developing next generation japanese racing drivers andrea de cesaris world champion karts strong contender british formula three andrea made his formula one debut alfa-romeo 1980 he soon became known his somewhat unpredictable driving style racing mclaren 1981 1982 1983 were spent alfa-romeo where he produced third place monaco race he could have won before moving ligier 1984 two seasons ligier produced little so it was minardi then brabham then rial then dallara then tyrrell jordan again finally sauber before his formula one career ended 1994 second most experienced formula one driver behind riccardo patrese although without win best race result second place german grand prix 1983 finished eighth title overall 1983 total grand prix drives 208 nigel mansell nigels formula one debut was lotus 1980 his first grand prix victory was williams 1985 1986 saw five grand prix victories yet through cruel luck no title accident qualifying ruined his title hopes again 1987 after six wins it was beginning look as if nigel mansell was be nearly man formula 1 bold move ferrari 1989 he won his first race instant adoration italian fans only finished fourth 1990 ferrari was disaster finishing ninth overall so it was back williams winning ways 1991 five wins however were not enough nigel still having play second fiddle ayrton sennas mclaren finally 1992 it all came right mansell storming nine victories williams-renault that was class its own he still drove magnificently after moving indy cars 1993 incredibly taking title his first attempt mansell returned williams mid-season 1994 before joining mclaren 1995 he retired after just two races damon hill as relatively late starter car racing 1984 formula ford damon soon progressed into british formula three then formula 3000 before gaining his first f1 drive 1992 signed williams 1993 drive alongside three-time world champion alain prost he gained three victories finished third overall staying williams 1994 this time ayrton senna as team-mate damon was thrust into role team leader after brazillians death season burdened michael schumachers disqualifications closed huge points gap set up grand finale australian grand prix sadly hill schumachers now famous chopping move just before mid-distance took out both himself hill leaving schumacher as champion just one point there were only four wins damon 1995 enough give him second place championship again johnny herbert johnny herberts talent was recognised he won-from-the-back during 1985 formula ford festival 1987 he took british formul\n",
      "Cosine similarity: 0.2402843355478433\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 6 : \"What does the French phrase \"\"de rigueur\"\" literally mean?\"\n",
      "Answer: de rigueur definition de rigueur merriam-webster definition de rigueur prescribed required fashion etiquette custom proper tattoos course being de rigueur among poetry set will ferguson examples de rigueur sentence dark sunglasses are de rigueur these days though he was wearing dinner jacket black bow tie his jeans tennis shoes were hardly de rigueur de rigueur pronounce it spell it use it sentence if you want use de rigueur conversation pronouncing it correctly is de rigueur click here find out spelling this fancy french borrowing correctly other hand isnt de rigueur your spellcheck will do it you most cases it is possible vowels its final syllable are trickiest it may help remember other french borrowings that end eur such as amateur chauffeur entrepreneur course last four letters liqueur match de rigueur perfectly de rigueur has been used as adjective english almost two centuries now means that its established enough appear running text without italics its foreign-sounding enough though that people can feel tentative about using it apply it where synonyms like proper correct decorous are home here are some examples it use its adopted language anglophone parents worry that being too strict will break their kids creative spirits visiting american mother was shocked she saw playpen our apartment paris apparently back home even playpens are now seen as too confining we didnt know paris theyre de rigueur pamela druckerman bringing up b√©b√© 2012 being business writing about cocktails bars i often find myself some pretty swank digsvarious mixology dens where elaborate drinks require complex techniques house-made bitters farm-to-table infusions are de rigueur bartender has achieved celebrity-chef star status jason rowan wine enthusiast april 2014 although de rigueur is usually found after verb especially after is are its also sometimes used traditional adjectival territory before noun stone who patiently smiled through de rigueur photo shoot front backdrop emblazoned logos festival its sponsors paul liberatore marin independent journal marinij com 6 oct 2016 did you know if youre invited ball other social function invitation includes french phrase costume de rigueur you are expected adhere very strict dress code-typically white tie tails if youre man floor-length evening gown if youre woman french de rigueur means out strictness according strict etiquette one definition our word rigor rigueur is related is quality being strict unyielding inflexible english we tend use de rigueur describe fashion custom that is so commonplace within context that it seems prescribed mandatory part it origin etymology de rigueur french\n",
      "Cosine similarity: 0.3145494684118476\n",
      "\n",
      "Answer: cad does cad stand free dictionary cad does cad stand free dictionary http acronyms thefreedictionary comcad cest dire french that is say cad ctrl alt del gaming webcomic cad canadian association deaf cad carol ann duffy british poet cad communaut√© dagglom√©ration drac√©noise french agglomeration community drac√©noise draguignan france cad communaut√© dagglom√©ration du douaisis french urban community douai douai france cad collisionally activated dissociation mass spectrometry cad california association deaf cad connecticut association deaf cad collective address designator us dod cad colorado association deaf cad crown assets distribution public works government services canada cad comit√© de laide au d√©veloppement french development assistance committee cad coalition des alternatives africaines dettes et d√©veloppement french african debt development alternatives coalition mali cad comportementalistes daujourdhui et de demain french behaviorists today tomorrow behavioral specialists association cad communaut√© dagglom√©ration dijonnaise french agglomeration community dijon dijon france cad centre darchives et de documentation french centre documentation archives cad characterization assessment division epa cad club alpine dieppe french automobile club dieppe france cad capability analysis document us dod cad cultural affairs department various locations cad coordination development committee various organizations want thank tfd its existence tell friend about us add link this page visit webmasters page free fun content link this page write you mean clearly correctly references periodicals archive 1 after creating importing 3-d part model users create cores cavities around that model using either automated routines generic cad operations some combination two arrive parting surfaces blow molds grow sophistication we considered several possibilities updating our current system evaluating variety other cad solutions cadcam wises up nineties leading developer 3d cad translation software announced today that it will partner autodesk leading software services company provide shared customers ability publish 3d-translated cad drawings into dwf format through autodesk dwf partner program copyright 2003-2017 farlex inc disclaimer all content this website including dictionary thesaurus literature geography other reference data is informational purposes only this information should not be considered complete up date is not intended be used place visit consultation advice legal medical any other professional\n",
      "Cosine similarity: 0.2763598115094076\n",
      "\n",
      "Answer: french defeated dien bien phu may 07 1954 history com french defeated dien bien phu share this french defeated dien bien phu author french defeated dien bien phu url publisher ae networks northwest vietnam ho chi minhs viet minh forces decisively defeat french dien bien phu french stronghold besieged vietnamese communists 57 days viet minh victory dien bien phu signaled end french colonial influence indochina cleared way division vietnam along 17th parallel conference geneva september 2 1945 hours after japanese signed their unconditional surrender world war ii communist leader ho chi minh proclaimed independent democratic republic vietnam hoping prevent french reclaiming their former colonial possession 1946 he hesitantly accepted french proposal that allowed vietnam exist as autonomous state within french union fighting broke out french tried reestablish colonial rule beginning 1949 viet minh fought increasingly effective guerrilla war against france military economic assistance newly communist china france received military aid united states november 1953 french weary jungle warfare occupied dien bien phu small mountain outpost vietnamese border near laos although vietnamese rapidly cut off all roads fort french were confident that they could be supplied air fort was also out open french believed that their superior artillery would keep position safe 1954 viet minh army under general vo nguyen giap moved against dien bien phu march encircled it 40 000 communist troops heavy artillery first viet minh assault against 13 000 entrenched french troops came march 12 despite massive air support french held only two square miles late april may 7 after 57 days siege french positions collapsed although defeat brought end french colonial efforts indochina united states soon stepped up fill vacuum increasing military aid south vietnam sending first u s military advisers country 1959 related videos\n",
      "Cosine similarity: 0.2701351013344489\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 7 : South Korea's national dish 'kimchi' (kimchee/gimchi), with variants in nearby countries, is seasoned aged pickled/fermented?\n",
      "Answer: south america map map south america south america industrial centers about south america south america is worlds fourth largest continent earth fifth most populous history that spans over thousand years south america has been culturally influenced spanish portuguese asian african cultures europeans explored south america beginning late fifteenth century continent was named after italian explorer amerigo vespucci who is believed have recognized it as separate continent located primarily southern hemisphere few countries northern hemisphere south america is comprised twelve independent countries three territories geography south america is bound caribbean sea north north atlantic ocean east northeast south atlantic ocean southeast south pacific ocean borders continent west northwest isthmus panama joins south america north america south america is also home stunning variety landscapes desert rainforest plains hills historic overview south america has long history dating back human migration across bering land bridge about 1200 bc hunters traveled asia alaska crossing bering strait drifted gradually south 1400 1550 indigenous people inca empire spread across south america regions modern-day bolivia chile ecuador northern argentina peru 1492 christopher columbus discovered new world number spanish explorers increased between 1496 1526 1533 spanish army led francisco pizarro had captured much inca territory period between 1535 1537 argentina peru bolivia were founded eighteenth century spanish colonies south america started make serious bid independence while fighting wars against france european mainland spain began lose control its south american colonies end war 1814 countries like argentina venezuela gained their independence spain other nations followed suit twentieth century several south american countries including peru venezuela had held elections first time after their independence economy manufacturing industries agriculture trade primarily support economy south america economies many south american countries are based export goods primarily export agricultural products brazil argentina lead export goods other nations some major agricultural products include sugarcane corn wheat soybean coffee south americas mineral resources also contribute substantially economy some major mineral resources found south america are petroleum gold iron ore silver copper south american countries have shown remarkable economic development past two decades countries like brazil argentina columbia peru chile uruguay have had maximum growth even during global recession 2008 2009 south american countries have shown resilience as compared other nations around world major challenge that south americas economy faces is high levels inequality between rich poor many countries gap between rich poor south america is highest world response many south american countries are trying come together help two trade blocs mercosur includes countries like brazil argentina uruguay venezuela paraguay andean community nations includes countries such as ecuador bolivia peru columbia venezuela chile these trade blocs help countries strengthen their economic ties improve their economies travel tourism tourism is another important industry south america that not only enhances gdp each country also ensures greater job opportunities historical si\n",
      "Cosine similarity: 0.3392658089675974\n",
      "\n",
      "Answer: australian cities states territories tourism australia add share mainland australia is worlds largest island also smallest continent country is divided into six states two territories are australias cities states territories mainland australia is worlds largest island also smallest continent country is divided into six states two territories australian capital territory australian capital territory act bounds national capital canberra is centre government australian capital territory is located approximately 290 kilometres 180 miles south sydney is home number important national institutions including parliament house australian war memorial national gallery australia new south wales new south wales nsw is australias oldest most populous state new south wales was originally settled as penal colony shores port jackson where bustling capital city sydney now stands sydney is nations largest city is renowned its idyllic beaches great walks world-class dining new south wales is also home popular attractions including blue mountains hunter valley wine region northern territory top end australia lies northern territory nt darwin northern coast is capital alice springs is principal inland town alice springs is physical heart australia almost exactly nations geographical centre northern territory is home famous uluru ayers rock kata tjuta olgas kakadu national park queensland queensland qld is australias second-largest state size is home world famous great barrier reef worlds most extensive subtropical rainforest beautiful queensland islands including world heritage-listed fraser island brisbane is states capital it enjoys more winter sunshine warmth than most australian cities is perfect outdoor activities water sports south australia south australia sa sits southern central part country covers some most arid parts continent states capital is adelaide is great base exploring barossa wineries flinders ranges kangaroo island south australia has thriving arts scene is known as festival state more than 500 events festivals taking place there each year tasmania tasmania tas is separated mainland australia bass strait is smallest state australia capital hobart was founded 1804 as penal colony is australias second oldest capital city after sydney one-fifth tasmania is covered national parks wilderness abundant driving routes walking trails it is one worlds most mountainous islands victoria victoria vic is smallest mainland states size is home countrys second most populated city melbourne often referred as nations cultural capital melbourne is famed its graffiti laneways fashion-forward boutiques booming caf√© scene victorians enthusiasm sport is also legendary this is where australian rules football began only thing more sacred than footy is melbournians love coffee here youll find some australias best flat whites cappuccinos piccolo lattes western australia western australia wa is australias largest state is place true contrasts desert east 13 000 kilometres pristine coastline west states capital is perth fourth most populous city australia famed its uncrowded beaches parklands fresh seafood off coast esperance states south is middle island is home extraordinary pink-coloured lake hillier australia also administers ashmore cartier islands christmas island cocos keeling islands coral s\n",
      "Cosine similarity: 0.30683940070873894\n",
      "\n",
      "Answer: national symbols bhutan flag emblem animal bird flower tree little bhutan little bhutan you are here home bhutan national symbols national symbols bhutan flag national flag bhutans national flag is divided diagonally upper diagonal is yellow lower orange separating two diagonals is white dragon facing away hoist side yellow signifies secular tradition authority king orange buddhist spiritual tradition dragon represents name kingdom druk yul land thunder dragon dragon signifies purity jewels held dragons claws represent bhutans wealth security dragons snarling mouth symbolizes bhutanese guardian deities ferocious commitment protect nation national emblem national emblem it is circle inside are two crossed vajras placed over lotus circled dragon each side wish-fulfilling jewel is located above them there are four jewels inside circle where two vajras intersect they symbolize spiritual secular traditions country based spiritual undertakings vajrayana buddhism lotus represents purity wish-fulfilling jewel is sovereign power people two dragons name kingdom national anthem druk tsendhen is national anthem it was first composed 1953 became official 1966 takin national animal takin burdorcas taxicolor is extremely rare mammal it herds steep thick woods altitude around 4 000 meters legend has it that 15th century tibetan saint drukpa kunley popularly known as divine madman created this unique animal its features resemble quaint blend between cow goat national bird raven corvus corax tibetanus represents one most powerful deities country jarog dongchen it is believed that deity took form raven guide unify country it looks quite similar crow raven is much larger national butterfly ludlows bhutan swallowtail rare endangered butterfly was declared as national butterfly 2011 it was rediscovered country 2009 after 75 years blue poppy national flower blue poppy meconopsis grandis is rare flower grows only high altitudes it is mostly found altitude 3 500 4 000 meters after enduring harsh winter weather it blooms its full beauty spring locals call it euitgel metog hoem national tree cypress cupressus torolusa is locally known as tsenden cypress grows between altitude 1 800 3 500 meters it is evergreen tree that grows up height 45 meters its ability survive rugged terrain represents bravery simplicity bhutanese traditional dress gho national dress zhabdrung ngawang namgyel introduced gho kira 17th century bhutanese women wear ankle length rectangular piece dress called kira is held place over shoulder pair komas broaches hooks hand woven belt known as kyera waist under kira women wear wonju blouse toego open jacket is worn over dress bhutanese woman men wear gho long robe it is worn till knee tied waist small hand woven kyera belt above large pouch is formed wearing long socks shoes completes costume all bhutanese are required wear kira gho offices administrative centers all officialformal occasions men are required wear kabney scarf women rachu scarf their dress color kabney designates rank person bhutanese archery national game archery is national game bhutan bow arrow plays significant role many bhutanese myths legends it was declared national sport 1971 bhutan became member united nations game is played during tournaments leisure it\n",
      "Cosine similarity: 0.29582830214471934\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 8 : Who played Professor Fate‚Äôs assistant, Max, in the Great Escape?\n",
      "Answer: list old english occupations descriptions assay master determined amount gold silver go coins assayer determined proportions metal ore attorney lawyer auctioneer dealer person who sells goods auction is usually paid commission sale auger maker someone who made carpenters augers used boring holes wood aurifaber goldsmith axeman axman one who wields axe woodsman axle axel tree maker axle axel tree turner made axles coaches wagons back washer employed clean wool worsted manufacturing industry backmann backster baxter beck becker baker backus boy kitchen servant back house badger licenced huckster peddler pedlar hawker corn miller dealer itinerant food trader travelling provisions dealer licensed pauper who wore badge letter p it could only work defined area term badgering comes this petty jobber trickster bagman travelling salesman bagniokeeper charge bath house brothel bailiff bailie baillie baillee officer sheriff land steward acting behalf landowner landlord scotland magistrate burgh also looked after fishing rights certain rivers bairman bareman pauper beggar bal maiden pit brow lass female mine worker who worked surface balancer person usually boy who operated balance pulley where full tubs were pulled up slope mine emptied baler person who bales hay mills one who bailed wool cotton goods balister archer most commonly crossbowman ballard master one charge loading ballast into hold empty ships ballast heaver ballast man person who used load ballast into hold empty ships baller baller up person who measured out balls clay potter band filer metal worker gun making industry bandster one who bound wheat sheaves after harvest bang beggar officer parish who controlled length stay any stranger parish banker person who dug trenches ditches allow drainage land placing surplus earth banks around edge banksman bank manager employed mining industry being charge cages pit head barber barber surgeon barber who also acted as surgeon act was passed that limited barbers hair-cutting shaving dentistry blood letting 18th century bard poet writer minstrel bareman beggar pauper barge mate supervise coordinate activities crew aboard ships boats barges dredges naval officer bargee bargeman one who worked owned operated barge barilla manufacturer made barilla substance obtained burning saltworts resulting mixture sodium salts being used glass ceramics industry barkeeper another name tollkeeper tavern keeper barker one who strips bark trees also one who prepared leather bark tanner barkman anyone who tanned leather using bark trees basil worker workers who used bark tan skins lambs sheep leather was called basil basketman made baskets furniture wicker person employed empty basket coal being off-loaded colliery into barges bass bast dresser employed dressing fibre matting batman officers servant army batt maker mattress maker made wadding used quilt mattress making batter out sliced short cylinder clay threw it onto mold shaped face ceramic plate battledore maker person who made usually cane beaters used clothes carpets etc remove dust very popular spring cleaning time battuere person who drives game cover during hunt bauer german farmer bayweaver baizeweaver one who wove bay fine woollen fabric also known as baize bead piercer employed drill holes beads beadle bedel bedell officer par\n",
      "Cosine similarity: 0.2344408785829827\n",
      "\n",
      "Answer: miranda richardson chameleons character makeups themakeupgallery chameleons miranda richardson miranda richardson miranda richardson is british stage film television actress she has been nominated two academy awards has won two golden globes seven nominations bafta seven nominations so far during her career she made her film debut playing ruth ellis last woman be hanged uk t dance stranger 1985 that performance her comedic queen elizabeth i aka queenie british television comedy blackadder ii established her reputation following dance stranger she was offered turned down numerous parts her character was unstable including glenn close role fatal attraction since then she played wide variety contemporary period fantasy roles encompassing both dramatic comeic performances 2014 she will be seen maleficent as fairy queen who is maleficents aunt characters world without end 2012 this period mini-series she played mother cecilia nun time black death made dagenham 2009 this movie she played british politician barbara castle young victoria 2009 this movie she played duchess sutherland queen victorias mother southland tales 2007 this movie she played nana mae van adler-frost harry potter goblet fire 2006 she played rita skeeter unscrupulous journalist daily prophet wah-wah 2006 she played lauren this movie set during last days british empire africa 1960s gideons daughter 2006 she played bereaved mother stella this tv drama stephen poliakoff phantom opera 2004 she played madame giry film adaptation churchill hollywood years 2004 she played eva braun this parody rage placid lake 2003 she played sylvia lake lost prince 2003 she played queen mary this itelevision drama about life prince john epileptic youngest child britains king george v queen mary who died age thirteen 1919 spider 2002 she played three roles this david cronenberg movie spiders mother yvonne fantasy mrs wilkingson hours 2002 she played virginia woolfs sister vanessa bell snow white 2001 this tv movie she played hideous sorceress elspeth who becomes snow whites step-mother after being transformed into beautiful woman blackadder back forth 2000 she reprised role queen elizabeth i millennium special jacob two two meets hooded fang 1999 she played miss fowl this childrens fantasy alice wonderland 1999 she played both queen hearts society woman this tv version merlin 1998 she played both queen mab lady lake kansas city 1996 this robert altman movie she played laudanum-addicted mrs stilton tom viv 1994 she played vivienne haigh-wood eliot first wife ts eliot crying game 1992 she played jude ira volunteer true adventures christopher columbus 1992 she played queen isabella this tv comedy blackadder ii 1986 she played childish queen elizabeth i aka queenie this classic tv comedy dance stranger 1985 she played ruth ellis last woman be hanged britain\n",
      "Cosine similarity: 0.210156508122437\n",
      "\n",
      "Answer: great race 1965 imdb imdb 17 january 2017 4 34 pm utc news there was error trying load your rating this title some parts this page wont work property please reload try later x beta im watching this keep track everything you watch tell your friends error popular daredevil proposes automobile race across three continents his arch rival vows beat him while ambitious female reporter has her own plans victory director 2 00 sd amazon video disc list 48 titles created 16 sep 2013 list 44 titles created 26 dec 2014 list 37 titles created 23 mar 2015 list 30 titles created 05 oct 2015 list 27 titles created 4 months ago title great race 1965 7 210 want share imdbs rating your own site use html below you must be registered user use imdb rating plugin won 1 oscar another 1 win 14 nominations see more awards videos edit storyline professional daredevil white-suited hero great leslie convinces turn-of-the-century auto makers that race new york paris westward across america bering straight russia will help promote automobile sales leslies arch-rival mustached black-attired professor fate vows beat leslie finish line car fates own invention blake edwards style slapstick song originated this movie dedication laurel hardy appears beginning film edwards tribute stan ollie can be seen most clearly interaction between professor fate his cohort max as well as operatic pottsdorf pie fight written jeanne baker jbakererim org movie 20 000-mile one-million-laughs guarantee see more genres 1 july 1965 usa see more also known as blake edwards great race see more filming locations stereo rca sound system 70 mm 6-track 70 mm prints color did you know trivia prof fate max maggie dubois drive into russian town maggie repeats professor she had already argued her first interview great leslie that she speaks french russian arabic she then speaks full sentence townspeople russian natalie wood who plays maggie dubois was russian descent her real name is natasha gurdin spoke fluent russian see more goofs american flag displayed near beginning race has 48 stars 1908 this movie supposedly takes place there were only 46 states new mexico arizona were admitted 1912 alaska hawaii were admitted 1959 see more quotes max red sky gonna be storm professor fate are you babbling about max red sky morning sailor take warning professor fate you simple-headed gherkin do you know chances storm this part world this time year professor fate hundred one great thunderclap it begins pour rain max red sky morning sailor take warning see more crazy credits starts dedication mr laurel mr hardy opening credits are form turn century slide show beginning ladies kindly remove your hats wb logo is drawn hood car main characters are introduced jack lemmon is jeered sticks out his tongue reply tony curtis cheered natalie wood gets dog whistles there are various hiccups along way fly is shooed off stick lights go out real hand match comes other slides have be adjusted hand one them starts burn one moment please is interjected producers credit is upside down last slide turns into opening shot movie see more connections biloxi mississippi see all my reviews great race may not be masterpiece it is perfect choice cold rainy night stylish frothy often flatly hilarious it makes comfort viewing its best one movies several charms\n",
      "Cosine similarity: 0.20247166786712142\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 9 : In which year was the Aberfan Disaster?\n",
      "Answer: bbc sport sports personality year sports personality facts figures sports personality facts figures elton john presented 1984 award torvill dean sports personality year venue birmingham lg arena date sunday 19 december time 1900 gmt coverage live bbc one bbc radio 5 live bbc sport website bbc sports personality year celebrates its 57th anniversary this year remains one most important fixtures sporting calendar end-of-the-year television spectacle began 1954 it attracted television audience 12m who watched athlete chris chataway pick up main award recognition setting 5 000m world record chataway fought off tough competition beating roger bannister award despite bannister becoming first man run mile under four minutes that same year where chataway was his pacemaker votes were cast postcard back 1954 14 517 votes arriving bbc hq since chataway was honoured there have been 54 sportsmen sportswomen who have won coveted title bbc sports personality year while many others have been recipients other bbc spoty awards bbc sport has delved through archives look back history sports personality year sports personality year bbcs sports personality year was created 1954 sir paul fox then editor magazine show sportsview was presented peter dimmock dimmock was first 11 presenters frank bough harry carpenter des lynam steve rider sue barker gary lineker clare balding john inverdale adrian chiles jake humphery have all played their part since bough was longest running presenter notching up record 19 shows between 1964 1982 first show was called sportsview before it was re-titled as sports review year then became as we know it today sports personality year 1999 event had been hosted various venues around london before decision was taken move show outside capital four years ago give public chance attend staging birmingham nec was its first port call 2006 2007 before event moved liverpools echo arena 2008 sheffield arena 2009 birmingham will host show third time 2010 lg arena hosts show other venues have hosted ceremony include savoy hotel grosvenor house hotel television theatre shepherds bush empire new london theatre queen elizabeth ii centre bbc television centre main award numbers swimmer ian black became youngest winner award 1958 age 17 golfer dai rees is oldest winner having picked up accolade age 44 1957 kelly holmes win 2004 was 17th time track field athlete had received accolade most any sport this is followed motor racing has produced six winners boxing football have both provided five winners four winners world cricket perhaps surprisingly there has only been one winner rugby union jonny wilkinson 2003 only three people have won award twice henry cooper 1967 1970 nigel mansell 1986 1992 damon hill 1994 1996 1960 first overseas personality year award was picked up australian athlete herb elliott same year inaugural team year prize was presented cooper formula one racing team swimmer anita lonsbrough was first female win personality year 1962 dorothy hyman 1963 mary rand 1964 making it hat-trick female winners facts stats spotys other awards skating duo jayne torvill christopher dean won team year twice 1982 1983 sports personality year once their golden year 1984 bobby moore nick faldo showjumper david broome steve redgrave david beckham jonny wilkinson andrew flintoff ryan giggs are only o\n",
      "Cosine similarity: 0.4406359385450814\n",
      "\n",
      "Answer: mary boleyn biography portrait facts information image source mary boleyn biography portrait facts information mary boleyn was sister king henry viiis second wife infamous anne boleyn she was also kings mistress before her sisters ascendancy she may also have given birth his son information about life mary boleyn is sketchy best before her sisters ascendancy mary was most famous member her family dubious honor since it was based upon her adulterous affair king henry viii there has been great debate over exact year her birth many researchers unable agree boleyn sister was older some speculate anne was born 1501 1502 others place it 1507 most recent scholarship supports 1507 as year annes birth mary was born year later 1508 their only surviving sibling was older brother george born 1503 mary was born hever castle family seat she was named after princess mary tudor youngest child henry vii elizabeth york her family was loyal tudor dynasty had yorkist connections her mother was elizabeth howard daughter thomas earl surrey his father 1st duke norfolk had died fighting richard iii against henry vii marys father thomas boleyn could trace his ancestry only 13th century his family was originally norfolk where they lived as tenant farmers 1457 sir geoffrey boleyn was serving as lord mayor london he wed anne heiress lord hoo hastings through her acquired hever castle kent blickling hall norfolk his son became knight under richard iii baron under henry vii he married great heiress as well she was margaret daughter thomas butler 7th earl ormond he was incredibly wealthy bequeathed margaret 36 manors their eldest child was thomas boleyn marys father thomas had married elizabeth howard 1501 their three surviving children were born within next 10 years 1512 thomas was one three envoys assigned regent netherlands court his skill speaking french his family connections secured appointment once there he was great success regent margaret archduchess austria he used this friendship secure prestigious appointment his eldest daughter anne she was reside regents wards sharing their royal education this is primary evidence that anne was elder sister such cases elder sister would receive opportunity first mary boleyn however mary was married before anne unusual occurrence one led many believe mary was older however it is completely plausible that anne was not married first because she was still europe gaining royal education hoping wed foreign nobleman mary other hand wed man named william carey gentleman royal privy chamber 4 february 1520 though he was not titled lord his duties meant he had intimate contact king daily basis he would be valuable connection boleyns henry used his attendants whom he spent his leisure hours carry out government work carey was 24 years old mary not quite twelve young even 16th century marriage consummation marriage was probably delayed few years marys wedding was held few weeks before her father returned mission abroad this indicates that thomas boleyn had planned marriage well advance king gave newlyweds cash present 6s 8d this was undoubtedly welcome since william carey was younger son lacked money lands henrys favor more particularly marys affair henry helped this respect before his death 1528 william had received two keeperships stewardship annuity manors two counties as williams ancestry he could trace his descent edward iii his mother was cousin margaret beaufort henry viis mother his aunt catherine spencer\n",
      "Cosine similarity: 0.3854073982381619\n",
      "\n",
      "Answer: remembering aberfan disaster 45 years ago today landslide blog agu blogosphere posted dr-dave summary today marks 45 anniverasary aberfan landslide disaster this post brett cherry i review events that day consider lessons that can be learnt this worst landslide disaster uk history remembering aberfan international landslide centre institute hazard risk resilience durham university introduction story aberfan disaster is seared into memories generation people south wales it remains tragedy huge proportions today 45 years disaster there is much learn events leading up that occurred day this article we seek explain events that occurred aberfan 21st october 1966 review disaster occurred examine aftermath finally we briefly examine legacy that this disaster has left many spheres life story aberfan disaster prior disaster aberfan was just another small welsh coal mining village located valleys south wales essentially reason existence village lay coal mining it was founded shortly after first excavations merthyr vale colliery 1869 village was formed primarily close knit community miners their families was sufficiently large be able sustain both primary secondary school pictures post-war period show that hills above village were dominated series enormous spoil heaps dealing waste is perennial problem coal mining often generates large volumes dirty material that has little economic use south wales as elsewhere it was common pile waste close mine workings case aberfan slopes above village mining aberfan started 1869 initially waste was dumped tips slope adjacent mine however as volume material increased new tips were built slopes higher up hiollside 1969 seven tips had been constructed tip 7 disastrous landslide developed was started 1958 reached height about 40 metres it contained about 230 000 m3 waste material was transported tip trams that were hauled up incline series motors before waste was dumped tip crane commission enquiry noted that coal waste tips are concerned water is undoubtedly root cause most failures this was not new finding indeed it had been known least 40 years 45 years it is still case this area south wales has wet climate average rainfall is about 1500 mm per year hillsides are marked lines springs presence these springs hillslopes above was noted ordnance survey maps dating late 19th century remarkably some older tips aberfan built springs watercourses had previously failed example tip 4 slipped 1944 tip 5 had large bulge that was considered be indication that it was unstable furthermore just down valley abercynon landslide developed tip 1939 that buried road depth nearly seven metres so arguments that events aberfan were unprecedented could not have been anticipated cannot be sustained years leading up landslide water hillside had been perennial problem people aberfan starting 1949 possibly earlier series floods had affected upper part town causing damage disruption leaving legacy slimy black deposit its wake was almost certainly mine waste people town repeatedly wrote council national coal board asking this problem be addressed no effect it is ironic that aftermath this disaster this flooding issue was solved through constructio\n",
      "Cosine similarity: 0.37848472717566056\n",
      "\n",
      "--------------------------------------------------\n",
      "Query 10 : An ossuary is a room or container in which what are kept?\n",
      "Answer: ashanti people ashanti people select code introduction ashanti live central ghana western africa map ghana approximately 300km away coast ashanti are major ethnic group akans ghana fairly new nation barely more than 50 years old ghana previously gold coast was british colony until 1957 it is now politically separated into four main parts ashanti is center kumasi is capital ashanti family mothers clan are most important child is said inherit fathers soul spirit ntoro mother child receives flesh blood mogya this relates them more closely mothers clan ashanti live extended family family lives various homes huts that are set up around courtyard head household is usually oldest brother that lives there he is chosen elders he is called either father housefather is obeyed everyone boys are trained their fathers age eight nine they are taught skill fathers choice father is also responsible paying school boys are taught use talking drums their mothers brother talking drums are used learning ashanti language spreading news are also used ceremonies talking drums are important ashanti there are very important rituals involved them girls are taught cooking housekeeping skills their mothers they also work fields bring necessary items such as water group marriage is very important ashanti communal life it can be polygamous men may want more than one wife express their willingness be generous support large family women ashanti culture will not marry without consent their parents many women do not meet their husbands until they are married even so divorce is very rare ashanti culture it is duty parents both sides keep marriage going government ashanti is shaped like pyramid there is one king he heads ashanti confederacy council group made paramount chiefs paramount chief presides over district chiefs district chief presides over district council elders is made up subchiefs villages are brought together subchief within every village there is village head council made up all heads households ashanti religion is mixture spiritual supernatural powers they believe that plants animals trees have souls they also believe fairies witches forest monsters there are variety religious beliefs involving ancestors higher gods abosom nyame supreme being ashanti ashanti also practice many rites marriage death puberty birth golden stool is sacred ashanti there is elaborate legend surrounding it that is told old men ashanti golden stool is very carefully protected no one has ever sat it since its arrival it has not touched ground as ashanti symbol golden stool represents worship ancestors well-being nation ashanti ashanti have wide variety arts bark cloth was used clothing before weaving was introduced weaving there is cotton silk women may pick cotton spin materials into thread only men are allowed weave there are different patterns weaving each its own name sometimes pattern represents social status clan saying sex one wearing it patterns are not always woven cloth it can also be stamped many designs pottery is skill that is taught daughter mother there are many stages making pots there are many colors clay available ashanti also do woodcarving metal casting written april west\n",
      "Cosine similarity: 0.43772847476098725\n",
      "\n",
      "Answer: holy books hinduism boldsky com holy books hinduism holy books hinduism published wednesday april 3 2013 22 30 ist subscribe boldsky hinduism is not really religion it is more like way life hinduism is neither monotheistic nor restricted one religious scripture that is there are many holy books hinduism unlike christianity islam it is not religion that is governed book holy books hinduism are there only guidance religious scriptures are not followed word word however holy books hinduism are basis we have evolved our culture way living following are most sacred holy books hinduism vedas vedas are oldest religious scriptures available us there are four vedas namely rigveda yajurveda samaveda atharvaveda vedic literature was composed knowledgeable pandits brahmins that era puranas puranas are holy books hinduism that date back gupta empire ancient india however puranas are supposed be complied muni vyasa these texts are glorious tales hindu trinity brahma vishnu maheshwar shiva unpanishads upanishads are also called as vedantas end vedas they are wide range philosophical texts that are written as epilogues vedas 200 more upanishads tell us attain nirvana ultimate truth hidden universe ramayana technically ramayana is hindu epic not really scripture due centuries re-telling ramayana has acquired demi-religious status moreover lord rama is avatar vishnu ramayana glorious story rams journey mortal world mahabharata just like ramayana mahabharata is also hindu epic ancient epics had lot divine intervention lord krishna also avatar vishnu who plays key role this story mahabharata is also epic battle during bhagwad gita was inscribed bhagwad gita many hindus whatever is written bhagwad gita is eternal truth it comprises advice teaching that krishna gave his friend arjun just before battle kurukshetra mahabharata gita is kept every hindu household has shlokas that tell you live your life fruitfully devi mahatmya hinduism is considered pagan religion because it worships god female form devi hinduism is single entity who was created cumulative power gods that is devi who is known different names like durga lakshmi saraswati so is most powerful divine being devi mahatmya sings glories devi durga her victory over mahishasura it is usually sung as verses mahalaya first day navratri these are holy books hinduism that govern tenets life religion\n",
      "Cosine similarity: 0.4079836809791347\n",
      "\n",
      "Answer: humidors humidification humatic journal humidors humidification cigars get better kept proper environment it could be inexpensive air tight food type container hand crafted humidor humatic is 1 choice cigar connoisseurs world over humatic 50 3 50 tupperware container two humatic hrs 3500 00 elie blue humidor storing cigars cigars must be kept some type humidity controlled environment traditionally cigars are stored humidors humidors come variety sizes designs most important consideration is that humidors seal tightly it is preferred that humidors are lined spanish cedar wood cedar is used two reasons it gives cigars cedar flavor that is enjoyed many cigars enthusiasts b it will hold moisture not mold rot if conditions were created that provoked mold it is obviously too wet cigars are best if kept 72 relative humidity 70¬∫f cigars stored 72 rh offer their greatest taste their bouquet combustibility is perfect some people prefer their cigars kept 70 rh some people prefer their cigars kept 74 rh keeping cigars within these parameters becomes personal choice if kept below 68 rih cigars start dry out dry cigars bum fast taste harsh above 80 rh cigars are too wet stay lit enjoy above 85 rh they will become soggy develop mold protecting your cigar investment shown left are several choice cuban cigars they are stored 3 50 tupperware container they are maintained perfect condition simple maintenance free low cost humatic 50 pouch shown right is is generally agreed be finest humidor world this hand crafted french made eli blu humidor is adorned gold medallions it is maintained two humatic hr humidification regulators two hr regulators are serviced humatic scientific solution twice year proud owner this choice eli blu humidor trusted his precious cuban made cohiba robustos lanceros esplendidos humatic aging cigars cigars should be stored optimum conditions 18 months this time they begin offer many beneficial characteristics cigar smokers desire if kept three years they develop deeper character if kept five seven years same cigars become masterful cuban cigars photographed canada\n",
      "Cosine similarity: 0.4052574202187244\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def retrieve_k_relevant_results(query: str, k: int) -> dict:\n",
    "    retrieved = {}\n",
    "    e_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "    query_similarity = cosine_similarity_1_to_n(e_query, valid_answers_bows)\n",
    "    top_indices = top_k_indices(query_similarity, k)\n",
    "    for idx in top_indices:\n",
    "        ans = answers_dataset['validation'][idx]['answer']\n",
    "        cos_sim = query_similarity[idx]\n",
    "        retrieved[ans] = cos_sim\n",
    "    return retrieved \n",
    "\n",
    "for i, row in enumerate(sampled_queries.iterrows(), start=1):\n",
    "    idx, data = row \n",
    "    q = data['query']\n",
    "    oq = data['original_query']\n",
    "    print(f\"Query {i} : {oq}\")\n",
    "    retrieved = retrieve_k_relevant_results(q, 3)\n",
    "    for key, value in retrieved.items():\n",
    "        print(f\"Answer: {key}\")\n",
    "        print(f\"Cosine similarity: {value}\\n\")\n",
    "    print(50*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Term Frequency - Inverse Document Frequency\n",
    "\n",
    "In this section we will implement the TF-IDF algorithm. While BOW is a simple way to represent the documents, it has some limitations. For example, it does not take into account the importance of each word in the document. TF-IDF representation takes into account the frequency of each word in the document and the frequency of the word in the whole dataset. It is a widely used technique in information retrieval and text mining. Refer to the lecture slides for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inverse Document Frequency\n",
    "\n",
    "<a name='e9'></a>\n",
    "#### Exercise 9: Inverse Document Frequency (IDF)\n",
    "In this exercise, you will implement the TF-IDF algorithm. First, calculate Inverse Document Frequency (IDF) for each word in the vocabulary. Intuitively, it is a measure of how informative a word is based on the whole dataset. Consult the lecture slides for the details. The IDF is calculated as follows:\n",
    "$$\n",
    "IDF(t) = log_{10}(N/df(t))$$\n",
    "where $N$ is the total number of documents (sentences) in the dataset and $df(t)$ is the number of documents containing the word $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_idf(bows):\n",
    "    \"\"\"\n",
    "    Calculates the IDF for each word in the vocabulary\n",
    "    Args:\n",
    "        bows: numpy array of size (N x D) where N is the number of documents and D is the vocabulary size\n",
    "\n",
    "    Returns: a numpy array of size D with IDF values for each token\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    dim = bows.shape \n",
    "    D = dim[-1]\n",
    "    N = dim[0]\n",
    "    counts = np.sum(bows, axis=0)\n",
    "    idf = np.log10(N / counts)\n",
    "\n",
    "    return idf\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To avoid the data leakage, the IDF should be calculated the train subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47971/47971 [00:23<00:00, 2034.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train_answers_bows = []\n",
    "for example in tqdm.tqdm(answers_dataset['train']):\n",
    "    train_answers_bows.append(bag_of_words(example['answer_tokens'], token_to_id))\n",
    "\n",
    "train_answers_bows = np.array(train_answers_bows)\n",
    "\n",
    "idf = calculate_idf(train_answers_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Full TF-IDF\n",
    "\n",
    "<a name='e10'></a>\n",
    "#### Exercise 10: TF-IDF\n",
    "- Calculate TF-IDF on the `test` subset of the dataset.\n",
    "- Analyze the search results based on your implemented TF-IDF. Does the search perform well? When does it fail? Discuss several examples that are we get an expected but also unexpected results (find at least 3 from each category). Provide reasons for the good/bad result in each case (e.g. is there some error in the data, is there some linguistic phenomenon that we don't capture, is something wrong with our modeling with average embeddings, ...)\n",
    "- Compare the results with the ones you got with the bag-of-words representation. Discuss the differences and similarities. Do you think TF-IDF is a better representation for this task? Why or why not? Provide examples to support your arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# You can implement the following functions, but you can also use your own design.\n",
    "\n",
    "def calculate_tf_idf_n(bows, idf):\n",
    "    \"\"\"\n",
    "    Calculates the TF-IDF for each word in the vocabulary\n",
    "    Args:\n",
    "        bows: numpty array of size (N x D) where N is the number of documents and D is the vocabulary size\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    Returns: a numpy array of size (N x D) with TF-IDF values for each document and each token\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_tf_idf(bow, idf):\n",
    "    \"\"\"\n",
    "    Calculates the TF-IDF for a single document\n",
    "    Args:\n",
    "        bow: a numpy array of size D with the bag-of-words representation of the document\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    Returns: a numpy array of size D with TF-IDF values for each token\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def embed_tf_idf(sentence, token_to_id, idf):\n",
    "    \"\"\"\n",
    "    Embeds the sentence using TF-IDF\n",
    "    Args:\n",
    "        sentence: a list of tokens\n",
    "        token_to_id: a dictionary mapping each word to an index in the vocabulary\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    Returns: a numpy array of size D with TF-IDF values for each token\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# query = dataset['validation'][0]['query']\n",
    "# print('query:', query)\n",
    "# query_tfidf = embed_text(query, clean, tokenize, lambda x: embed_tf_idf(x, token_to_id, idf))\n",
    "#\n",
    "# answers_tfidf = calculate_tf_idf_n(valid_answers_bows, idf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word Embeddings\n",
    "\n",
    "\n",
    "Word embeddings are a powerful model for representing words and their meaning (in terms of distributional similarity). As we discussed in class, we can use them in a wide variety of tasks with more complex architectures. Word vectors offer a dense vector for each word.\n",
    "\n",
    "In this section you will load the pre-trained word embeddings model - Glove. You can read more about it [here](https://aclanthology.org/D14-1162/) ([https://aclanthology.org/D14-1162/](https://aclanthology.org/D14-1162/)). The embeddings are trained on a large corpus of text and are available in different dimensions. We will start with the dimension of 100, but later you will be asked to experiment with other dimensions.\n",
    "\n",
    "You can download the embeddings manually from one of the following links:\n",
    "- https://www.kaggle.com/datasets/pkugoodspeed/nlpword2vecembeddingspretrained/data?select=glove.6B.50d.txt\n",
    "- https://github.com/nishankmahore/word2vec-flask-api (check the table in the readme)\n",
    "\n",
    "The extracted files should contain several models but for now we will be using the 50-dimensional one. This means that each token is represented as a 50-dimensional floating point vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_embeddings_path = 'glove.6B/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will load and parse this file line-by-line. Your job in the next exercise is the parsing part.\n",
    "\n",
    "<a name='e11'></a>\n",
    "#### Exercise 11: Parsing the embeddings\n",
    "Implement the following function to parse a single line of the glove embeddings file. The line contains string values separated by spaces. The first value is the token and the rest are the elements of the embedding vector (the values should be cast to float). You can inspect the file to get a better idea of what is there. Return both the token (as string) and the embedding (as a numpy array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_embeddings_row(line):\n",
    "    \"\"\"\n",
    "    Parses a single line from the GloVe embeddings file. The line contains a word followed by its embedding values separated by spaces.\n",
    "    Args:\n",
    "        line: a line from the GloVe embeddings file\n",
    "\n",
    "    Returns: a tuple (word, embedding) where 'word' is a string and 'embedding' is a numpy array of floats\n",
    "    \"\"\"\n",
    "    line_split = line.split()\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return token, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we load the file and iterate over the lines to load the tokens and their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "embeddings = []\n",
    "with open(glove_embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        token, embedding = parse_embeddings_row(line)\n",
    "        tokens.append(token)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "embeddings = np.stack(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we will create a class `WordEmbeddings` that will hold embeddings and expose useful methods to embed a single token (`embed_token()`) and the whole sentence (`embed_sentence()`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sentence Embeddings by Averaging Word Embeddings\n",
    "In the course, we will see different architectures that take into account the sequence of words (by combining their vectors). A first naive but simple and sometimes (as we are going to see) quite effective approach would be to represent a sentence with an embedding vector that is the average of the word vectors that form the sentence.\n",
    "\n",
    "So formally, this is what we are aiming for:\n",
    "\n",
    "$\n",
    "\\text{Sentence_Embedding} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Word_Embedding}_i\n",
    "$\n",
    "\n",
    "where:\n",
    "* $N$ is the number of words in a sentence\n",
    "* $\\text{Word_Embedding}_i$ is the word vector for the $i$-th in the sentence.\n",
    "\n",
    "Things to note:\n",
    "* The embedding vector for the sentence will obviously have the same dimension as the word embedding.\n",
    "* This representation ignores the word order (like bag-of-words). During the course we will see how we can overcome this limitation by using sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e12'></a>\n",
    "#### Exercise 12: Word Embeddings Class\n",
    "Implement the two methods in the following class:\n",
    "- `embed_token()` - accepts a token to be embedded. Use `self.token_to_id` to find the row in the `self.embeddings` attribute. If the token is outside the vocabulary, return `None`.\n",
    "- `embed_sentence()` - accepts a list of tokens that form a sentence. Each token (that is inside the vocabulary) should be embedded. The second parameter `reduction` will determine how the embedded tokens are \"reduced\". There are three options: `mean` should average the tokens (resulting in a single numpy array of size `embedding_dim`, which is 50 for our model), `sum` should sum the tokens, and `none` should return the embeddings of all tokens as a single numpy array (the array should be of shape `(N, embedding_dim)`). Think about a situation where none of the tokens in a sentence is in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WordEmbeddings:\n",
    "    def __init__(self, vocabulary, embeddings):\n",
    "        \"\"\"\n",
    "        Initializes the WordEmbeddings object.\n",
    "        Args:\n",
    "            vocabulary: list of str\n",
    "            embeddings: np.ndarray of shape (vocab_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        self.token_to_id = {token: i for i, token in enumerate(vocabulary)}\n",
    "        self.id_to_token = {i: token for i, token in enumerate(vocabulary)}\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def embed_token(self, token):\n",
    "        \"\"\"\n",
    "        Embed a single token into its word embedding.\n",
    "        Args:\n",
    "            token: str, the token to embed\n",
    "\n",
    "        Returns: np.ndarray with the embedded token or None if the token is not in the vocabulary\n",
    "        \"\"\"\n",
    "        embedding = None\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### YOUR CODE ENDS HERE\n",
    "        return embedding\n",
    "\n",
    "    def embed_sentence(self, tokens, reduction='none'):\n",
    "        \"\"\"\n",
    "        Embed a sentence (list of tokens) into word embeddings. Reduction can be 'none', 'mean', or 'sum'.\n",
    "        If 'reduction' is 'none', returns a 2D array of shape (len(tokens), embedding_dim). If 'mean' or 'sum',\n",
    "        returns a 1D array of shape (embedding_dim,) with the values averaged or summed respectively.\n",
    "        Args:\n",
    "            tokens: list of str\n",
    "            reduction: str, one of 'none', 'mean', 'sum'\n",
    "\n",
    "        Returns: np.ndarray with the embedded sentence\n",
    "        \"\"\"\n",
    "        embedding = None\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### YOUR CODE ENDS HERE\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove50_model = WordEmbeddings(tokens, embeddings)\n",
    "del tokens, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's test the method `embed_sentence()`. Notice the shape of the returned arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedding = glove50_model.embed_sentence('how are you doing ?'.split(' '))\n",
    "print(embedding.shape)\n",
    "print(embedding[:, :10])\n",
    "embedding = glove50_model.embed_sentence('how are you doing ?'.split(' '), reduction='mean')\n",
    "print(embedding.shape)\n",
    "print(embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Similarities between words\n",
    "\n",
    "The function below returns the most similar words to the word provided. The returned list does not contain the word itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def most_similar_words(word, model:WordEmbeddings, k):\n",
    "    \"\"\"\n",
    "    Finds the k most similar words to the given word using cosine similarity.\n",
    "    The returned list should contain tuples (word, similarity) sorted by similarity (descending from the most similar).\n",
    "    Args:\n",
    "        word: str, the word to find similar words for\n",
    "        model: WordEmbeddings, the word embeddings model\n",
    "        k: int, the number of similar words to return\n",
    "\n",
    "    Returns: list of tuples (word, similarity)\n",
    "    \"\"\"\n",
    "    embedding = model.embed_token(word)\n",
    "    if embedding is None:\n",
    "        return []\n",
    "\n",
    "    word_id = model.token_to_id[word]\n",
    "    all_embeddings = model.embeddings\n",
    "    similarity = cosine_similarity_1_to_n(embedding, all_embeddings)\n",
    "    top_indices = top_k_indices(similarity, k=k + 1).tolist()\n",
    "    most_similar = []\n",
    "    for id in top_indices:\n",
    "        if id == word_id:\n",
    "            continue\n",
    "        most_similar.append((model.id_to_token[id], similarity[id].item()))\n",
    "    return most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(most_similar_words('what', glove50_model, k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next function contains the code to plot a similarity matrix between multiple words (e.g. if we want to compare 10 words and their pair-wise similarities). It requires a matrix with similarities (as input) and labels (aka the words) to display in the final figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_similarity_matrix(matrix, labels):\n",
    "    \"\"\"\n",
    "    Displays a plot of the `matrix` of size (N x N) with the labels specified as a list of size N\n",
    "    Args:\n",
    "        matrix: a square-sized (N x N) numpy array\n",
    "        labels: a list of strings of hte size N\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(matrix)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "    ax.set_yticks(np.arange(len(labels)), labels=labels)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{matrix[i, j]:.2f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e13'></a>\n",
    "#### Exercise 13: Plotting similarities between words\n",
    "\n",
    "In the following, we will explore some properties of word embeddings through some examples. We will use 6 example words for this purpose but experiment with other set of words as well. Fill in the next cell to create a similarity matrix between a list of words.\n",
    "\n",
    "Experiment with different words and their similarities plotted. Try at least 2 more (different) sets of words of at least 6 words each. Use the `plot_similarity_matrix` function to visualize the results.\n",
    "Comment on the results. Do they make sense? Why some words are closer to each other than others? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list_of_words = ['love', 'hate', 'life', 'equal', 'alive', 'dead']\n",
    "\n",
    "similarity_matrix = np.zeros((len(list_of_words), len(list_of_words)), dtype=float)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "plot_similarity_matrix(similarity_matrix, list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Back to Sentence Embeddings\n",
    "\n",
    "Let us go back to embedding the whole sentences by averaging the embeddings in the sentence. Below you can find a code snippet that uses our `embed_text()` function and glove model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = 'fox and deer'\n",
    "print(query)\n",
    "\n",
    "query_embedding = embed_text(query, clean, tokenize, lambda x: glove50_model.embed_sentence(x, reduction='mean'))\n",
    "print(query_embedding.shape)\n",
    "print(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e14'></a>\n",
    "#### Exercise 14: Analyze sentence embeddings\n",
    "- Calculate similarity between the word embeddings representations of the selected queries and the dataset sentences.\n",
    "- Analyze the search results. Does the search work as expected? Discuss the results.\n",
    "- Compare the results with the ones you got with the bag-of-words and TF-IDF representation. Discuss the differences and similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Evaluating Retrieval\n",
    "\n",
    "In this last section we will try to evaluate how good our sentence retrieval system is. To keep the computational resources manageable, we will use the test set for that as its size is more manageable.\n",
    "\n",
    "Recall from the lecture in IR that there are several metrics to evaluate retrieval performance by taking into account the relevance of the retrieved results to the query. We will use Recall@K here (for more metrics and more details refer to the lecture slides and the textbooks).\n",
    "\n",
    "Recall@K is a metric used to measure the effectiveness of a search system in retrieving relevant documents within the top $K$ retrieved documents. It calculates the proportion of relevant documents retrieved within the top-$K$ results, compared to the total number of relevant documents in the collection.\n",
    "\n",
    "$\n",
    "\\text{Recall@K} = \\frac{\\text{Number of relevant documents retrieved in the top }-K}{\\text{Total number of relevant documents}}\n",
    "$\n",
    "\n",
    "In our case, we have a sentence, and it's compressed version. To test our system, we will treat compressed sentences as the queries. Each query will have only a single relevant sentence - the corresponding uncompressed sentence.\n",
    "\n",
    "Therefore, for the calculation of Recall@K we will take into account whether the correct retrieved result is contained within the first $K$ retrieved results. For example, if for a query (i.e. a compressed sentence) we retrieve 10 results and within these we see the relevant one (i.e. the full sentence), then Recall@10 = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e15'></a>\n",
    "### Exercise 15: Cosine similarity between two sets of vectors\n",
    "\n",
    "In this exercise you will revisit your implementation of the cosine similarity. Generalize it so that it can accept two arrays containing two sets of vectors (first one containing $M$ vectors and the second one $N$ vectors). Compute the cosine similarity between each pair of vectors coming from the two sets. The result should be an array of size $M x N$.\n",
    "\n",
    "Once again, try to write an efficient code. This means no loops. Remember the relation between matrix multiplication and dot product. (Depending on your implementation of the previous function calculating cosine similarity, this one can be almost the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_m_to_n(vectors, other_vectors):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between a multiple vectors and other vectors.\n",
    "    Args:\n",
    "        vectors: a numpy array representing M number of vectors of D dimensions (of the size MxD)\n",
    "        other_vectors: a 2D numpy array representing other vectors (of the size NxD, where N is the number of vectors and D is their dimension)\n",
    "\n",
    "    Returns: a numpy array of cosine similarity between all the vectors and all the other vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will use your implementation to calculate Recall@K based on the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_recall(queries, sentences, labels, k, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Calculates recall@k given the embeddings of the queries and sentences.\n",
    "    Assumes that only a single sentence with the same index as query is relevant.\n",
    "    Batching is implemented to avoid high memory usage.\n",
    "    Args:\n",
    "        queries: a numpy array with the embeddings of N queries\n",
    "        sentences: a numpy array with the embeddings of N sentences available for retrieval\n",
    "        k: number of top results to search for the relevant sentence\n",
    "        batch_size: number of queries to process at a time\n",
    "\n",
    "    Returns: calculated recall@k\n",
    "\n",
    "    \"\"\"\n",
    "    n_queries = queries.shape[0]\n",
    "    correct = np.zeros(n_queries, dtype=bool)\n",
    "\n",
    "    with tqdm.tqdm(total=n_queries) as pbar:\n",
    "        for batch_start in range(0, n_queries, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, n_queries)\n",
    "            queries_batch = queries[batch_start:batch_end]\n",
    "            batch_similarity = cosine_similarity_m_to_n(queries_batch, sentences)\n",
    "\n",
    "            for i, similarity_row in enumerate(batch_similarity):\n",
    "                query_index = batch_start + i\n",
    "                top_k = top_k_indices(similarity_row, k=k, sorted=False)\n",
    "                label = labels[query_index]\n",
    "                if label in top_k:\n",
    "                    correct[query_index] = True\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    recall = np.sum(correct) / n_queries\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we embed both the queries and answers from the validation subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query_embeddings = []\n",
    "expected_answers = []\n",
    "for example in tqdm.tqdm(dataset['validation']):\n",
    "    query_tokens = example['query_tokens']\n",
    "    query_embeddings.append(glove50_model.embed_sentence(query_tokens, reduction='mean'))\n",
    "    expected_answers.append(example['answer_id'])\n",
    "query_embeddings = np.stack(query_embeddings, axis=0)\n",
    "expected_answers = np.array(expected_answers)\n",
    "\n",
    "answers_embeddings = []\n",
    "for example in tqdm.tqdm(answers_dataset['validation']):\n",
    "    answer_tokens = example['answer_tokens']\n",
    "    answers_embeddings.append(glove50_model.embed_sentence(answer_tokens, reduction='mean'))\n",
    "answers_embeddings = np.stack(answers_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use the recall function like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall_at_1 = calculate_recall(query_embeddings, answers_embeddings, expected_answers, k=1, batch_size=1000)\n",
    "print(f'\\n{recall_at_1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e16'></a>\n",
    "### Exercise 16: Evaluating retrieval methods\n",
    "\n",
    "Calculate recall for different values of $K$ for all methods:\n",
    "- BOW,\n",
    "- TF-IDF,\n",
    "- Pre-trained embeddings.\n",
    "- Another pre-trained embeddings (for example with larger embedding vectors)\n",
    "\n",
    "Make sure to test on the `test` split. Discuss the results. Comment on how recall changes based on the value of $K$. Are the results expected or surprising?\n",
    "\n",
    "The deliverable for this whole lab is a scientific poster and this last question should be the main thing you will include in the poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplab2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
